search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202407192000+TO+202407252000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.LG, cs.AI, stat.*, physics.data-an staritng 202407192000 and ending 202407252000</h1>Feed last updated: 2024-07-25T00:00:00-04:00<a href="http://arxiv.org/pdf/2407.16917v1"><h2>TelescopeML -- I. An End-to-End Python Package for Interpreting
  Telescope Datasets through Training Machine Learning Models, Generating
  Statistical Reports, and Visualizing Results</h2></a>Authors:  Ehsan, Gharib-Nezhad, Natasha E. Batalha, Hamed Valizadegan, Miguel J. S. Martinho, Mahdi Habibi, Gopal Nookula</br>Comments: Please find the accepted paper with complete reference list at
  https://joss.theoj.org/papers/10.21105/joss.06346</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.EP, cs.LG</br><p>We are on the verge of a revolutionary era in space exploration, thanks to
advancements in telescopes such as the James Webb Space Telescope
(\textit{JWST}). High-resolution, high signal-to-noise spectra from exoplanet
and brown dwarf atmospheres have been collected over the past few decades,
requiring the development of accurate and reliable pipelines and tools for
their analysis. Accurately and swiftly determining the spectroscopic parameters
from the observational spectra of these objects is crucial for understanding
their atmospheric composition and guiding future follow-up observations.
\texttt{TelescopeML} is a Python package developed to perform three main tasks:
1. Process the synthetic astronomical datasets for training a CNN model and
prepare the observational dataset for later use for prediction; 2. Train a CNN
model by implementing the optimal hyperparameters; and 3. Deploy the trained
CNN models on the actual observational data to derive the output spectroscopic
parameters.</p></br><a href="http://arxiv.org/pdf/2407.15180v1"><h2>Generalizing Trilateration: Approximate Maximum Likelihood Estimator for
  Initial Orbit Determination in Low-Earth Orbit</h2></a>Authors:  Ricardo Ferreira, Filipa Valdeira, Marta Guimarães, Cláudia Soares</br>Comments: No comment found</br>Primary Category: math.OC</br>All Categories: math.OC, astro-ph.IM, cs.LG</br><p>With the increase in the number of active satellites and space debris in
orbit, the problem of initial orbit determination (IOD) becomes increasingly
important, demanding a high accuracy. Over the years, different approaches have
been presented such as filtering methods (for example, Extended Kalman Filter),
differential algebra or solving Lambert's problem. In this work, we consider a
setting of three monostatic radars, where all available measurements are taken
approximately at the same instant. This follows a similar setting as
trilateration, a state-of-the-art approach, where each radar is able to obtain
a single measurement of range and range-rate. Differently, and due to advances
in Multiple-Input Multiple-Output (MIMO) radars, we assume that each location
is able to obtain a larger set of range, angle and Doppler shift measurements.
Thus, our method can be understood as an extension of trilateration leveraging
more recent technology and incorporating additional data. We formulate the
problem as a Maximum Likelihood Estimator (MLE), which for some number of
observations is asymptotically unbiased and asymptotically efficient. Through
numerical experiments, we demonstrate that our method attains the same accuracy
as the trilateration method for the same number of measurements and offers an
alternative and generalization, returning a more accurate estimation of the
satellite's state vector, as the number of available measurements increases.</p></br><a href="http://arxiv.org/pdf/2407.15703v1"><h2>Estimating Probability Densities with Transformer and Denoising
  Diffusion</h2></a>Authors:  Henry W. Leung, Jo Bovy, Joshua S. Speagle</br>Comments: Accepted at the ICML 2024 Workshop on Foundation Models in the Wild</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.IM, stat.ML</br><p>Transformers are often the go-to architecture to build foundation models that
ingest a large amount of training data. But these models do not estimate the
probability density distribution when trained on regression problems, yet
obtaining full probabilistic outputs is crucial to many fields of science,
where the probability distribution of the answer can be non-Gaussian and
multimodal. In this work, we demonstrate that training a probabilistic model
using a denoising diffusion head on top of the Transformer provides reasonable
probability density estimation even for high-dimensional inputs. The combined
Transformer+Denoising Diffusion model allows conditioning the output
probability density on arbitrary combinations of inputs and it is thus a highly
flexible density function emulator of all possible input/output combinations.
We illustrate our Transformer+Denoising Diffusion model by training it on a
large dataset of astronomical observations and measured labels of stars within
our Galaxy and we apply it to a variety of inference tasks to show that the
model can infer labels accurately with reasonable distributions.</p></br>
