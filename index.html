search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202512022000+TO+202512082000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, cs.LG, physics.data-an, stat.* staritng 202512022000 and ending 202512082000</h1>Feed last updated: 2025-12-08T04:25:21Z<a href="https://arxiv.org/pdf/2512.04803v1"><h2>287,872 Supermassive Black Holes Masses: Deep Learning Approaching Reverberation Mapping Accuracy</h2></a>Authors:  Yuhao Lu, HengJian SiTu, Jie Li, Yixuan Li, Yang Liu, Wenbin Lin, Yu Wang</br>Comments: 14 pages, 9 figures. Submitted to Journal of High Energy Astrophysics</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, astro-ph.HE, astro-ph.IM, cs.AI</br><p>We present a population-scale catalogue of 287,872 supermassive black hole masses with high accuracy. Using a deep encoder-decoder network trained on optical spectra with reverberation-mapping (RM) based labels of 849 quasars and applied to all SDSS quasars up to $z=4$, our method achieves a root-mean-square error of $0.058$\,dex, a relative uncertainty of $\approx 14\%$, and coefficient of determination $R^{2}\approx0.91$ with respect to RM-based masses, far surpassing traditional single-line virial estimators. Notably, the high accuracy is maintained for both low ($<10^{7.5}\,M_\odot$) and high ($>10^{9}\,M_\odot$) mass quasars, where empirical relations are unreliable.</p></br><a href="https://arxiv.org/pdf/2512.04031v1"><h2>Large Language Models for Limited Noisy Data: A Gravitational Wave Identification Study</h2></a>Authors:  Yixuan Li, Yuhao Lu, Yang Liu, Liang Li, R. Ruffini, Di Li, Rong-Gen Cai, Xiaoyan Zhu, Wenbin Lin, Yu Wang</br>Comments: 10 pages, 5 figures</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.HE, cs.AI</br><p>This work investigates whether large language models (LLMs) offer advantages over traditional neural networks for astronomical data processing, in regimes with non-Gaussian, non-stationary noise and limited labeled samples. Gravitational wave observations provide an suitable test case, using only 90 LIGO events, finetuned LLMs achieve 97.4\% accuracy for identifying signals. Further experiments show that, in contrast to traditional networks that rely on large simulated datasets, additional simulated samples do not improve LLM performance, while scaling studies reveal predictable gains with increasing model size and dataset size. These results indicate that LLMs can extract discriminative structure directly from observational data and provide an efficient assessment for gravitational wave identification. The same strategy may extend to other astronomical domains with similar noise properties, such as radio or pulsar observations.</p></br><a href="https://arxiv.org/pdf/2512.04204v1"><h2>Machine Phenomenology: A Simple Equation Classifying Fast Radio Bursts</h2></a>Authors:  Yang Liu, Yuhao Lu, Rahim Moradi, Bo Yang, Bing Zhang, Wenbin Lin, Yu Wang</br>Comments: 19 pages, 9 figures, 3 tables. Submitted to SCIENCE CHINA Physics, Mechanics & Astronomy</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.HE, cs.AI</br><p>This work shows how human physical reasoning can guide machine-driven symbolic regression toward discovering empirical laws from observations. As an example, we derive a simple equation that classifies fast radio bursts (FRBs) into two distinct Gaussian distributions, indicating the existence of two physical classes. This human-AI workflow integrates feature selection, dimensional analysis, and symbolic regression: deep learning first analyzes CHIME Catalog 1 and identifies six independent parameters that collectively provide a complete description of FRBs; guided by Buckingham-$Ï€$ analysis and correlation analysis, humans then construct dimensionless groups; finally, symbolic regression performed by the machine discovers the governing equation. When applied to the newer CHIME Catalog, the equation produces consistent results, demonstrating that it captures the underlying physics. This framework is applicable to a broad range of scientific domains.</p></br><a href="https://arxiv.org/pdf/2512.04600v1"><h2>The dynamical memory of tidal stellar streams: Joint inference of the Galactic potential and the progenitor of GD-1 with flow matching</h2></a>Authors:  Giuseppe Viterbo, Tobias Buck</br>Comments: submitted to A&A, comments welcome, all source code to reproduce this work can be found on GitHub under the url: https://github.com/vepe99/sbi-sim/tree/odisseo_branch . The simulator \textsc{\texttt{Odisseo}} is available on GitHub at the following url: https://github.com/vepe99/Odisseo</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, physics.class-ph, physics.data-an, physics.space-ph</br><p>Stellar streams offer one of the most sensitive probes of the Milky Way`s gravitational potential, as their phase-space morphology encodes both the tidal field of the host galaxy and the internal structure of their progenitors. In this work, we introduce a framework that leverages Flow Matching and Simulation-Based Inference (SBI) to jointly infer the parameters of the GD-1 progenitor and the global properties of the Milky Way potential. Our aim is to move beyond traditional techniques (e.g. orbit-fitting and action-angle methods) by constructing a fully Bayesian, likelihood-free posterior over both host-galaxy parameters and progenitor properties, thereby capturing the intrinsic coupling between tidal stripping dynamics and the underlying potential. To achieve this, we generate a large suite of mock GD-1-like streams using our differentiable N-body code \textsc{\texttt{Odisseo}}, sampling self-consistent initial conditions from a Plummer sphere and evolving them in a flexible Milky Way potential model. We then apply conditional Flow Matching to learn the vector field that transports a base Gaussian distribution into the posterior, enabling efficient, amortized inference directly from stream phase-space data. We demonstrate that our method successfully recovers the true parameters of a fiducial GD-1 simulation, producing well-calibrated posteriors and accurately reproducing parameter degeneracies arising from progenitor-host interactions. Flow Matching provides a powerful, flexible framework for Galactic Archaeology. Our approach enables joint inference on progenitor and Galactic parameters, capturing complex dependencies that are difficult to model with classical likelihood-based methods.</p></br><a href="https://arxiv.org/pdf/2512.05751v1"><h2>Exoplanet formation inference using conditional invertible neural networks</h2></a>Authors:  Remo Burn, Victor F. Ksoll, Hubert Klahr, Thomas Henning</br>Comments: 10 pages, accepted poster for the Machine Learning and the Physical Sciences Workshop at the 39th conference on Neural Information Processing Systems (NeurIPS 2025)</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, cs.NE, physics.data-an</br><p>The interpretation of the origin of observed exoplanets is usually done only qualitatively due to uncertainties of key parameters in planet formation models. To allow a quantitative methodology which traces back in time to the planet birth locations, we train recently developed conditional invertible neural networks (cINN) on synthetic data from a global planet formation model which tracks growth from dust grains to evolved final giant planets. In addition to deterministic single planet formation runs, we also include gravitationally interacting planets in multiplanetary systems, which include some measure of chaos. For the latter case, we treat them as individual planets or choose the two or three planets most likely to be discovered by telescopes. We find that training on multiplanetary data, each planet treated as individual point, is promising. The single-planet data only covers a small range of planets and does not extrapolate well to planet properties not included in the training data. Extension to planetary systems will require more training data due to the higher dimensionality of the problem.</p></br>
