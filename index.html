search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202512102000+TO+202512162000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, cs.LG, physics.data-an, stat.* staritng 202512102000 and ending 202512162000</h1>Feed last updated: 2025-12-16T04:27:32Z<a href="https://arxiv.org/pdf/2512.10283v1"><h2>MorphZ: Enhancing evidence estimation through the Morph approximation</h2></a>Authors:  El Mehdi Zahraoui, Patricio Maturana-Russel, Avi Vajpeyi, Willem van Straten, Renate Meyer, Sergei Gulyaev</br>Comments: No comment found</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.CO, physics.data-an</br><p>We introduce the Morph approximation, a class of product approximations of probability densities that selects low-order disjoint parameter blocks by maximizing the sum of their total correlations. We use the posterior approximation via Morph as the importance distribution in optimal bridge sampling. We denote this procedure by MorphZ, which serves as a post-processing estimator of the marginal likelihood. The MorphZ estimator requires only posterior samples together with the prior and likelihood, and is fully agnostic to the choice of sampler. We evaluate MorphZ's performance across statistical benchmarks, pulsar timing array (PTA) models, compact binary coalescence (CBC) gravitational-wave (GW) simulations and the GW150914 event. Across these applications, spanning low to high dimensionalities, MorphZ yields accurate evidence at substantially reduced computational cost relative to standard approaches, and can improve these estimates even when posterior coverage is incomplete. Its bridge sampling relative error diagnostic provides conservative uncertainty estimates. Because MorphZ operates directly on posterior draws, it complements exploration-oriented samplers by enabling fast and reliable evidence estimation, while it can be seamlessly integrated into existing inference workflows.</p></br><a href="https://arxiv.org/pdf/2512.10222v1"><h2>Galaxy Phase-Space and Field-Level Cosmology: The Strength of Semi-Analytic Models</h2></a>Authors:  Natalí S. M. de Santi, Francisco Villaescusa-Navarro, Pablo Araya-Araya, Gabriella De Lucia, Fabio Fontanot, Lucia A. Perez, Manuel Arnés-Curto, Violeta Gonzalez-Perez, Ángel Chandro-Gómez, Rachel S. Somerville, Tiago Castro</br>Comments: 23 pages, 5 figures</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, astro-ph.GA, cs.LG</br><p>Semi-analytic models are a widely used approach to simulate galaxy properties within a cosmological framework, relying on simplified yet physically motivated prescriptions. They have also proven to be an efficient alternative for generating accurate galaxy catalogs, offering a faster and less computationally expensive option compared to full hydrodynamical simulations. In this paper, we demonstrate that using only galaxy $3$D positions and radial velocities, we can train a graph neural network coupled to a moment neural network to obtain a robust machine learning based model capable of estimating the matter density parameters, $Ω_{\rm m}$, with a precision of approximately 10%. The network is trained on ($25 h^{-1}$Mpc)$^3$ volumes of galaxy catalogs from L-Galaxies and can successfully extrapolate its predictions to other semi-analytic models (GAEA, SC-SAM, and Shark) and, more remarkably, to hydrodynamical simulations (Astrid, SIMBA, IllustrisTNG, and SWIFT-EAGLE). Our results show that the network is robust to variations in astrophysical and subgrid physics, cosmological and astrophysical parameters, and the different halo-profile treatments used across simulations. This suggests that the physical relationships encoded in the phase-space of semi-analytic models are largely independent of their specific physical prescriptions, reinforcing their potential as tools for the generation of realistic mock catalogs for cosmological parameter inference.</p></br><a href="https://arxiv.org/pdf/2512.11202v1"><h2>amc: The Automated Mission Classifier for Telescope Bibliographies</h2></a>Authors:  John F. Wu, Joshua E. G. Peek, Sophie J. Miller, Jenny Novacescu, Achu J. Usha, Christopher A. Wilkinson</br>Comments: Accepted to IJCNLP-AACL WASP 2025 workshop. Code available at: https://github.com/jwuphysics/automated-mission-classifier</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI, cs.DL, cs.LG</br><p>Telescope bibliographies record the pulse of astronomy research by capturing publication statistics and citation metrics for telescope facilities. Robust and scalable bibliographies ensure that we can measure the scientific impact of our facilities and archives. However, the growing rate of publications threatens to outpace our ability to manually label astronomical literature. We therefore present the Automated Mission Classifier (amc), a tool that uses large language models (LLMs) to identify and categorize telescope references by processing large quantities of paper text. A modified version of amc performs well on the TRACS Kaggle challenge, achieving a macro $F_1$ score of 0.84 on the held-out test set. amc is valuable for other telescopes beyond TRACS; we developed the initial software for identifying papers that featured scientific results by NASA missions. Additionally, we investigate how amc can also be used to interrogate historical datasets and surface potential label errors. Our work demonstrates that LLM-based applications offer powerful and scalable assistance for library sciences.</p></br><a href="https://arxiv.org/pdf/2512.11982v1"><h2>Semantic search for 100M+ galaxy images using AI-generated captions</h2></a>Authors:  Nolan Koblischke, Liam Parker, Francois Lanusse, Irina Espejo Morales, Jo Bovy, Shirley Ho</br>Comments: Presented at the NeurIPS 2025 AI4Science Workshop</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI, cs.CV, cs.LG</br><p>Finding scientifically interesting phenomena through slow, manual labeling campaigns severely limits our ability to explore the billions of galaxy images produced by telescopes. In this work, we develop a pipeline to create a semantic search engine from completely unlabeled image data. Our method leverages Vision-Language Models (VLMs) to generate descriptions for galaxy images, then contrastively aligns a pre-trained multimodal astronomy foundation model with these embedded descriptions to produce searchable embeddings at scale. We find that current VLMs provide descriptions that are sufficiently informative to train a semantic search model that outperforms direct image similarity search. Our model, AION-Search, achieves state-of-the-art zero-shot performance on finding rare phenomena despite training on randomly selected images with no deliberate curation for rare cases. Furthermore, we introduce a VLM-based re-ranking method that nearly doubles the recall for our most challenging targets in the top-100 results. For the first time, AION-Search enables flexible semantic search scalable to 140 million galaxy images, enabling discovery from previously infeasible searches. More broadly, our work provides an approach for making large, unlabeled scientific image archives semantically searchable, expanding data exploration capabilities in fields from Earth observation to microscopy. The code, data, and app are publicly available at https://github.com/NolanKoblischke/AION-Search</p></br>
