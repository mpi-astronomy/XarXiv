search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202508052000+TO+202508112000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on stat.*, cs.LG, physics.data-an, cs.AI staritng 202508052000 and ending 202508112000</h1>Feed last updated: 2025-08-11T00:00:00-04:00<a href="http://arxiv.org/pdf/2508.04982v1"><h2>Supervised Machine Learning Methods with Uncertainty Quantification for
  Exoplanet Atmospheric Retrievals from Transmission Spectroscopy</h2></a>Authors:  Roy T. Forestano, Konstantin T. Matchev, Katia Matcheva, Eyup B. Unlu</br>Comments: 51 pages, 26 figures, Submitted to AAS Journals</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG, physics.data-an</br><p>Standard Bayesian retrievals for exoplanet atmospheric parameters from
transmission spectroscopy, while well understood and widely used, are generally
computationally expensive. In the era of the JWST and other upcoming
observatories, machine learning approaches have emerged as viable alternatives
that are both efficient and robust. In this paper we present a systematic study
of several existing machine learning regression techniques and compare their
performance for retrieving exoplanet atmospheric parameters from transmission
spectra. We benchmark the performance of the different algorithms on the
accuracy, precision, and speed. The regression methods tested here include
partial least squares (PLS), support vector machines (SVM), k nearest neighbors
(KNN), decision trees (DT), random forests (RF), voting (VOTE), stacking
(STACK), and extreme gradient boosting (XGB). We also investigate the impact of
different preprocessing methods of the training data on the model performance.
We quantify the model uncertainties across the entire dynamical range of
planetary parameters. The best performing combination of ML model and
preprocessing scheme is validated on a the case study of JWST observation of
WASP-39b.</p></br><a href="http://arxiv.org/pdf/2508.05876v1"><h2>A Markov Decision Process Framework for Early Maneuver Decisions in
  Satellite Collision Avoidance</h2></a>Authors:  Francesca Ferrara, Lander W. Schillinger Arana, Florian DÃ¶rfler, Sarah H. Q. Li</br>Comments: 16 pages, 13 figures, submitted to the 2025 Astrodynamics Specialist
  Conference</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.EP, astro-ph.IM, cs.ET</br><p>This work presents a Markov decision process (MDP) framework to model
decision-making for collision avoidance maneuver (CAM) and a reinforcement
learning policy gradient (RL-PG) algorithm to train an autonomous guidance
policy using historic CAM data. In addition to maintaining acceptable collision
risks, this approach seeks to minimize the average fuel consumption of CAMs by
making early maneuver decisions. We model CAM as a continuous state, discrete
action and finite horizon MDP, where the critical decision is determining when
to initiate the maneuver. The MDP model also incorporates analytical models for
conjunction risk, propellant consumption, and transit orbit geometry. The
Markov policy effectively trades-off maneuver delay-which improves the
reliability of conjunction risk indicators-with propellant consumption-which
increases with decreasing maneuver time. Using historical data of tracked
conjunction events, we verify this framework and conduct an extensive ablation
study on the hyper-parameters used within the MDP. On synthetic conjunction
events, the trained policy significantly minimizes both the overall and average
propellant consumption per CAM when compared to a conventional cut-off policy
that initiates maneuvers 24 hours before the time of closest approach (TCA). On
historical conjunction events, the trained policy consumes more propellant
overall but reduces the average propellant consumption per CAM. For both
historical and synthetic conjunction events, the trained policy achieves equal
if not higher overall collision risk guarantees.</p></br><a href="http://arxiv.org/pdf/2508.05728v1"><h2>CLAPP: The CLASS LLM Agent for Pair Programming</h2></a>Authors:  Santiago Casas, Christian Fidler, Boris Bolliet, Francisco Villaescusa-Navarro, Julien Lesgourgues</br>Comments: Code: https://github.com/santiagocasas/clapp, Streamlit app:
  https://classclapp.streamlit.app</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.CO, cs.AI, cs.MA</br><p>We introduce CLAPP (CLASS LLM Agent for Pair Programming), an interactive AI
assistant designed to support researchers working with the Einstein-Boltzmann
solver CLASS. CLAPP leverages large language models (LLMs) and domain-specific
retrieval to provide conversational coding support for CLASS-answering
questions, generating code, debugging errors, and producing plots. Its
architecture combines multi-agent LLM orchestration, semantic search across
CLASS documentation, and a live Python execution environment. Deployed as a
user-friendly web application, CLAPP lowers the entry barrier for scientists
unfamiliar with AI tools and enables more productive human-AI collaboration in
computational and numerical cosmology. The app is available at
https://classclapp.streamlit.app</p></br><a href="http://arxiv.org/pdf/2508.05744v1"><h2>Detecting Model Misspecification in Cosmology with Scale-Dependent
  Normalizing Flows</h2></a>Authors:  Aizhan Akhmetzhanova, Carolina Cuesta-Lazaro, Siddharth Mishra-Sharma</br>Comments: 14 + 5 pages, 6 + 4 figures</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, astro-ph.IM, cs.LG</br><p>Current and upcoming cosmological surveys will produce unprecedented amounts
of high-dimensional data, which require complex high-fidelity forward
simulations to accurately model both physical processes and systematic effects
which describe the data generation process. However, validating whether our
theoretical models accurately describe the observed datasets remains a
fundamental challenge. An additional complexity to this task comes from
choosing appropriate representations of the data which retain all the relevant
cosmological information, while reducing the dimensionality of the original
dataset. In this work we present a novel framework combining scale-dependent
neural summary statistics with normalizing flows to detect model
misspecification in cosmological simulations through Bayesian evidence
estimation. By conditioning our neural network models for data compression and
evidence estimation on the smoothing scale, we systematically identify where
theoretical models break down in a data-driven manner. We demonstrate a first
application to our approach using matter and gas density fields from three
CAMELS simulation suites with different subgrid physics implementations.</p></br>
