search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202510232000+TO+202510292000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on physics.data-an, stat.*, cs.AI, cs.LG staritng 202510232000 and ending 202510292000</h1>Feed last updated: 2025-10-29T00:00:00-04:00<a href="http://arxiv.org/pdf/2510.22527v1"><h2>Multi-Modal Masked Autoencoders for Learning Image-Spectrum Associations
  for Galaxy Evolution and Cosmology</h2></a>Authors:  Morgan Himes, Samiksha Krishnamurthy, Andrew Lizarraga, Srinath Saikrishnan, Vikram Seenivasan, Jonathan Soriano, Ying Nian Wu, Tuan Do</br>Comments: 8 pages, 3 figures, 1 table, accepted to NeurIPS 2025 Workshop ML4PS</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.GA, cs.LG</br><p>Upcoming surveys will produce billions of galaxy images but comparatively few
spectra, motivating models that learn cross-modal representations. We build a
dataset of 134,533 galaxy images (HSC-PDR2) and spectra (DESI-DR1) and adapt a
Multi-Modal Masked Autoencoder (MMAE) to embed both images and spectra in a
shared representation. The MMAE is a transformer-based architecture, which we
train by masking 75% of the data and reconstructing missing image and spectral
tokens. We use this model to test three applications: spectral and image
reconstruction from heavily masked data and redshift regression from images
alone. It recovers key physical features, such as galaxy shapes, atomic
emission line peaks, and broad continuum slopes, though it struggles with fine
image details and line strengths. For redshift regression, the MMAE performs
comparably or better than prior multi-modal models in terms of prediction
scatter even when missing spectra in testing. These results highlight both the
potential and limitations of masked autoencoders in astrophysics and motivate
extensions to additional modalities, such as text, for foundation models.</p></br><a href="http://arxiv.org/pdf/2510.24159v1"><h2>Self-supervised Synthetic Pretraining for Inference of Stellar Mass
  Embedded in Dense Gas</h2></a>Authors:  Keiya Hirashima, Shingo Nozaki, Naoto Harada</br>Comments: 6 pages, 3 figures, 1 table, accepted for NeurIPS 2025 ML4PS workshop</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, astro-ph.IM, cs.AI, cs.LG</br><p>Stellar mass is a fundamental quantity that determines the properties and
evolution of stars. However, estimating stellar masses in star-forming regions
is challenging because young stars are obscured by dense gas and the regions
are highly inhomogeneous, making spherical dynamical estimates unreliable.
Supervised machine learning could link such complex structures to stellar mass,
but it requires large, high-quality labeled datasets from high-resolution
magneto-hydrodynamical (MHD) simulations, which are computationally expensive.
We address this by pretraining a vision transformer on one million synthetic
fractal images using the self-supervised framework DINOv2, and then applying
the frozen model to limited high-resolution MHD simulations. Our results
demonstrate that synthetic pretraining improves frozen-feature regression
stellar mass predictions, with the pretrained model performing slightly better
than a supervised model trained on the same limited simulations. Principal
component analysis of the extracted features further reveals semantically
meaningful structures, suggesting that the model enables unsupervised
segmentation of star-forming regions without the need for labeled data or
fine-tuning.</p></br><a href="http://arxiv.org/pdf/2510.21912v1"><h2>Analytic Marginalization over Binary Variables in Physics Data</h2></a>Authors:  Marcus Högås, Edvard Mörtsell</br>Comments: Comments are welcomme!</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, astro-ph.IM, cond-mat.stat-mech, physics.data-an</br><p>In many data analyses, each measurement may come with a simple yes/no
correction; for example, belonging to one of two populations or being
contaminated or not. Ignoring such binary effects may bias the results, while
accounting for them explicitly quickly becomes infeasible as each of the $N$
data points introduces an additional parameter, resulting in an exponentially
growing number of possible configurations ($2^N$). We show that, under generic
conditions, an exact treatment of these binary corrections leads to a
mathematical form identical to the well-known Ising model from statistical
physics. This connection opens up a powerful set of tools developed for the
Ising model, enabling fast and accurate likelihood calculations. We present
efficient approximation schemes with minimal computational cost and demonstrate
their effectiveness in applications, including Type Ia supernova calibration,
where we show that the uncertainty in host-galaxy mass classification has
negligible impact on the inferred value of the Hubble constant.</p></br><a href="http://arxiv.org/pdf/2510.22190v1"><h2>RGC: a radio AGN classifier based on deep learning. I. A semi-supervised
  model for the VLA images of bent radio AGNs</h2></a>Authors:  M. S. Hossain, M. S. H. Shahal, A. Khan, K. M. B. Asad, P. Saikia, F. Akter, A. Ali, M. A. Amin, A. Momen, M. Hasan, A. K. M. M. Rahman</br>Comments: 12 pages, 7 pages appendix, 6 figures, submitted to A&A</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.CO, cs.LG</br><p>Wide-angle tail (WAT) and narrow-angle tail (NAT) radio active galactic
nuclei (RAGNs) are key tracers of dense environments in galaxy groups and
clusters, yet no machine-learning classifier of bent RAGNs has been trained
using both unlabeled data and purely visually inspected labels. We release the
RGC Python package, which includes two newly preprocessed labeled datasets of
639 WATs and NATs derived from a publicly available catalog of visually
inspected sources, along with a semi-supervised RGC model that leverages 20,000
unlabeled RAGNs. The two labeled datasets in RGC were preprocessed using PyBDSF
which retains spurious sources, and Photutils which removes them. The RGC model
integrates the self-supervised framework BYOL (Bootstrap YOur Latent) with the
supervised E2CNN (E2-equivariant Convolutional Neural Network) to form a
semi-supervised binary classifier. The RGC model, when trained and evaluated on
a dataset devoid of spurious sources, reaches peak performance, attaining an
accuracy of 88.88% along with F1-scores of 0.90 for WATs and 0.85 for NATs. The
model's attention patterns amid class imbalance suggest that this work can
serve as a stepping stone toward developing physics-informed foundation models
capable of identifying a broad range of AGN physical properties.</p></br><a href="http://arxiv.org/pdf/2510.23702v1"><h2>In Search of the Unknown Unknowns: A Multi-Metric Distance Ensemble for
  Out of Distribution Anomaly Detection in Astronomical Surveys</h2></a>Authors:  Siddharth Chaini, Federica B. Bianco, Ashish Mahabal</br>Comments: 9 pages, 5 figures, Accepted at the 2025 Machine Learning and the
  Physical Sciences (ML4PS) workshop at NeurIPS</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.LG</br><p>Distance-based methods involve the computation of distance values between
features and are a well-established paradigm in machine learning. In anomaly
detection, anomalies are identified by their large distance from normal data
points. However, the performance of these methods often hinges on a single,
user-selected distance metric (e.g., Euclidean), which may not be optimal for
the complex, high-dimensional feature spaces common in astronomy. Here, we
introduce a novel anomaly detection method, Distance Multi-Metric Anomaly
Detection (DiMMAD), which uses an ensemble of distance metrics to find
novelties.
  Using multiple distance metrics is effectively equivalent to using different
geometries in the feature space. By using a robust ensemble of diverse distance
metrics, we overcome the metric-selection problem, creating an anomaly score
that is not reliant on any single definition of distance. We demonstrate this
multi-metric approach as a tool for simple, interpretable scientific discovery
on astronomical time series -- (1) with simulated data for the upcoming Vera C.
Rubin Observatory Legacy Survey of Space and Time, and (2) real data from the
Zwicky Transient Facility.
  We find that DiMMAD excels at out-of-distribution anomaly detection --
anomalies in the data that might be new classes -- and beats other
state-of-the-art methods in the goal of maximizing the diversity of new classes
discovered. For rare in-distribution anomaly detection, DiMMAD performs
similarly to other methods, but may allow for improved interpretability. All
our code is open source: DiMMAD is implemented within DistClassiPy:
https://github.com/sidchaini/distclassipy/, while all code to reproduce the
results of this paper is available here: https://github.com/sidchaini/dimmad/.</p></br><a href="http://arxiv.org/pdf/2510.23749v1"><h2>Re-envisioning Euclid Galaxy Morphology: Identifying and Interpreting
  Features with Sparse Autoencoders</h2></a>Authors:  John F. Wu, Michael Walmsley</br>Comments: Accepted to NeurIPS Machine Learning and the Physical Sciences
  Workshop</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.LG</br><p>Sparse Autoencoders (SAEs) can efficiently identify candidate monosemantic
features from pretrained neural networks for galaxy morphology. We demonstrate
this on Euclid Q1 images using both supervised (Zoobot) and new self-supervised
(MAE) models. Our publicly released MAE achieves superhuman image
reconstruction performance. While a Principal Component Analysis (PCA) on the
supervised model primarily identifies features already aligned with the Galaxy
Zoo decision tree, SAEs can identify interpretable features outside of this
framework. SAE features also show stronger alignment than PCA with Galaxy Zoo
labels. Although challenges in interpretability remain, SAEs provide a powerful
engine for discovering astrophysical phenomena beyond the confines of
human-defined classification.</p></br><a href="http://arxiv.org/pdf/2510.21411v1"><h2>Optimizing searches for gravitational wave bursts using coherent
  WaveBurst 2G</h2></a>Authors:  Alessandro Martini, Andrea Miani, Marco Drago, Claudia Lazzaro, Francesco Salemi, Sophie Bini, Osvaldo Freitas, Edoardo Milotti, Giacomo Principe, Shubhanshu Tiwari, Agata Trovato, Gabriele Vedovato, Yumeng Xu, Giovanni Andrea Prodi</br>Comments: No comment found</br>Primary Category: gr-qc</br>All Categories: gr-qc, astro-ph.IM, physics.data-an</br><p>The most general searches for gravitational wave transients (GWTs) rely on
data analysis methods that do not assume prior knowledge of the signal
waveform, direction, or arrival time on Earth. These searches provide
data-driven signal reconstructions that are crucial both for testing available
emission models and for discovering yet-to-be-uncovered sources. Here, we
discuss progress in the detection performance of the coherent WaveBurst
second-generation pipeline (cWB-2G), which is highly adaptable to both
minimally modeled and model-informed searches for GWTs. Several search
configurations for GWTs are examined using approximately 14.8 days of
observation time from the third observing run by LIGO-Virgo-KAGRA (LVK). Recent
enhancements include a ranking statistic fully based on multivariate
classification with eXtreme Gradient Boosting, a thorough validation of the
statistical significance accuracy of GWT candidates, and a measurement of the
correlations of false alarms and simulated detections between different
concurrent searches. For the first time, we provide a comprehensive comparison
of cWB-2G performance on data from networks made of two and three detectors,
and we demonstrate the advantage of combining concurrent searches for GWTs of
generic morphology in a global observatory. This work offers essential insights
for assessing our data analysis strategies in ongoing and future LVK searches
for generic GWTs.</p></br><a href="http://arxiv.org/pdf/2510.21022v1"><h2>CIPHER: Scalable Time Series Analysis for Physical Sciences with
  Application to Solar Wind Phenomena</h2></a>Authors:  Jasmine R. Kobayashi, Daniela Martin, Valmir P Moraes Filho, Connor O'Brien, Jinsu Hong, Sudeshna Boro Saikia, Hala Lamdouar, Nathan D. Miles, Marcella Scoczynski, Mavis Stone, Sairam Sundaresan, Anna Jungbluth, Andrés Muñoz-Jaramillo, Evangelia Samara, Joseph Gallego</br>Comments: 5 pages, 2 figures, Machine Learning and the Physical Sciences
  Workshop @ NeurIPS 2025</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.SR</br><p>Labeling or classifying time series is a persistent challenge in the physical
sciences, where expert annotations are scarce, costly, and often inconsistent.
Yet robust labeling is essential to enable machine learning models for
understanding, prediction, and forecasting. We present the \textit{Clustering
and Indexation Pipeline with Human Evaluation for Recognition} (CIPHER), a
framework designed to accelerate large-scale labeling of complex time series in
physics. CIPHER integrates \textit{indexable Symbolic Aggregate approXimation}
(iSAX) for interpretable compression and indexing, density-based clustering
(HDBSCAN) to group recurring phenomena, and a human-in-the-loop step for
efficient expert validation. Representative samples are labeled by domain
scientists, and these annotations are propagated across clusters to yield
systematic, scalable classifications. We evaluate CIPHER on the task of
classifying solar wind phenomena in OMNI data, a central challenge in space
weather research, showing that the framework recovers meaningful phenomena such
as coronal mass ejections and stream interaction regions. Beyond this case
study, CIPHER highlights a general strategy for combining symbolic
representations, unsupervised learning, and expert knowledge to address label
scarcity in time series across the physical sciences. The code and
configuration files used in this study are publicly available to support
reproducibility.</p></br><a href="http://arxiv.org/pdf/2510.21066v1"><h2>Scalable Machine Learning Analysis of Parker Solar Probe Solar Wind Data</h2></a>Authors:  Daniela Martin, Connor O'Brien, Valmir P Moraes Filho, Jinsu Hong, Jasmine R. Kobayashi, Evangelia Samara, Joseph Gallego</br>Comments: No comment found</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.SR, physics.space-ph</br><p>We present a scalable machine learning framework for analyzing Parker Solar
Probe (PSP) solar wind data using distributed processing and the
quantum-inspired Kernel Density Matrices (KDM) method. The PSP dataset
(2018--2024) exceeds 150 GB, challenging conventional analysis approaches. Our
framework leverages Dask for large-scale statistical computations and KDM to
estimate univariate and bivariate distributions of key solar wind parameters,
including solar wind speed, proton density, and proton thermal speed, as well
as anomaly thresholds for each parameter. We reveal characteristic trends in
the inner heliosphere, including increasing solar wind speed with distance from
the Sun, decreasing proton density, and the inverse relationship between speed
and density. Solar wind structures play a critical role in enhancing and
mediating extreme space weather phenomena and can trigger geomagnetic storms;
our analyses provide quantitative insights into these processes. This approach
offers a tractable, interpretable, and distributed methodology for exploring
complex physical datasets and facilitates reproducible analysis of large-scale
in situ measurements. Processed data products and analysis tools are made
publicly available to advance future studies of solar wind dynamics and space
weather forecasting. The code and configuration files used in this study are
publicly available to support reproducibility.</p></br><a href="http://arxiv.org/pdf/2510.23330v1"><h2>The First Star-by-star $N$-body/Hydrodynamics Simulation of Our Galaxy
  Coupling with a Surrogate Model</h2></a>Authors:  Keiya Hirashima, Michiko S. Fujii, Takayuki R. Saitoh, Naoto Harada, Kentaro Nomura, Kohji Yoshikawa, Yutaka Hirai, Tetsuro Asano, Kana Moriwaki, Masaki Iwasawa, Takashi Okamoto, Junichiro Makino</br>Comments: 12 pages, 7 figures, 7 tables, IEEE/ACM Supercomputing Conference
  (SC25)</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, cs.DC, cs.LG, physics.comp-ph</br><p>A major goal of computational astrophysics is to simulate the Milky Way
Galaxy with sufficient resolution down to individual stars. However, the
scaling fails due to some small-scale, short-timescale phenomena, such as
supernova explosions. We have developed a novel integration scheme of
$N$-body/hydrodynamics simulations working with machine learning. This approach
bypasses the short timesteps caused by supernova explosions using a surrogate
model, thereby improving scalability. With this method, we reached 300 billion
particles using 148,900 nodes, equivalent to 7,147,200 CPU cores, breaking
through the billion-particle barrier currently faced by state-of-the-art
simulations. This resolution allows us to perform the first star-by-star galaxy
simulation, which resolves individual stars in the Milky Way Galaxy. The
performance scales over $10^4$ CPU cores, an upper limit in the current
state-of-the-art simulations using both A64FX and X86-64 processors and NVIDIA
CUDA GPUs.</p></br>
