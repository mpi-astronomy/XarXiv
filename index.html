search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202410262000+TO+202411012000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on stat.*, physics.data-an, cs.AI, cs.LG staritng 202410262000 and ending 202411012000</h1>Feed last updated: 2024-11-01T00:00:00-04:00<a href="http://arxiv.org/pdf/2410.20839v1"><h2>Asteroid Mining: ACT&Friends' Results for the GTOC 12 Problem</h2></a>Authors:  Dario Izzo, Marcus Märtens, Laurent Beauregard, Max Bannach, Giacomo Acciarini, Emmanuel Blazquez, Alexander Hadjiivanov, Jai Grover, Gernot Heißel, Yuri Shimane, Chit Hong Yam</br>Comments: No comment found</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>In 2023, the 12th edition of Global Trajectory Competition was organised
around the problem referred to as "Sustainable Asteroid Mining". This paper
reports the developments that led to the solution proposed by ESA's Advanced
Concepts Team. Beyond the fact that the proposed approach failed to rank higher
than fourth in the final competition leader-board, several innovative
fundamental methodologies were developed which have a broader application. In
particular, new methods based on machine learning as well as on manipulating
the fundamental laws of astrodynamics were developed and able to fill with
remarkable accuracy the gap between full low-thrust trajectories and their
representation as impulsive Lambert transfers. A novel technique was devised to
formulate the challenge of optimal subset selection from a repository of
pre-existing optimal mining trajectories as an integer linear programming
problem. Finally, the fundamental problem of searching for single optimal
mining trajectories (mining and collecting all resources), albeit ignoring the
possibility of having intra-ship collaboration and thus sub-optimal in the case
of the GTOC12 problem, was efficiently solved by means of a novel search based
on a look-ahead score and thus making sure to select asteroids that had chances
to be re-visited later on.</p></br><a href="http://arxiv.org/pdf/2410.21024v1"><h2>Breccia and basalt classification of thin sections of Apollo rocks with
  deep learning</h2></a>Authors:  Freja Thoresen, Aidan Cowley, Romeo Haak, Jonas Lewe, Clara Moriceau, Piotr Knapczyk, Victoria S. Engelschiøn</br>Comments: No comment found</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>Human exploration of the moon is expected to resume in the next decade,
following the last such activities in the Apollo programme time. One of the
major objectives of returning to the Moon is to continue retrieving geological
samples, with a focus on collecting high-quality specimens to maximize
scientific return. Tools that assist astronauts in making informed decisions
about sample collection activities can maximize the scientific value of future
lunar missions. A lunar rock classifier is a tool that can potentially provide
the necessary information for astronauts to analyze lunar rock samples,
allowing them to augment in-situ value identification of samples. Towards
demonstrating the value of such a tool, in this paper, we introduce a framework
for classifying rock types in thin sections of lunar rocks. We leverage the
vast collection of petrographic thin-section images from the Apollo missions,
captured under plane-polarized light (PPL), cross-polarised light (XPL), and
reflected light at varying magnifications. Advanced machine learning methods,
including contrastive learning, are applied to analyze these images and extract
meaningful features. The contrastive learning approach fine-tunes a pre-trained
Inception-Resnet-v2 network with the SimCLR loss function. The fine-tuned
Inception-Resnet-v2 network can then extract essential features effectively
from the thin-section images of Apollo rocks. A simple binary classifier is
trained using transfer learning from the fine-tuned Inception-ResNet-v2 to
98.44\% ($\pm$1.47) accuracy in separating breccias from basalts.</p></br><a href="http://arxiv.org/pdf/2410.21477v1"><h2>Flow Matching for Atmospheric Retrieval of Exoplanets: Where Reliability
  meets Adaptive Noise Levels</h2></a>Authors:  Timothy D. Gebhard, Jonas Wildberger, Maximilian Dax, Annalena Kofler, Daniel Angerhausen, Sascha P. Quanz, Bernhard Schölkopf</br>Comments: Accepted for publication in Astronomy & Astrophysics</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.EP, cs.LG</br><p>Inferring atmospheric properties of exoplanets from observed spectra is key
to understanding their formation, evolution, and habitability. Since
traditional Bayesian approaches to atmospheric retrieval (e.g., nested
sampling) are computationally expensive, a growing number of machine learning
(ML) methods such as neural posterior estimation (NPE) have been proposed. We
seek to make ML-based atmospheric retrieval (1) more reliable and accurate with
verified results, and (2) more flexible with respect to the underlying neural
networks and the choice of the assumed noise models. First, we adopt flow
matching posterior estimation (FMPE) as a new ML approach to atmospheric
retrieval. FMPE maintains many advantages of NPE, but provides greater
architectural flexibility and scalability. Second, we use importance sampling
(IS) to verify and correct ML results, and to compute an estimate of the
Bayesian evidence. Third, we condition our ML models on the assumed noise level
of a spectrum (i.e., error bars), thus making them adaptable to different noise
models. Both our noise level-conditional FMPE and NPE models perform on par
with nested sampling across a range of noise levels when tested on simulated
data. FMPE trains about 3 times faster than NPE and yields higher IS
efficiencies. IS successfully corrects inaccurate ML results, identifies model
failures via low efficiencies, and provides accurate estimates of the Bayesian
evidence. FMPE is a powerful alternative to NPE for fast, amortized, and
parallelizable atmospheric retrieval. IS can verify results, thus helping to
build confidence in ML-based approaches, while also facilitating model
comparison via the evidence ratio. Noise level conditioning allows design
studies for future instruments to be scaled up, for example, in terms of the
range of signal-to-noise ratios.</p></br><a href="http://arxiv.org/pdf/2410.20843v1"><h2>Generative Simulations of The Solar Corona Evolution With Denoising
  Diffusion : Proof of Concept</h2></a>Authors:  Grégoire Francisco, Francesco Pio Ramunno, Manolis K. Georgoulis, João Fernandes, Teresa Barata, Dario Del Moro</br>Comments: No comment found</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, astro-ph.IM, cs.AI</br><p>The solar magnetized corona is responsible for various manifestations with a
space weather impact, such as flares, coronal mass ejections (CMEs) and,
naturally, the solar wind. Modeling the corona's dynamics and evolution is
therefore critical for improving our ability to predict space weather In this
work, we demonstrate that generative deep learning methods, such as Denoising
Diffusion Probabilistic Models (DDPM), can be successfully applied to simulate
future evolutions of the corona as observed in Extreme Ultraviolet (EUV)
wavelengths. Our model takes a 12-hour video of an Active Region (AR) as input
and simulate the potential evolution of the AR over the subsequent 12 hours,
with a time-resolution of two hours. We propose a light UNet backbone
architecture adapted to our problem by adding 1D temporal convolutions after
each classical 2D spatial ones, and spatio-temporal attention in the bottleneck
part. The model not only produce visually realistic outputs but also captures
the inherent stochasticity of the system's evolution. Notably, the simulations
enable the generation of reliable confidence intervals for key predictive
metrics such as the EUV peak flux and fluence of the ARs, paving the way for
probabilistic and interpretable space weather forecasting. Future studies will
focus on shorter forecasting horizons with increased spatial and temporal
resolution, aiming at reducing the uncertainty of the simulations and providing
practical applications for space weather forecasting. The code used for this
study is available at the following link:
https://github.com/gfrancisco20/video_diffusion</p></br><a href="http://arxiv.org/pdf/2410.20516v1"><h2>A Cosmic-Scale Benchmark for Symmetry-Preserving Data Processing</h2></a>Authors:  Julia Balla, Siddharth Mishra-Sharma, Carolina Cuesta-Lazaro, Tommi Jaakkola, Tess Smidt</br>Comments: 19 pages, 3 figures; To appear at the NeurReps Workshop @ NeurIPS
  2024</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.IM</br><p>Efficiently processing structured point cloud data while preserving
multiscale information is a key challenge across domains, from graphics to
atomistic modeling. Using a curated dataset of simulated galaxy positions and
properties, represented as point clouds, we benchmark the ability of graph
neural networks to simultaneously capture local clustering environments and
long-range correlations. Given the homogeneous and isotropic nature of the
Universe, the data exhibits a high degree of symmetry. We therefore focus on
evaluating the performance of Euclidean symmetry-preserving
($E(3)$-equivariant) graph neural networks, showing that they can outperform
non-equivariant counterparts and domain-specific information extraction
techniques in downstream performance as well as simulation-efficiency. However,
we find that current architectures fail to capture information from long-range
correlations as effectively as domain-specific baselines, motivating future
work on architectures better suited for extracting long-range information.</p></br><a href="http://arxiv.org/pdf/2410.23178v1"><h2>Uncertainty quantification for fast reconstruction methods using
  augmented equivariant bootstrap: Application to radio interferometry</h2></a>Authors:  Mostafa Cherif, Tobías I. Liaudat, Jonathan Kern, Christophe Kervazo, Jérôme Bobin</br>Comments: 13 pages, 7 figures. Accepted at the Machine Learning and the
  Physical Sciences Workshop, NeurIPS 2024</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.LG</br><p>The advent of next-generation radio interferometers like the Square Kilometer
Array promises to revolutionise our radio astronomy observational capabilities.
The unprecedented volume of data these devices generate requires fast and
accurate image reconstruction algorithms to solve the ill-posed radio
interferometric imaging problem. Most state-of-the-art reconstruction methods
lack trustworthy and scalable uncertainty quantification, which is critical for
the rigorous scientific interpretation of radio observations. We propose an
unsupervised technique based on a conformalized version of a radio-augmented
equivariant bootstrapping method, which allows us to quantify uncertainties for
fast reconstruction methods. Noticeably, we rely on reconstructions from
ultra-fast unrolled algorithms. The proposed method brings more reliable
uncertainty estimations to our problem than existing alternatives.</p></br><a href="http://arxiv.org/pdf/2410.20886v1"><h2>CODES: Benchmarking Coupled ODE Surrogates</h2></a>Authors:  Robin Janssen, Immanuel Sulzer, Tobias Buck</br>Comments: 12 pages, 10 figures, accepted for the Machine Learning and the
  Physical Sciences workshop at NeurIPS 2024, source code available on GitHub
  at https://github.com/robin-janssen/CODES-Benchmark</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.IM, physics.comp-ph</br><p>We introduce CODES, a benchmark for comprehensive evaluation of surrogate
architectures for coupled ODE systems. Besides standard metrics like mean
squared error (MSE) and inference time, CODES provides insights into surrogate
behaviour across multiple dimensions like interpolation, extrapolation, sparse
data, uncertainty quantification and gradient correlation. The benchmark
emphasizes usability through features such as integrated parallel training, a
web-based configuration generator, and pre-implemented baseline models and
datasets. Extensive documentation ensures sustainability and provides the
foundation for collaborative improvement. By offering a fair and multi-faceted
comparison, CODES helps researchers select the most suitable surrogate for
their specific dataset and application while deepening our understanding of
surrogate learning behaviour.</p></br><a href="http://arxiv.org/pdf/2410.21374v1"><h2>Model-agnostic basis functions for the 2-point correlation function of
  dark matter in linear theory</h2></a>Authors:  Aseem Paranjape, Ravi K. Sheth</br>Comments: 20 pages, 9 figures, to be submitted to JCAP. The implementation of
  the BiSequential architecture, along with a simple example notebook, is
  publicly available as part of the MLFundas repository at
  https://github.com/a-paranjape/mlfundas</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, cs.LG</br><p>We consider approximating the linearly evolved 2-point correlation function
(2pcf) of dark matter $\xi_{\rm lin}(r;\boldsymbol{\theta})$ in a cosmological
model with parameters $\boldsymbol{\theta}$ as the linear combination $\xi_{\rm
lin}(r;\boldsymbol{\theta})\approx\sum_i\,b_i(r)\,w_i(\boldsymbol{\theta})$,
where the functions $\mathcal{B}=\{b_i(r)\}$ form a $\textit{model-agnostic
basis}$ for the linear 2pcf. This decomposition is important for model-agnostic
analyses of the baryon acoustic oscillation (BAO) feature in the nonlinear 2pcf
of galaxies that fix $\mathcal{B}$ and leave the coefficients $\{w_i\}$ free.
To date, such analyses have made simple but sub-optimal choices for
$\mathcal{B}$, such as monomials. We develop a machine learning framework for
systematically discovering a $\textit{minimal}$ basis $\mathcal{B}$ that
describes $\xi_{\rm lin}(r)$ near the BAO feature in a wide class of
cosmological models. We use a custom architecture, denoted
$\texttt{BiSequential}$, for a neural network (NN) that explicitly realizes the
separation between $r$ and $\boldsymbol{\theta}$ above. The optimal NN trained
on data in which only $\{\Omega_{\rm m},h\}$ are varied in a $\textit{flat}$
$\Lambda$CDM model produces a basis $\mathcal{B}$ comprising $9$ functions
capable of describing $\xi_{\rm lin}(r)$ to $\sim0.6\%$ accuracy in
$\textit{curved}$ $w$CDM models varying 7 parameters within $\sim5\%$ of their
fiducial, flat $\Lambda$CDM values. Scales such as the peak, linear point and
zero-crossing of $\xi_{\rm lin}(r)$ are also recovered with very high accuracy.
We compare our approach to other compression schemes in the literature, and
speculate that $\mathcal{B}$ may also encompass $\xi_{\rm lin}(r)$ in modified
gravity models near our fiducial $\Lambda$CDM model. Using our basis functions
in model-agnostic BAO analyses can potentially lead to significant statistical
gains.</p></br><a href="http://arxiv.org/pdf/2410.23346v1"><h2>ASURA-FDPS-ML: Star-by-star Galaxy Simulations Accelerated by Surrogate
  Modeling for Supernova Feedback</h2></a>Authors:  Keiya Hirashima, Kana Moriwaki, Michiko S. Fujii, Yutaka Hirai, Takayuki R. Saitoh, Junnichiro Makino, Ulrich P. Steinwandel, Shirley Ho</br>Comments: 20 pages, 14 figures, 3 tables, submitted to ApJ</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, cs.AI, cs.LG</br><p>We introduce new high-resolution galaxy simulations accelerated by a
surrogate model that reduces the computation cost by approximately 75 percent.
Massive stars with a Zero Age Main Sequence mass of about 8 solar masses and
above explode as core-collapse supernovae (CCSNe), which play a critical role
in galaxy formation. The energy released by CCSNe is essential for regulating
star formation and driving feedback processes in the interstellar medium (ISM).
However, the short integration timesteps required for SNe feedback present
significant bottlenecks in star-by-star galaxy simulations that aim to capture
individual stellar dynamics and the inhomogeneous shell expansion of SNe within
the turbulent ISM. Our new framework combines direct numerical simulations and
surrogate modeling, including machine learning and Gibbs sampling. The star
formation history and the time evolution of outflow rates in the galaxy match
those obtained from resolved direct numerical simulations. Our new approach
achieves high-resolution fidelity while reducing computational costs,
effectively bridging the physical scale gap and enabling multi-scale
simulations.</p></br>
