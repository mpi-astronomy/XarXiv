search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202511262000+TO+202512022000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on physics.data-an, cs.LG, cs.AI, stat.* staritng 202511262000 and ending 202512022000</h1>Feed last updated: 2025-12-02T04:21:45Z<a href="https://arxiv.org/pdf/2512.01576v1"><h2>From Black Hole to Galaxy: Neural Operator: Framework for Accretion and Feedback Dynamics</h2></a>Authors:  Nihaal Bhojwani, Chuwei Wang, Hai-Yang Wang, Chang Sun, Elias R. Most, Anima Anandkumar</br>Comments: ML4PS Workshop, Neurips 2025 accepted</br>Primary Category: astro-ph.HE</br>All Categories: astro-ph.HE, astro-ph.GA, cs.AI, gr-qc</br><p>Modeling how supermassive black holes co-evolve with their host galaxies is notoriously hard because the relevant physics spans nine orders of magnitude in scale-from milliparsecs to megaparsecs--making end-to-end first-principles simulation infeasible. To characterize the feedback from the small scales, existing methods employ a static subgrid scheme or one based on theoretical guesses, which usually struggle to capture the time variability and derive physically faithful results. Neural operators are a class of machine learning models that achieve significant speed-up in simulating complex dynamics. We introduce a neural-operator-based ''subgrid black hole'' that learns the small-scale local dynamics and embeds it within the direct multi-level simulations. Trained on small-domain (general relativistic) magnetohydrodynamic data, the model predicts the unresolved dynamics needed to supply boundary conditions and fluxes at coarser levels across timesteps, enabling stable long-horizon rollouts without hand-crafted closures. Thanks to the great speedup in fine-scale evolution, our approach for the first time captures intrinsic variability in accretion-driven feedback, allowing dynamic coupling between the central black hole and galaxy-scale gas. This work reframes subgrid modeling in computational astrophysics with scale separation and provides a scalable path toward data-driven closures for a broad class of systems with central accretors.</p></br><a href="https://arxiv.org/pdf/2511.23073v1"><h2>Constraining dark matter halo profiles with symbolic regression</h2></a>Authors:  Alicia Mart√≠n, Tariq Yasin, Deaglan J. Bartlett, Harry Desmond, Pedro G. Ferreira</br>Comments: 18 pages, 5 figures. Accepted for publication in Philosophical Transactions of the Royal Society A</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, astro-ph.GA, astro-ph.IM, cs.LG</br><p>Dark matter haloes are typically characterised by radial density profiles with fixed forms motivated by simulations (e.g. NFW). However, simulation predictions depend on uncertain dark matter physics and baryonic modelling. Here, we present a method to constrain halo density profiles directly from observations using Exhaustive Symbolic Regression (ESR), a technique that searches the space of analytic expressions for the function that best balances accuracy and simplicity for a given dataset. We test the approach on mock weak lensing excess surface density (ESD) data of synthetic clusters with NFW profiles. Motivated by real data, we assign each ESD data point a constant fractional uncertainty and vary this uncertainty and the number of clusters to probe how data precision and sample size affect model selection. For fractional errors around 5%, ESR recovers the NFW profile even from samples as small as 20 clusters. At higher uncertainties representative of current surveys, simpler functions are favoured over NFW, though it remains competitive. This preference arises because weak lensing errors are smallest in the outskirts, causing the fits to be dominated by the outer profile. ESR therefore provides a robust, simulation-independent framework both for testing mass models and determining which features of a halo's density profile are genuinely constrained by the data.</p></br><a href="https://arxiv.org/pdf/2511.22296v1"><h2>Data-driven informative priors for Bayesian inference with quasi-periodic data</h2></a>Authors:  Javier Lopez-Santiago, Luca Martino, Joaquin Miguez, Gonzalo Vazquez-Vilar</br>Comments: Accepted for publication in AJ. 19 pages (one column), 14 figures</br>Primary Category: stat.ML</br>All Categories: stat.ML, astro-ph.IM, astro-ph.SR, cs.LG</br><p>Bayesian computational strategies for inference can be inefficient in approximating the posterior distribution in models that exhibit some form of periodicity. This is because the probability mass of the marginal posterior distribution of the parameter representing the period is usually highly concentrated in a very small region of the parameter space. Therefore, it is necessary to provide as much information as possible to the inference method through the parameter prior distribution. We intend to show that it is possible to construct a prior distribution from the data by fitting a Gaussian process (GP) with a periodic kernel. More specifically, we want to show that it is possible to approximate the marginal posterior distribution of the hyperparameter corresponding to the period in the kernel. Subsequently, this distribution can be used as a prior distribution for the inference method. We use an adaptive importance sampling method to approximate the posterior distribution of the hyperparameters of the GP. Then, we use the marginal posterior distribution of the hyperparameter related to the periodicity in order to construct a prior distribution for the period of the parametric model. This workflow is empirical Bayes, implemented as a modular (cut) transfer of a GP posterior for the period to the parametric model. We applied the proposed methodology to both synthetic and real data. We approximated the posterior distribution of the period of the GP kernel and then passed it forward as a posterior-as-prior with no feedback. Finally, we analyzed its impact on the marginal posterior distribution.</p></br><a href="https://arxiv.org/pdf/2511.22453v1"><h2>Galaxy and Mass Assembly (GAMA): The Properties of Quasar Host Galaxies: Star Formation Histories and Stellar Populations</h2></a>Authors:  Maria B. Stone, Roberto De Propris, Clare Wethers, Jari Kotilainen, Nischal Acharya, Benne Holwerda, Andrew M. Hopkins, Kevin Pimbblet</br>Comments: 23 pages, 12 figures, accepted in ApJ</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, physics.data-an, physics.space-ph</br><p>We investigated the star formation history and stellar populations of a sample of 205 Type I quasar host galaxies (0.1$<$z$<$0.35) and compared with normal (non-active) galaxies of the same mass and redshift within the volume of the Galaxy and Mass Assembly (GAMA) redshift survey. We find that quasar host galaxies tend to be star-forming galaxies ($\sim$ 80%) lying on the star-forming MS; the fraction of quasar host galaxies that are quiescent ($\sim$ 20%) is lower than the fraction of quiescent galaxies in the comparison sample of normal galaxies (54%). We find that the mean star formation rate of quasar host galaxies has increased over the past 100 Myr by a factor of 2--3, but these galaxies were star-forming at all times previously. Our data are more consistent with quasar activity originating together with an increase in the star formation rate of otherwise normal galaxies, similar to episodic star formation in normal spirals. We argue that this indicates that secular processes and minor mergers may be the favored triggers of nuclear activity in the local Universe.</p></br><a href="https://arxiv.org/pdf/2511.23228v1"><h2>SlotFlow: Amortized Trans-Dimensional Inference with Slot-Based Normalizing Flows</h2></a>Authors:  Niklas Houba, Giovanni Giarda, Lorenzo Speri</br>Comments: 58 pages, 20 figures</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, gr-qc, physics.data-an</br><p>Inferring the number of distinct components contributing to an observation, while simultaneously estimating their parameters, remains a long-standing challenge across signal processing, astrophysics, and neuroscience. Classical trans-dimensional Bayesian methods such as Reversible Jump Markov Chain Monte Carlo (RJMCMC) provide asymptotically exact inference but can be computationally expensive. Instead, modern deep learning provides a faster alternative to inference but typically assume fixed component counts, sidestepping the core challenge of trans-dimensionality. To address this, we introduce SlotFlow, a deep learning architecture for trans-dimensional amortized inference. The architecture processes time-series observations, which we represent jointly in the frequency and time domains through parallel encoders. A classifier produces a distribution over component counts K, and its MAP estimate specifies the number of slots instantiated. Each slot is parameterized by a shared conditional normalizing flow trained via permutation-invariant Hungarian matching. On sinusoidal decomposition with up to 10 overlapping components and Gaussian noise, SlotFlow achieves 99.85% cardinality accuracy and well-calibrated parameter posteriors, with systematic biases well below one posterior standard deviation. Direct comparison with RJMCMC shows close agreement in amplitude and phase, with Wasserstein distances $W_2 < 0.01$ and $< 0.03$, indicating that shared global context captures inter-component structure despite a factorized posterior. Frequency posteriors remain centered but exhibit 2-3x broader intervals, consistent with an encoder bottleneck in retaining long-baseline phase coherence. The method delivers a $\sim 10^6\times$ speedup over RJMCMC, suggesting applicability to time-critical workflows in gravitational-wave astronomy, neural spike sorting, and object-centric vision.</p></br><a href="https://arxiv.org/pdf/2512.00769v1"><h2>AI Agent for Source Finding by SoFiA-2 for SKA-SDC2</h2></a>Authors:  Xingchen Zhou, Nan Li, Peng Jia, Yingfeng Liu, Furen Deng, Shuanghao Shu, Ying Li, Liang Cao, Huanyuan Shan, Ayodeji Ibitoye</br>Comments: 20 pages, 10 figures, accepted by RAA</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.GA</br><p>Source extraction is crucial in analyzing data from next-generation, large-scale sky surveys in radio bands, such as the Square Kilometre Array (SKA). Several source extraction programs, including SoFiA and Aegean, have been developed to address this challenge. However, finding optimal parameter configurations when applying these programs to real observations is non-trivial. For example, the outcomes of SoFiA intensely depend on several key parameters across its preconditioning, source-finding, and reliability-filtering modules. To address this issue, we propose a framework to automatically optimize these parameters using an AI agent based on a state-of-the-art reinforcement learning (RL) algorithm, i.e., Soft Actor-Critic (SAC). The SKA Science Data Challenge 2 (SDC2) dataset is utilized to assess the feasibility and reliability of this framework. The AI agent interacts with the environment by adjusting parameters based on the feedback from the SDC2 score defined by the SDC2 Team, progressively learning to select parameter sets that yield improved performance. After sufficient training, the AI agent can automatically identify an optimal parameter configuration that outperform the benchmark set by Team SoFiA within only 100 evaluation steps and with reduced time consumption. Our approach could address similar problems requiring complex parameter tuning, beyond radio band surveys and source extraction. Yet, high-quality training sets containing representative observations and catalogs of ground truth are essential.</p></br>
