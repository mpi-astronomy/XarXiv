search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202503042000+TO+202503102000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, cs.LG, physics.data-an, stat.* staritng 202503042000 and ending 202503102000</h1>Feed last updated: 2025-03-10T00:00:00-04:00<a href="http://arxiv.org/pdf/2503.03982v1"><h2>Image Data Augmentation for the TAIGA-IACT Experiment with Conditional
  Generative Adversarial Networks</h2></a>Authors:  Yu. Yu. Dubenskaya, A. P. Kryukov, E. O. Gres, S. P. Polyakov, E. B. Postnikov, P. A. Volchugov, A. A. Vlaskina, D. P. Zhurov</br>Comments: 19 pages, 10 figures, Proceedings of The 8th International Conference
  on Deep Learning in Computational Physics, June 19-21, 2024, Moscow, Russia</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.HE, cs.LG</br><p>Modern Imaging Atmospheric Cherenkov Telescopes (IACTs) generate a huge
amount of data that must be classified automatically, ideally in real time.
Currently, machine learning-based solutions are increasingly being used to
solve classification problems. However, these classifiers require proper
training data sets to work correctly. The problem with training neural networks
on real IACT data is that these data need to be pre-labeled, whereas such
labeling is difficult and its results are estimates. In addition, the
distribution of incoming events is highly imbalanced. Firstly, there is an
imbalance in the types of events, since the number of detected gamma quanta is
significantly less than the number of protons. Secondly, the energy
distribution of particles of the same type is also imbalanced, since
high-energy particles are extremely rare. This imbalance results in poorly
trained classifiers that, once trained, do not handle rare events correctly.
Using only conventional Monte Carlo event simulation methods to solve this
problem is possible, but extremely resource-intensive and time-consuming. To
address this issue, we propose to perform data augmentation with artificially
generated events of the desired type and energy using conditional generative
adversarial networks (cGANs), distinguishing classes by energy values. In the
paper, we describe a simple algorithm for generating balanced data sets using
cGANs. Thus, the proposed neural network model produces both imbalanced data
sets for physical analysis as well as balanced data sets suitable for training
other neural networks.</p></br><a href="http://arxiv.org/pdf/2503.03959v1"><h2>Improving the Temporal Resolution of SOHO/MDI Magnetograms of Solar
  Active Regions Using a Deep Generative Model</h2></a>Authors:  Jialiang Li, Vasyl Yurchyshyn, Jason T. L. Wang, Haimin Wang, Yasser Abduallah, Khalid A. Alobaid, Chunhui Xu, Ruizhu Chen, Yan Xu</br>Comments: 11 pages, 7 figures</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, astro-ph.IM, cs.LG</br><p>We present a novel deep generative model, named GenMDI, to improve the
temporal resolution of line-of-sight (LOS) magnetograms of solar active regions
(ARs) collected by the Michelson Doppler Imager (MDI) on board the Solar and
Heliospheric Observatory (SOHO). Unlike previous studies that focus primarily
on spatial super-resolution of MDI magnetograms, our approach can perform
temporal super-resolution, which generates and inserts synthetic data between
observed MDI magnetograms, thus providing finer temporal structure and enhanced
details in the LOS data. The GenMDI model employs a conditional diffusion
process, which synthesizes images by considering both preceding and subsequent
magnetograms, ensuring that the generated images are not only of high-quality,
but also temporally coherent with the surrounding data. Experimental results
show that the GenMDI model performs better than the traditional linear
interpolation method, especially in ARs with dynamic evolution in magnetic
fields.</p></br><a href="http://arxiv.org/pdf/2503.04227v1"><h2>Potential of Ka-band Range Rate Post-fit Residuals for High-frequency
  Mass Change Applications</h2></a>Authors:  Michal Cuadrat-Grzybowski, Joao G. Teixeira da Encarnacao, Pieter N. A. M. Visser</br>Comments: To be later submitted to JGR: Solid Earth (AGU) later in March 2025</br>Primary Category: physics.geo-ph</br>All Categories: physics.geo-ph, astro-ph.EP, physics.ao-ph, physics.data-an</br><p>We present the first extensive analysis of K/Ka-band ranging post-fit
residuals of an official Level-2 product, characterised as Line-of-Sight
Gravity Differences (LGD), which exhibit and showcase interesting sub-monthly
geophysical signals. These residuals, provided by CSR, were derived from the
difference between spherical harmonic coefficient least-squares fits and
reduced Level-1B range-rate observations. We classified the geophysical signals
into four distinct categories: oceanic, meteorological, hydrological, and solid
Earth, focusing primarily on the first three categories in this study. In our
examination of oceanic processes, we identified notable mass anomalies in the
Argentine basin, specifically within the Zapiola Rise, where persistent
remnants of the rotating dipole-like modes are evident in the LGD post-fit
residuals. Our analysis extended to the Gulf of Carpentaria and Australia
during the 2013 Oswald cyclone, revealing significant LGD residual anomalies
that correlate with cyclone tracking and precipitation data. Additionally, we
investigated the monsoon seasons in Bangladesh, particularly from June to
September 2007, where we observed peaks in sub-monthly variability. These
findings were further validated by demonstrating high spatial and temporal
correlations between gridded LGD residuals and ITSG-Grace2018 daily solutions.
Given that these anomalies are associated with significant mass change
phenomena, it is essential to integrate the post-fit residuals into a
high-frequency mass change framework, with the purpose of providing enhanced
spatial resolution compared to conventional Kalman-filtered methods.</p></br><a href="http://arxiv.org/pdf/2503.03237v1"><h2>Prediction of Halo Coronal Mass Ejections Using SDO/HMI Vector Magnetic
  Data Products and a Transformer Model</h2></a>Authors:  Hongyang Zhang, Ju Jing, Jason T. L. Wang, Haimin Wang, Yasser Abduallah, Yan Xu, Khalid A. Alobaid, Hameedullah Farooki, Vasyl Yurchyshyn</br>Comments: 13 pages, 8 figures</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, cs.LG</br><p>We present a transformer model, named DeepHalo, to predict the occurrence of
halo coronal mass ejections (CMEs). Our model takes as input an active region
(AR) and a profile, where the profile contains a time series of data samples in
the AR that are collected 24 hours before the beginning of a day, and predicts
whether the AR would produce a halo CME during that day. Each data sample
contains physical parameters, or features, derived from photospheric vector
magnetic field data taken by the Helioseismic and Magnetic Imager (HMI) on
board the Solar Dynamics Observatory (SDO). We survey and match CME events in
the Space Weather Database Of Notification, Knowledge, Information (DONKI) and
Large Angle and Spectrometric Coronagraph (LASCO) CME Catalog, and compile a
list of CMEs including halo CMEs and non-halo CMEs associated with ARs in the
period between November 2010 and August 2023. We use the information gathered
above to build the labels (positive versus negative) of the data samples and
profiles at hand, where the labels are needed for machine learning.
Experimental results show that DeepHalo with a true skill statistics (TSS)
score of 0.907 outperforms a closely related long short-term memory network
with a TSS score of 0.821. To our knowledge, this is the first time that the
transformer model has been used for halo CME prediction.</p></br><a href="http://arxiv.org/pdf/2503.03816v1"><h2>The optical and infrared are connected</h2></a>Authors:  Christian K. Jespersen, Peter Melchior, David N. Spergel, Andy D. Goulding, ChangHoon Hahn, Kartheik G. Iyer</br>Comments: 17 pages, 14 figures. 12 pages of Appendix. Submitted to ApJ</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, cs.LG</br><p>Galaxies are often modelled as composites of separable components with
distinct spectral signatures, implying that different wavelength ranges are
only weakly correlated. They are not. We present a data-driven model which
exploits subtle correlations between physical processes to accurately predict
infrared (IR) WISE photometry from a neural summary of optical SDSS spectra.
The model achieves accuracies of $\chi^2_N \approx 1$ for all photometric bands
in WISE, as well as good colors. We are also able to tightly constrain
typically IR-derived properties, e.g. the bolometric luminosities of AGN and
dust parameters such as $\mathrm{q_{PAH}}$. We find that current SED-fitting
methods are incapable of making comparable predictions, and that model
misspecification often leads to correlated biases in star-formation rates and
AGN luminosities. To help improve SED models, we determine what features of the
optical spectrum are responsible for our improved predictions, and identify
several lines (CaII, SrII, FeI, [OII] and H$\alpha$), which point to the
complex chronology of star formation and chemical enrichment being incorrectly
modelled.</p></br><a href="http://arxiv.org/pdf/2503.03799v1"><h2>DeepGrav: Anomalous Gravitational-Wave Detection Through Deep Latent
  Features</h2></a>Authors:  Jianqi Yan, Alex P. Leung, Zhiyuan Pei, David C. Y. Hui, Sangin Kim</br>Comments: 6 pages, 3 figures, A concise introduction to the winning solution
  for NSF HDR A3D3 GW challenge. Our training code is publicly available at
  https://github.com/yan123yan/HDR-anomaly-challenge-submission</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.HE, gr-qc</br><p>This work introduces a novel deep learning-based approach for gravitational
wave anomaly detection, aiming to overcome the limitations of traditional
matched filtering techniques in identifying unknown waveform gravitational wave
signals. We introduce a modified convolutional neural network architecture
inspired by ResNet that leverages residual blocks to extract high-dimensional
features, effectively capturing subtle differences between background noise and
gravitational wave signals. This network architecture learns a high-dimensional
projection while preserving discrepancies with the original input, facilitating
precise identification of gravitational wave signals. In our experiments, we
implement an innovative data augmentation strategy that generates new data by
computing the arithmetic mean of multiple signal samples while retaining the
key features of the original signals.
  In the NSF HDR A3D3: Detecting Anomalous Gravitational Wave Signals
competition, it is honorable for us (group name: easonyan123) to get to the
first place at the end with our model achieving a true negative rate (TNR) of
0.9708 during development/validation phase and 0.9832 on an unseen challenge
dataset during final/testing phase, the highest among all competitors. These
results demonstrate that our method not only achieves excellent generalization
performance but also maintains robust adaptability in addressing the complex
uncertainties inherent in gravitational wave anomaly detection.</p></br>
