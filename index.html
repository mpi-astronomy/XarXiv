search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202409032000+TO+202409092000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, physics.data-an, stat.*, cs.LG staritng 202409032000 and ending 202409092000</h1>Feed last updated: 2024-09-09T00:00:00-04:00<a href="http://arxiv.org/pdf/2409.03466v1"><h2>Panopticon: a novel deep learning model to detect single transit events
  with no prior data filtering in PLATO light curves</h2></a>Authors:  H. G. Vivien, M. Deleuil, N. Jannsen, J. De Ridder, D. Seynaeve, M. -A. Carpine, Y. Zerah</br>Comments: Submitted to A&A</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>To prepare for the analyses of the future PLATO light curves, we develop a
deep learning model, Panopticon, to detect transits in high precision
photometric light curves. Since PLATO's main objective is the detection of
temperate Earth-size planets around solar-type stars, the code is designed to
detect individual transit events. The filtering step, required by conventional
detection methods, can affect the transit, which could be an issue for long and
shallow transits. To protect transit shape and depth, the code is also designed
to work on unfiltered light curves. We trained the model on a set of simulated
PLATO light curves in which we injected, at pixel level, either planetary,
eclipsing binary, or background eclipsing binary signals. We also include a
variety of noises in our data, such as granulation, stellar spots or cosmic
rays. The approach is able to recover 90% of our test population, including
more than 25% of the Earth-analogs, even in the unfiltered light curves. The
model also recovers the transits irrespective of the orbital period, and is
able to retrieve transits on a unique event basis. These figures are obtained
when accepting a false alarm rate of 1%. When keeping the false alarm rate low
(<0.01%), it is still able to recover more than 85% of the transit signals. Any
transit deeper than 180ppm is essentially guaranteed to be recovered. This
method is able to recover transits on a unique event basis, and does so with a
low false alarm rate. Thanks to light curves being one-dimensional, model
training is fast, on the order of a few hours per model. This speed in training
and inference, coupled to the recovery effectiveness and precision of the model
make it an ideal tool to complement, or be used ahead of, classical approaches.</p></br><a href="http://arxiv.org/pdf/2409.02980v1"><h2>How DREAMS are made: Emulating Satellite Galaxy and Subhalo Populations
  with Diffusion Models and Point Clouds</h2></a>Authors:  Tri Nguyen, Francisco Villaescusa-Navarro, Siddharth Mishra-Sharma, Carolina Cuesta-Lazaro, Paul Torrey, Arya Farahi, Alex M. Garcia, Jonah C. Rose, Stephanie O'Neil, Mark Vogelsberger, Xuejian Shen, Cian Roche, Daniel Anglés-Alcázar, Nitya Kallivayalil, Julian B. Muñoz, Francis-Yan Cyr-Racine, Sandip Roy, Lina Necib, Kassidy E. Kollmann</br>Comments: Submitted to ApJ; 30 + 6 pages; 11 + 4 figures; Comments welcomed</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, astro-ph.CO, cs.LG</br><p>The connection between galaxies and their host dark matter (DM) halos is
critical to our understanding of cosmology, galaxy formation, and DM physics.
To maximize the return of upcoming cosmological surveys, we need an accurate
way to model this complex relationship. Many techniques have been developed to
model this connection, from Halo Occupation Distribution (HOD) to empirical and
semi-analytic models to hydrodynamic. Hydrodynamic simulations can incorporate
more detailed astrophysical processes but are computationally expensive; HODs,
on the other hand, are computationally cheap but have limited accuracy. In this
work, we present NeHOD, a generative framework based on variational diffusion
model and Transformer, for painting galaxies/subhalos on top of DM with an
accuracy of hydrodynamic simulations but at a computational cost similar to
HOD. By modeling galaxies/subhalos as point clouds, instead of binning or
voxelization, we can resolve small spatial scales down to the resolution of the
simulations. For each halo, NeHOD predicts the positions, velocities, masses,
and concentrations of its central and satellite galaxies. We train NeHOD on the
TNG-Warm DM suite of the DREAMS project, which consists of 1024 high-resolution
zoom-in hydrodynamic simulations of Milky Way-mass halos with varying warm DM
mass and astrophysical parameters. We show that our model captures the complex
relationships between subhalo properties as a function of the simulation
parameters, including the mass functions, stellar-halo mass relations,
concentration-mass relations, and spatial clustering. Our method can be used
for a large variety of downstream applications, from galaxy clustering to
strong lensing studies.</p></br><a href="http://arxiv.org/pdf/2409.03833v1"><h2>AI forecasting of higher-order wave modes of spinning binary black hole
  mergers</h2></a>Authors:  Victoria Tiki, Kiet Pham, Eliu Huerta</br>Comments: 27 pages, 1 appendix, 10 figures</br>Primary Category: gr-qc</br>All Categories: gr-qc, astro-ph.IM, cs.AI, 68T10, 85-08, 83C35, 83C57, I.2</br><p>We present a physics-inspired transformer model that predicts the non-linear
dynamics of higher-order wave modes emitted by quasi-circular, spinning,
non-precessing binary black hole mergers. The model forecasts the waveform
evolution from the pre-merger phase through the ringdown, starting with an
input time-series spanning $ t \in [-5000\textrm{M}, -100\textrm{M}) $. The
merger event, defined as the peak amplitude of waveforms that include the $l =
|m| = 2$ modes, occurs at $ t = 0\textrm{M} $. The transformer then generates
predictions over the time range $ t \in [-100\textrm{M}, 130\textrm{M}] $. We
produced training, evaluation and test sets using the NRHybSur3dq8 model,
considering a signal manifold defined by mass ratios $ q \in [1, 8] $; spin
components $ s^z_{\{1,2\}} \in [-0.8, 0.8] $; modes up to $l \leq 4$, including
the $(5,5)$ mode but excluding the $(4,0)$ and $(4,1)$ modes; and inclination
angles $\theta \in [0, \pi]$. We trained the model on 14,440,761 waveforms,
completing the training in 15 hours using 16 NVIDIA A100 GPUs in the Delta
supercomputer. We used 4 H100 GPUs in the DeltaAI supercomputer to compute,
within 7 hours, the overlap between ground truth and predicted waveforms using
a test set of 840,000 waveforms, finding that the mean and median overlaps over
the test set are 0.996 and 0.997, respectively. Additionally, we conducted
interpretability studies to elucidate the waveform features utilized by our
transformer model to produce accurate predictions. The scientific software used
for this work is released with this manuscript.</p></br>
