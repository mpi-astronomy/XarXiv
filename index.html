search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202505142000+TO+202505202000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on physics.data-an, cs.LG, stat.*, cs.AI staritng 202505142000 and ending 202505202000</h1>Feed last updated: 2025-05-20T00:00:00-04:00<a href="http://arxiv.org/pdf/2505.11053v1"><h2>Conceptual framework for the application of deep neural networks to
  surface composition reconstruction from Mercury's exospheric data</h2></a>Authors:  Adrian Kazakov, Anna Milillo, Alessandro Mura, Stavro Ivanovski, Valeria Mangano, Alessandro Aronica, Elisabetta De Angelis, Pier Paolo Di Bartolomeo, Alessandro Brin, Luca Colasanti, Miguel Escalona-Moran, Francesco Lazzarotto, Stefano Massetti, Martina Moroni, Raffaella Noschese, Fabrizio Nuccilli, Stefano Orsini, Christina Plainaki, Rosanna Rispoli, Roberto Sordini, Mirko Stumpo, Nello Vertolli</br>Comments: All versions of this article can be explored in the collection: DOI
  https://doi.org/10.5281/zenodo.15394849 . This article is identical to v2.5
  of the aforementioned collection: DOI https://doi.org/10.5281/zenodo.15425584</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>Surface information derived from exospheric measurements at planetary bodies
complements surface mapping provided by dedicated imagers, offering critical
insights into surface release processes, interactions within the planetary
environment, space weathering, and planetary evolution. This study explores the
feasibility of deriving Mercury's regolith elemental composition from in-situ
measurements of its neutral exosphere using deep neural networks (DNNs). We
present a supervised feed-forward DNN architecture - a multilayer perceptron
(MLP) - that, starting from exospheric densities and proton precipitation
fluxes, predicts the chemical elements of the surface regolith below. It serves
as an estimator for the surface-exosphere interaction and the processes leading
to exosphere formation. Because the DNN requires a comprehensive exospheric
dataset not available from previous missions, this study uses simulated
exosphere components and simulated drivers. Extensive training and testing
campaigns demonstrate the MLP's ability to accurately predict and reconstruct
surface composition maps from these simulated measurements. Although this
initial version does not aim to reproduce Mercury's actual surface composition,
it provides a proof of concept, showcasing the algorithm's robustness and
capacity for handling complex datasets to create estimators for exospheric
generation models. Moreover, our tests reveal substantial potential for further
development, suggesting that this method could significantly enhance the
analysis of complex surface-exosphere interactions and complement planetary
exosphere models. This work anticipates applying the approach to data from the
BepiColombo mission, specifically the SERENA package, whose nominal phase
begins in 2027.</p></br><a href="http://arxiv.org/pdf/2505.11910v1"><h2>Improving the discovery of near-Earth objects with machine-learning
  methods</h2></a>Authors:  Peter Vere≈°, Richard Cloete, Matthew J. Payne, Abraham Loeb</br>Comments: 13 pages, 16 figures, 11 tables</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.EP, cs.LG</br><p>We present a comprehensive analysis of the digest2 parameters for candidates
of the Near-Earth Object Confirmation Page (NEOCP) that were reported between
2019 and 2024. Our study proposes methods for significantly reducing the
inclusion of non-NEO objects on the NEOCP. Despite the substantial increase in
near-Earth object (NEO) discoveries in recent years, only about half of the
NEOCP candidates are ultimately confirmed as NEOs. Therefore, much observing
time is spent following up on non-NEOs. Furthermore, approximately 11% of the
candidates remain unconfirmed because the follow-up observations are
insufficient. These are nearly 600 cases per year. To reduce false positives
and minimize wasted resources on non-NEOs, we refine the posting criteria for
NEOCP based on a detailed analysis of all digest2 scores. We investigated 30
distinct digest2 parameter categories for candidates that were confirmed as
NEOs and non-NEOs. From this analysis, we derived a filtering mechanism based
on selected digest2 parameters that were able to exclude 20% of the non-NEOs
from the NEOCP while maintaining a minimal loss of true NEOs. We also
investigated the application of four machine-learning (ML) techniques, that is,
the gradient-boosting machine (GBM), the random forest (RF) classifier, the
stochastic gradient descent (SGD) classifier, and neural networks (NN) to
classify NEOCP candidates as NEOs or non-NEOs. Based on digest2 parameters as
input, our ML models achieved a precision of approximately 95% in
distinguishing between NEOs and non-NEOs. Results. Combining the digest2
parameter filter with an ML-based classification model, we demonstrate a
significant reduction in non-NEOs on the NEOCP that exceeds 80%, while limiting
the loss of NEO discovery tracklets to 5.5%. Importantly, we show that most
follow-up tracklets of initially misclassified NEOs are later correctly
identified as NEOs.</p></br><a href="http://arxiv.org/pdf/2505.10283v1"><h2>Comparative Analysis of Richardson-Lucy Deconvolution and Data Unfolding
  with Mean Integrated Square Error Optimization</h2></a>Authors:  Nikolay D. Gagunashvili</br>Comments: 15 pages, 18 figures</br>Primary Category: physics.data-an</br>All Categories: physics.data-an, astro-ph.IM, hep-ex, nucl-ex, stat.AP, 62-07 (Primary), 62F03, 62F10, 62P35, 62P30 (Secondary)</br><p>Two maximum likelihood-based algorithms for unfolding or deconvolution are
considered: the Richardson-Lucy method and the Data Unfolding method with Mean
Integrated Square Error (MISE) optimization [10]. Unfolding is viewed as a
procedure for estimating an unknown probability density function. Both external
and internal quality assessment methods can be applied for this purpose. In
some cases, external criteria exist to evaluate deconvolution quality. A
typical example is the deconvolution of a blurred image, where the sharpness of
the restored image serves as an indicator of quality. However, defining such
external criteria can be challenging, particularly when a measurement has not
been performed previously. In such instances, internal criteria are necessary
to assess the quality of the result independently of external information. The
article discusses two internal criteria: MISE for the unfolded distribution and
the condition number of the correlation matrix of the unfolded distribution.
These internal quality criteria are applied to a comparative analysis of the
two methods using identical numerical data. The results of the analysis
demonstrate the superiority of the Data Unfolding method with MISE optimization
over the Richardson-Lucy method.</p></br><a href="http://arxiv.org/pdf/2505.10299v1"><h2>Nature-inspired optimization, the Philippine Eagle, and cosmological
  parameter estimation</h2></a>Authors:  Reginald Christian Bernardo, Erika Antonette Enriquez, Renier Mendoza, Reinabelle Reyes, Arrianne Crystal Velasco</br>Comments: 24 pages + refs, 13 figures, comments welcome</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, physics.comp-ph, physics.data-an</br><p>Precise and accurate estimation of cosmological parameters is crucial for
understanding the Universe's dynamics and addressing cosmological tensions. In
this methods paper, we explore bio-inspired metaheuristic algorithms, including
the Improved Multi-Operator Differential Evolution scheme and the Philippine
Eagle Optimization Algorithm (PEOA), alongside the relatively known genetic
algorithm, for cosmological parameter estimation. Using mock data that underlay
a true fiducial cosmology, we test the viability of each optimization method to
recover the input cosmological parameters with confidence regions generated by
bootstrapping on top of optimization. We compare the results with Markov chain
Monte Carlo (MCMC) in terms of accuracy and precision, and show that PEOA
performs comparably well under the specific circumstances provided.
Understandably, Bayesian inference and optimization serve distinct purposes,
but comparing them highlights the potential of nature-inspired algorithms in
cosmological analysis, offering alternative pathways to explore parameter
spaces and validate standard results.</p></br>
