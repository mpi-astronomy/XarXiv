search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202506052000+TO+202506112000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on physics.data-an, cs.AI, cs.LG, stat.* staritng 202506052000 and ending 202506112000</h1>Feed last updated: 2025-06-11T00:00:00-04:00<a href="http://arxiv.org/pdf/2506.05631v1"><h2>The TESS Ten Thousand Catalog: 10,001 uniformly-vetted and -validated
  Eclipsing Binary Stars detected in Full-Frame Image data by machine learning
  and analyzed by citizen scientists</h2></a>Authors:  Veselin B. Kostov, Brian P. Powell, Aline U. Fornear, Marco Z. Di Fraia, Robert Gagliano, Thomas L. Jacobs, Julien S. de Lambilly, Hugo A. Durantini Luca, Steven R. Majewski, Mark Omohundro, Jerome Orosz, Saul A. Rappaport, Ryan Salik, Donald Short, William Welsh, Svetoslav Alexandrov, Cledison Marcos da Silva, Erika Dunning, Gerd Guhne, Marc Huten, Michiharu Hyogo, Davide Iannone, Sam Lee, Christian Magliano, Manya Sharma, Allan Tarr, John Yablonsky, Sovan Acharya, Fred Adams, Thomas Barclay, Benjamin T. Montet, Susan Mullally, Greg Olmschenk, Andrej Prsa, Elisa Quintana, Robert Wilson, Hasret Balcioglu, Ethan Kruse, the Eclipsing Binary Patrol Collaboration</br>Comments: 40 pages, 39 figures, 4 tables</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, astro-ph.EP, astro-ph.IM, cs.LG</br><p>The Transiting Exoplanet Survey Satellite (TESS) has surveyed nearly the
entire sky in Full-Frame Image mode with a time resolution of 200 seconds to 30
minutes and a temporal baseline of at least 27 days. In addition to the primary
goal of discovering new exoplanets, TESS is exceptionally capable at detecting
variable stars, and in particular short-period eclipsing binaries which are
relatively common, making up a few percent of all stars, and represent powerful
astrophysical laboratories for deep investigations of stellar formation and
evolution. We combed Sectors 1-82 of TESS Full-Frame Image data searching for
eclipsing binary stars using a neural network that identified ~1.2 million
stars with eclipse-like features. Of these, we have performed an in-depth
analysis on ~60,000 targets using automated methods and manual inspection by
citizen scientists. Here we present a catalog of 10001 uniformly-vetted and
-validated eclipsing binary stars that passed all our ephemeris and photocenter
tests, as well as complementary visual inspection. Of these, 7936 are new
eclipsing binaries while the remaining 2065 are known systems for which we
update the published ephemerides. We outline the detection and analysis of the
targets, discuss the properties of the sample, and highlight potentially
interesting systems. Finally, we also provide a list of ~900,000 unvetted and
unvalidated targets for which the neural network found eclipse-like features
with a score higher than 0.9, and for which there are no known eclipsing
binaries within a sky-projected separation of a TESS pixel (~21 arcsec).</p></br><a href="http://arxiv.org/pdf/2506.08783v1"><h2>syren-baryon: Analytic emulators for the impact of baryons on the matter
  power spectrum</h2></a>Authors:  Lukas Kammerer, Deaglan J. Bartlett, Gabriel Kronberger, Harry Desmond, Pedro G. Ferreira</br>Comments: 14 pages, 6 figures. Submitted to A&A</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, astro-ph.GA, astro-ph.IM, cs.LG, cs.NE</br><p>Baryonic physics has a considerable impact on the distribution of matter in
our Universe on scales probed by current and future cosmological surveys,
acting as a key systematic in such analyses. We seek simple symbolic
parametrisations for the impact of baryonic physics on the matter power
spectrum for a range of physically motivated models, as a function of
wavenumber, redshift, cosmology, and parameters controlling the baryonic
feedback. We use symbolic regression to construct analytic approximations for
the ratio of the matter power spectrum in the presence of baryons to that
without such effects. We obtain separate functions of each of four distinct
sub-grid prescriptions of baryonic physics from the CAMELS suite of
hydrodynamical simulations (Astrid, IllustrisTNG, SIMBA and Swift-EAGLE) as
well as for a baryonification algorithm. We also provide functions which
describe the uncertainty on these predictions, due to both the stochastic
nature of baryonic physics and the errors on our fits. The error on our
approximations to the hydrodynamical simulations is comparable to the sample
variance estimated through varying initial conditions, and our baryonification
expression has a root mean squared error of better than one percent, although
this increases on small scales. These errors are comparable to those of
previous numerical emulators for these models. Our expressions are enforced to
have the physically correct behaviour on large scales and at high redshift. Due
to their analytic form, we are able to directly interpret the impact of varying
cosmology and feedback parameters, and we can identify parameters which have
little to no effect. Each function is based on a different implementation of
baryonic physics, and can therefore be used to discriminate between these
models when applied to real data. We provide publicly available code for all
symbolic approximations found.</p></br><a href="http://arxiv.org/pdf/2506.05556v1"><h2>DART-Vetter: A Deep LeARning Tool for automatic triage of exoplanet
  candidates</h2></a>Authors:  Stefano Fiscale, Laura Inno, Alessandra Rotundi, Angelo Ciaramella, Alessio Ferone, Christian Magliano, Luca Cacciapuoti, Veselin Kostov, Elisa Quintana, Giovanni Covone, Maria Teresa Muscari Tomajoli, Vito Saggese, Luca Tonietti, Antonio Vanzanella, Vincenzo Della Corte</br>Comments: Number of pages: 24, Number of figures: 8, Article accepted for
  publication in The Astronomical Journal on 2025-05-30</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>In the identification of new planetary candidates in transit surveys, the
employment of Deep Learning models proved to be essential to efficiently
analyse a continuously growing volume of photometric observations. To further
improve the robustness of these models, it is necessary to exploit the
complementarity of data collected from different transit surveys such as NASA's
Kepler, Transiting Exoplanet Survey Satellite (TESS), and, in the near future,
the ESA PLAnetary Transits and Oscillation of stars (PLATO) mission. In this
work, we present a Deep Learning model, named DART-Vetter, able to distinguish
planetary candidates (PC) from false positives signals (NPC) detected by any
potential transiting survey. DART-Vetter is a Convolutional Neural Network that
processes only the light curves folded on the period of the relative signal,
featuring a simpler and more compact architecture with respect to other
triaging and/or vetting models available in the literature. We trained and
tested DART-Vetter on several dataset of publicly available and homogeneously
labelled TESS and Kepler light curves in order to prove the effectiveness of
our model. Despite its simplicity, DART-Vetter achieves highly competitive
triaging performance, with a recall rate of 91% on an ensemble of TESS and
Kepler data, when compared to Exominer and Astronet-Triage. Its compact, open
source and easy to replicate architecture makes DART-Vetter a particularly
useful tool for automatizing triaging procedures or assisting human vetters,
showing a discrete generalization on TCEs with Multiple Event Statistic (MES) >
20 and orbital period < 50 days.</p></br><a href="http://arxiv.org/pdf/2506.06087v1"><h2>Multilevel neural simulation-based inference</h2></a>Authors:  Yuga Hikida, Ayush Bharti, Niall Jeffrey, François-Xavier Briol</br>Comments: No comment found</br>Primary Category: stat.ML</br>All Categories: stat.ML, astro-ph.CO, astro-ph.IM, cs.LG, stat.CO</br><p>Neural simulation-based inference (SBI) is a popular set of methods for
Bayesian inference when models are only available in the form of a simulator.
These methods are widely used in the sciences and engineering, where writing
down a likelihood can be significantly more challenging than constructing a
simulator. However, the performance of neural SBI can suffer when simulators
are computationally expensive, thereby limiting the number of simulations that
can be performed. In this paper, we propose a novel approach to neural SBI
which leverages multilevel Monte Carlo techniques for settings where several
simulators of varying cost and fidelity are available. We demonstrate through
both theoretical analysis and extensive experiments that our method can
significantly enhance the accuracy of SBI methods given a fixed computational
budget.</p></br><a href="http://arxiv.org/pdf/2506.08065v1"><h2>Dynamic Diffusion Schrödinger Bridge in Astrophysical Observational
  Inversions</h2></a>Authors:  Ye Zhu, Duo Xu, Zhiwei Deng, Jonathon C. Tan, Olga Russakovsky</br>Comments: Preprint. Code will be available at
  https://github.com/L-YeZhu/AstroDSB</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.LG</br><p>We study Diffusion Schr\"odinger Bridge (DSB) models in the context of
dynamical astrophysical systems, specifically tackling observational inverse
prediction tasks within Giant Molecular Clouds (GMCs) for star formation. We
introduce the Astro-DSB model, a variant of DSB with the pairwise domain
assumption tailored for astrophysical dynamics. By investigating its learning
process and prediction performance in both physically simulated data and in
real observations (the Taurus B213 data), we present two main takeaways. First,
from the astrophysical perspective, our proposed paired DSB method improves
interpretability, learning efficiency, and prediction performance over
conventional astrostatistical and other machine learning methods. Second, from
the generative modeling perspective, probabilistic generative modeling reveals
improvements over discriminative pixel-to-pixel modeling in Out-Of-Distribution
(OOD) testing cases of physical simulations with unseen initial conditions and
different dominant physical processes. Our study expands research into
diffusion models beyond the traditional visual synthesis application and
provides evidence of the models' learning abilities beyond pure data
statistics, paving a path for future physics-aware generative models which can
align dynamics between machine learning and real (astro)physical systems.</p></br><a href="http://arxiv.org/pdf/2506.08306v1"><h2>AstroCompress: A benchmark dataset for multi-purpose compression of
  astronomical data</h2></a>Authors:  Tuan Truong, Rithwik Sudharsan, Yibo Yang, Peter Xiangyuan Ma, Ruihan Yang, Stephan Mandt, Joshua S. Bloom</br>Comments: ICLR 2025 conference paper. See reviews at
  https://openreview.net/forum?id=kQCHCkNk7s</br>Primary Category: cs.AI</br>All Categories: cs.AI, astro-ph.IM</br><p>The site conditions that make astronomical observatories in space and on the
ground so desirable -- cold and dark -- demand a physical remoteness that leads
to limited data transmission capabilities. Such transmission limitations
directly bottleneck the amount of data acquired and in an era of costly modern
observatories, any improvements in lossless data compression has the potential
scale to billions of dollars worth of additional science that can be
accomplished on the same instrument. Traditional lossless methods for
compressing astrophysical data are manually designed. Neural data compression,
on the other hand, holds the promise of learning compression algorithms
end-to-end from data and outperforming classical techniques by leveraging the
unique spatial, temporal, and wavelength structures of astronomical images.
This paper introduces AstroCompress: a neural compression challenge for
astrophysics data, featuring four new datasets (and one legacy dataset) with
16-bit unsigned integer imaging data in various modes: space-based,
ground-based, multi-wavelength, and time-series imaging. We provide code to
easily access the data and benchmark seven lossless compression methods (three
neural and four non-neural, including all practical state-of-the-art
algorithms). Our results on lossless compression indicate that lossless neural
compression techniques can enhance data collection at observatories, and
provide guidance on the adoption of neural compression in scientific
applications. Though the scope of this paper is restricted to lossless
compression, we also comment on the potential exploration of lossy compression
methods in future studies.</p></br><a href="http://arxiv.org/pdf/2506.05758v1"><h2>Mapping correlations and coherence: adjacency-based approach to data
  visualization and regularity discovery</h2></a>Authors:  Guang-Xing Li</br>Comments: Code is avaliable at
  https://github.com/gxli/Adjacent-Correlation-Analysis</br>Primary Category: physics.comp-ph</br>All Categories: physics.comp-ph, astro-ph.IM, cs.LG, math.DS</br><p>The development of science has been transforming man's view towards nature
for centuries. Observing structures and patterns in an effective approach to
discover regularities from data is a key step toward theory-building. With
increasingly complex data being obtained, revealing regularities systematically
has become a challenge. Correlation is a most commonly-used and effective
approach to describe regularities in data, yet for complex patterns, spatial
inhomogeneity and complexity can often undermine the correlations. We present
an algorithm to derive maps representing the type and degree of correlations,
by taking the two-fold symmetry of the correlation vector into full account
using the Stokes parameter. The method allows for a spatially resolved view of
the nature and strength of correlations between physical quantities. In the
correlation view, a region can often be separated into different subregions
with different types of correlations. Subregions correspond to physical regimes
for physical systems, or climate zones for climate maps. The simplicity of the
method makes it widely applicable to a variety of data, where the
correlation-based approach makes the map particularly useful in revealing
regularities in physical systems and alike. As a new and efficient approach to
represent data, the method should facilitate the development of new
computational approaches to regularity discovery.</p></br><a href="http://arxiv.org/pdf/2506.05759v1"><h2>Revealing hidden correlations from complex spatial distributions:
  Adjacent Correlation Analysis</h2></a>Authors:  Guang-Xing Li</br>Comments: Code avaliable at
  https://github.com/gxli/Adjacent-Correlation-Analysis</br>Primary Category: physics.comp-ph</br>All Categories: physics.comp-ph, astro-ph.IM, cs.AI, math.DS</br><p>Physics has been transforming our view of nature for centuries. While
combining physical knowledge with computational approaches has enabled detailed
modeling of physical systems' evolution, understanding the emergence of
patterns and structures remains limited. Correlations between quantities are
the most reliable approach to describe relationships between different
variables. However, for complex patterns, directly searching for correlations
is often impractical, as complexity and spatial inhomogeneity can obscure
correlations. We discovered that the key is to search for correlations in local
regions and developed a new method, adjacent correlation analysis, to extract
such correlations and represent them in phase space. When multiple observations
are available, a useful way to study a system is to analyze distributions in
phase space using the Probability Density Function (PDF). Adjacent correlation
analysis evaluates vectors representing local correlations, which can be
overlaid on the PDF plot to form the adjacent correlation plot. These
correlation vectors often exhibit remarkably regular patterns and may lead to
the discovery of new laws. The vectors we derive are equivalent to the vector
field in dynamical systems on the attracting manifold. By efficiently
representing spatial patterns as correlation vectors in phase space, our
approach opens avenues for classification, prediction, parameter fitting, and
forecasting.</p></br><a href="http://arxiv.org/pdf/2506.05657v1"><h2>Emulating compact binary population synthesis simulations with robust
  uncertainty quantification and model comparison: Bayesian normalizing flows</h2></a>Authors:  Anarya Ray</br>Comments: 16 pages, 4 figures</br>Primary Category: astro-ph.HE</br>All Categories: astro-ph.HE, cs.LG, gr-qc</br><p>Population synthesis simulations of compact binary coalescences~(CBCs) play a
crucial role in extracting astrophysical insights from an ensemble of
gravitational wave~(GW) observations. However, realistic simulations are costly
to implement for a dense grid of initial conditions. Normalizing flows can
emulate the distribution functions of a simulated population of binary
parameters and thereby enable empirical constraints on the astrophysical
initial conditions and branching fractions of various formation channels given
data from a catalog of GW observations. They can also be used for data
amplification in sparse regions of the CBC parameter space to guide the
development of phenomenological population models for rarely synthesizable
systems with components in theorized mass gaps, without having to simulate a
prohibitively large number of binaries. But flow predictions are wrought with
uncertainties, especially for sparse training sets. In this work I develop a
method for quantifying and marginalizing uncertainties in the emulators by
introducing the Bayesian Normalizing flow, a conditional density estimator
constructed from Bayesian neural networks. Using the exact likelihood function
associated with density estimators I sample the posterior distribution of flow
parameters with suitably chosen priors to quantify and marginalize over flow
uncertainties. I demonstrate the accuracy, calibration, and data-amplification
impacts of the estimated uncertainties for simulations of binary black hole
populations formed through common envelope evolution. I outline applications of
the methodology in simulation-based inference from growing GW catalogs and
sketch other uses for general simulation-based approaches in GW astronomy.</p></br>
