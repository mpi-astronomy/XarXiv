search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202507082000+TO+202507142000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, cs.LG, stat.*, physics.data-an staritng 202507082000 and ending 202507142000</h1>Feed last updated: 2025-07-14T00:00:00-04:00<a href="http://arxiv.org/pdf/2507.07155v1"><h2>Evaluating Retrieval-Augmented Generation Agents for Autonomous
  Scientific Discovery in Astrophysics</h2></a>Authors:  Xueqing Xu, Boris Bolliet, Adrian Dimitrov, Andrew Laverick, Francisco Villaescusa-Navarro, Licong Xu, Íñigo Zubeldia</br>Comments: Accepted contribution (spotlight) to the ICML 2025 Workshop on
  Machine Learning for Astrophysics; codes:
  https://huggingface.co/datasets/ASTROANTS/CosmoPaperQA,
  https://github.com/CMBAgents/cmbagent, https://github.com/CMBAgents/scirag</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.CO, cs.AI</br><p>We evaluate 9 Retrieval Augmented Generation (RAG) agent configurations on
105 Cosmology Question-Answer (QA) pairs that we built specifically for this
purpose.The RAG configurations are manually evaluated by a human expert, that
is, a total of 945 generated answers were assessed. We find that currently the
best RAG agent configuration is with OpenAI embedding and generative model,
yielding 91.4\% accuracy. Using our human evaluation results we calibrate
LLM-as-a-Judge (LLMaaJ) system which can be used as a robust proxy for human
evaluation. These results allow us to systematically select the best RAG agent
configuration for multi-agent system for autonomous scientific discovery in
astrophysics (e.g., cmbagent presented in a companion paper) and provide us
with an LLMaaJ system that can be scaled to thousands of cosmology QA pairs. We
make our QA dataset, human evaluation results, RAG pipelines, and LLMaaJ system
publicly available for further use by the astrophysics community.</p></br>
