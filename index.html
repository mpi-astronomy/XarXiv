search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202407242000+TO+202407302000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on stat.*, physics.data-an, cs.LG, cs.AI staritng 202407242000 and ending 202407302000</h1>Feed last updated: 2024-07-30T00:00:00-04:00<a href="http://arxiv.org/pdf/2407.17667v1"><h2>Tackling the Problem of Distributional Shifts: Correcting Misspecified,
  High-Dimensional Data-Driven Priors for Inverse Problems</h2></a>Authors:  Gabriel Missael Barco, Alexandre Adam, Connor Stone, Yashar Hezaveh, Laurence Perreault-Levasseur</br>Comments: 17 pages, 15 figures, Submitted to The Astrophysical Journal</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.CO, cs.LG</br><p>Bayesian inference for inverse problems hinges critically on the choice of
priors. In the absence of specific prior information, population-level
distributions can serve as effective priors for parameters of interest. With
the advent of machine learning, the use of data-driven population-level
distributions (encoded, e.g., in a trained deep neural network) as priors is
emerging as an appealing alternative to simple parametric priors in a variety
of inverse problems. However, in many astrophysical applications, it is often
difficult or even impossible to acquire independent and identically distributed
samples from the underlying data-generating process of interest to train these
models. In these cases, corrupted data or a surrogate, e.g. a simulator, is
often used to produce training samples, meaning that there is a risk of
obtaining misspecified priors. This, in turn, can bias the inferred posteriors
in ways that are difficult to quantify, which limits the potential
applicability of these models in real-world scenarios. In this work, we propose
addressing this issue by iteratively updating the population-level
distributions by retraining the model with posterior samples from different
sets of observations and showcase the potential of this method on the problem
of background image reconstruction in strong gravitational lensing when
score-based models are used as data-driven priors. We show that starting from a
misspecified prior distribution, the updated distribution becomes progressively
closer to the underlying population-level distribution, and the resulting
posterior samples exhibit reduced bias after several updates.</p></br><a href="http://arxiv.org/pdf/2407.19481v1"><h2>What can we learn about Reionization astrophysical parameters using
  Gaussian Process Regression?</h2></a>Authors:  Purba Mukherjee, Antara Dey, Supratik Pal</br>Comments: No comment found</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, astro-ph.IM, cs.LG</br><p>Reionization is one of the least understood processes in the evolution
history of the Universe, mostly because of the numerous astrophysical processes
occurring simultaneously about which we do not have a very clear idea so far.
In this article, we use the Gaussian Process Regression (GPR) method to learn
the reionization history and infer the astrophysical parameters. We reconstruct
the UV luminosity density function using the HFF and early JWST data. From the
reconstructed history of reionization, the global differential brightness
temperature fluctuation during this epoch has been computed. We perform MCMC
analysis of the global 21-cm signal using the instrumental specifications of
SARAS, in combination with Lyman-$\alpha$ ionization fraction data, Planck
optical depth measurements and UV luminosity data. Our analysis reveals that
GPR can help infer the astrophysical parameters in a model-agnostic way than
conventional methods. Additionally, we analyze the 21-cm power spectrum using
the reconstructed history of reionization and demonstrate how the future 21-cm
mission SKA, in combination with Planck and Lyman-$\alpha$ forest data,
improves the bounds on the reionization astrophysical parameters by doing a
joint MCMC analysis for the astrophysical parameters plus 6 cosmological
parameters for $\Lambda$CDM model. The results make the GPR-based
reconstruction technique a robust learning process and the inferences on the
astrophysical parameters obtained therefrom are quite reliable that can be used
for future analysis.</p></br><a href="http://arxiv.org/pdf/2407.19048v1"><h2>Rapid Likelihood Free Inference of Compact Binary Coalescences using
  Accelerated Hardware</h2></a>Authors:  Deep Chatterjee, Ethan Marx, William Benoit, Ravi Kumar, Malina Desai, Ekaterina Govorkova, Alec Gunny, Eric Moreno, Rafia Omer, Ryan Raikman, Muhammed Saleem, Shrey Aggarwal, Michael W. Coughlin, Philip Harris, Erik Katsavounidis</br>Comments: Submitted to MLST</br>Primary Category: gr-qc</br>All Categories: gr-qc, astro-ph.IM, cs.LG</br><p>We report a gravitational-wave parameter estimation algorithm, AMPLFI, based
on likelihood-free inference using normalizing flows. The focus of AMPLFI is to
perform real-time parameter estimation for candidates detected by
machine-learning based compact binary coalescence search, Aframe. We present
details of our algorithm and optimizations done related to data-loading and
pre-processing on accelerated hardware. We train our model using binary
black-hole (BBH) simulations on real LIGO-Virgo detector noise. Our model has
$\sim 6$ million trainable parameters with training times $\lesssim 24$ hours.
Based on online deployment on a mock data stream of LIGO-Virgo data, Aframe +
AMPLFI is able to pick up BBH candidates and infer parameters for real-time
alerts from data acquisition with a net latency of $\sim 6$s.</p></br><a href="http://arxiv.org/pdf/2407.18647v1"><h2>Towards unveiling the large-scale nature of gravity with the wavelet
  scattering transform</h2></a>Authors:  Georgios Valogiannis, Francisco Villaescusa-Navarro, Marco Baldi</br>Comments: 19 pages, 15 figures, 1 table</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, gr-qc, hep-ph, physics.data-an</br><p>We present the first application of the Wavelet Scattering Transform (WST) in
order to constrain the nature of gravity using the three-dimensional (3D)
large-scale structure of the universe. Utilizing the Quijote-MG N-body
simulations, we can reliably model the 3D matter overdensity field for the f(R)
Hu-Sawicki modified gravity (MG) model down to $k_{\rm max}=0.5$ h/Mpc.
Combining these simulations with the Quijote $\nu$CDM collection, we then
conduct a Fisher forecast of the marginalized constraints obtained on gravity
using the WST coefficients and the matter power spectrum at redshift z=0. Our
results demonstrate that the WST substantially improves upon the 1$\sigma$
error obtained on the parameter that captures deviations from standard General
Relativity (GR), yielding a tenfold improvement compared to the corresponding
matter power spectrum result. At the same time, the WST also enhances the
precision on the $\Lambda$CDM parameters and the sum of neutrino masses, by
factors of 1.2-3.4 compared to the matter power spectrum, respectively. Despite
the overall reduction in the WST performance when we focus on larger scales, it
still provides a relatively $4.5\times$ tighter 1$\sigma$ error for the MG
parameter at $k_{\rm max}=0.2$ h/Mpc, highlighting its great sensitivity to the
underlying gravity theory. This first proof-of-concept study reaffirms the
constraining properties of the WST technique and paves the way for exciting
future applications in order to perform precise large-scale tests of gravity
with the new generation of cutting-edge cosmological data.</p></br><a href="http://arxiv.org/pdf/2407.18909v1"><h2>Hybrid summary statistics: neural weak lensing inference beyond the
  power spectrum</h2></a>Authors:  T. Lucas Makinen, Alan Heavens, Natalia Porqueres, Tom Charnock, Axel Lapel, Benjamin D. Wandelt</br>Comments: 16 pages, 11 figures. Submitted to JCAP. We provide publicly
  available code at https://github.com/tlmakinen/hybridStatsWL</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, cs.LG, physics.comp-ph, stat.ML, stat.OT</br><p>In inference problems, we often have domain knowledge which allows us to
define summary statistics that capture most of the information content in a
dataset. In this paper, we present a hybrid approach, where such physics-based
summaries are augmented by a set of compressed neural summary statistics that
are optimised to extract the extra information that is not captured by the
predefined summaries. The resulting statistics are very powerful inputs to
simulation-based or implicit inference of model parameters. We apply this
generalisation of Information Maximising Neural Networks (IMNNs) to parameter
constraints from tomographic weak gravitational lensing convergence maps to
find summary statistics that are explicitly optimised to complement angular
power spectrum estimates. We study several dark matter simulation resolutions
in low- and high-noise regimes. We show that i) the information-update
formalism extracts at least $3\times$ and up to $8\times$ as much information
as the angular power spectrum in all noise regimes, ii) the network summaries
are highly complementary to existing 2-point summaries, and iii) our formalism
allows for networks with smaller, physically-informed architectures to match
much larger regression networks with far fewer simulations needed to obtain
asymptotically optimal inference.</p></br>
