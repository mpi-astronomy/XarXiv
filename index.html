search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202512112000+TO+202512172000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on stat.*, cs.LG, cs.AI, physics.data-an staritng 202512112000 and ending 202512172000</h1>Feed last updated: 2025-12-17T04:24:06Z<a href="https://arxiv.org/pdf/2512.11202v1"><h2>amc: The Automated Mission Classifier for Telescope Bibliographies</h2></a>Authors:  John F. Wu, Joshua E. G. Peek, Sophie J. Miller, Jenny Novacescu, Achu J. Usha, Christopher A. Wilkinson</br>Comments: Accepted to IJCNLP-AACL WASP 2025 workshop. Code available at: https://github.com/jwuphysics/automated-mission-classifier</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI, cs.DL, cs.LG</br><p>Telescope bibliographies record the pulse of astronomy research by capturing publication statistics and citation metrics for telescope facilities. Robust and scalable bibliographies ensure that we can measure the scientific impact of our facilities and archives. However, the growing rate of publications threatens to outpace our ability to manually label astronomical literature. We therefore present the Automated Mission Classifier (amc), a tool that uses large language models (LLMs) to identify and categorize telescope references by processing large quantities of paper text. A modified version of amc performs well on the TRACS Kaggle challenge, achieving a macro $F_1$ score of 0.84 on the held-out test set. amc is valuable for other telescopes beyond TRACS; we developed the initial software for identifying papers that featured scientific results by NASA missions. Additionally, we investigate how amc can also be used to interrogate historical datasets and surface potential label errors. Our work demonstrates that LLM-based applications offer powerful and scalable assistance for library sciences.</p></br><a href="https://arxiv.org/pdf/2512.11982v1"><h2>Semantic search for 100M+ galaxy images using AI-generated captions</h2></a>Authors:  Nolan Koblischke, Liam Parker, Francois Lanusse, Irina Espejo Morales, Jo Bovy, Shirley Ho</br>Comments: Presented at the NeurIPS 2025 AI4Science Workshop</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI, cs.CV, cs.LG</br><p>Finding scientifically interesting phenomena through slow, manual labeling campaigns severely limits our ability to explore the billions of galaxy images produced by telescopes. In this work, we develop a pipeline to create a semantic search engine from completely unlabeled image data. Our method leverages Vision-Language Models (VLMs) to generate descriptions for galaxy images, then contrastively aligns a pre-trained multimodal astronomy foundation model with these embedded descriptions to produce searchable embeddings at scale. We find that current VLMs provide descriptions that are sufficiently informative to train a semantic search model that outperforms direct image similarity search. Our model, AION-Search, achieves state-of-the-art zero-shot performance on finding rare phenomena despite training on randomly selected images with no deliberate curation for rare cases. Furthermore, we introduce a VLM-based re-ranking method that nearly doubles the recall for our most challenging targets in the top-100 results. For the first time, AION-Search enables flexible semantic search scalable to 140 million galaxy images, enabling discovery from previously infeasible searches. More broadly, our work provides an approach for making large, unlabeled scientific image archives semantically searchable, expanding data exploration capabilities in fields from Earth observation to microscopy. The code, data, and app are publicly available at https://github.com/NolanKoblischke/AION-Search</p></br>
