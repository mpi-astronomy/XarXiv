search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202410312000+TO+202411062000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on stat.*, cs.AI, physics.data-an, cs.LG staritng 202410312000 and ending 202411062000</h1>Feed last updated: 2024-11-05T00:00:00-05:00<a href="http://arxiv.org/pdf/2411.02653v1"><h2>Deep operator neural network applied to efficient computation of
  asteroid surface temperature and the Yarkovsky effect</h2></a>Authors:  Shunjing Zhao, Hanlun Lei, Xian Shi</br>Comments: accepted for publication in "Astronomy & Astrophysics"</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>Surface temperature distribution is crucial for thermal property-based
studies about irregular asteroids in our Solar System. While direct numerical
simulations could model surface temperatures with high fidelity, they often
take a significant amount of computational time, especially for problems where
temperature distributions are required to be repeatedly calculated. To this
end, deep operator neural network (DeepONet) provides a powerful tool due to
its high computational efficiency and generalization ability. In this work, we
applied DeepONet to the modelling of asteroid surface temperatures. Results
show that the trained network is able to predict temperature with an accuracy
of ~1% on average, while the computational cost is five orders of magnitude
lower, hence enabling thermal property analysis in a multidimensional parameter
space. As a preliminary application, we analyzed the orbital evolution of
asteroids through direct N-body simulations embedded with instantaneous
Yarkovsky effect inferred by DeepONet-based thermophysical modelling.Taking
asteroids (3200) Phaethon and (89433) 2001 WM41 as examples, we show the
efficacy and efficiency of our AI-based approach.</p></br><a href="http://arxiv.org/pdf/2411.03186v1"><h2>Insights into Lunar Mineralogy: An Unsupervised Approach for Clustering
  of the Moon Mineral Mapper (M3) spectral data</h2></a>Authors:  Freja Thoresen, Igor Drozdovskiy, Aidan Cowley, Magdelena Laban, Sebastien Besse, Sylvain Blunier</br>Comments: No comment found</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>This paper presents a novel method for mapping spectral features of the Moon
using machine learning-based clustering of hyperspectral data from the Moon
Mineral Mapper (M3) imaging spectrometer. The method uses a convolutional
variational autoencoder to reduce the dimensionality of the spectral data and
extract features of the spectra. Then, a k-means algorithm is applied to
cluster the latent variables into five distinct groups, corresponding to
dominant spectral features, which are related to the mineral composition of the
Moon's surface. The resulting global spectral cluster map shows the
distribution of the five clusters on the Moon, which consist of a mixture of,
among others, plagioclase, pyroxene, olivine, and Fe-bearing minerals across
the Moon's surface. The clusters are compared to the mineral maps from the
Kaguya mission, which showed that the locations of the clusters overlap with
the locations of high wt% of minerals such as plagioclase, clinopyroxene, and
olivine. The paper demonstrates the usefulness of unbiased unsupervised
learning for lunar mineral exploration and provides a comprehensive analysis of
lunar mineralogy.</p></br><a href="http://arxiv.org/pdf/2411.02656v1"><h2>High-pass Filter Periodogram: An Improved Power Spectral Density
  Estimator for Unevenly Sampled Data</h2></a>Authors:  Ezequiel Albentosa-Ruiz, Nicola Marchili</br>Comments: No comment found</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, physics.data-an</br><p>Accurate time series analysis is essential for studying variable astronomical
sources, where detecting periodicities and characterizing power spectral
density (PSD) are crucial. The Lomb-Scargle periodogram, commonly used in
astronomy for analyzing unevenly sampled time series data, often suffers from
noise introduced by irregular sampling. This paper presents a new high-pass
filter (HPF) periodogram, a novel implementation designed to mitigate this
sampling-induced noise. By applying a frequency-dependent high-pass filter
before computing the periodogram, the HPF method enhances the precision of PSD
estimates and periodicity detection across a wide range of signal
characteristics. Simulations and comparisons with the Lomb-Scargle periodogram
demonstrate that the HPF periodogram improves accuracy and reliability under
challenging sampling conditions, making it a valuable complementary tool for
more robust time series analysis in astronomy and other fields dealing with
unevenly sampled data.</p></br><a href="http://arxiv.org/pdf/2411.00991v1"><h2>Re-thinking Richardson-Lucy without Iteration Cutoffs: Physically
  Motivated Bayesian Deconvolution</h2></a>Authors:  Zachary H. Hendrix, Peter T. Brown, Tim Flanagan, Douglas P. Shepherd, Ayush Saurabh, Steve Press√©</br>Comments: 5 figures</br>Primary Category: cs.CV</br>All Categories: cs.CV, astro-ph.IM, physics.bio-ph, physics.data-an, physics.optics</br><p>Richardson-Lucy deconvolution is widely used to restore images from
degradation caused by the broadening effects of a point spread function and
corruption by photon shot noise, in order to recover an underlying object. In
practice, this is achieved by iteratively maximizing a Poisson emission
likelihood. However, the RL algorithm is known to prefer sparse solutions and
overfit noise, leading to high-frequency artifacts. The structure of these
artifacts is sensitive to the number of RL iterations, and this parameter is
typically hand-tuned to achieve reasonable perceptual quality of the inferred
object. Overfitting can be mitigated by introducing tunable regularizers or
other ad hoc iteration cutoffs in the optimization as otherwise incorporating
fully realistic models can introduce computational bottlenecks. To resolve
these problems, we present Bayesian deconvolution, a rigorous deconvolution
framework that combines a physically accurate image formation model avoiding
the challenges inherent to the RL approach. Our approach achieves deconvolution
while satisfying the following desiderata:
  I deconvolution is performed in the spatial domain (as opposed to the
frequency domain) where all known noise sources are accurately modeled and
integrated in the spirit of providing full probability distributions over the
density of the putative object recovered;
  II the probability distribution is estimated without making assumptions on
the sparsity or continuity of the underlying object;
  III unsupervised inference is performed and converges to a stable solution
with no user-dependent parameter tuning or iteration cutoff;
  IV deconvolution produces strictly positive solutions; and
  V implementation is amenable to fast, parallelizable computation.</p></br>
