search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202508012000+TO+202508072000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.LG, cs.AI, stat.*, physics.data-an staritng 202508012000 and ending 202508072000</h1>Feed last updated: 2025-08-07T00:00:00-04:00<a href="http://arxiv.org/pdf/2508.03661v1"><h2>Automated Algorithmic Discovery for Gravitational-Wave Detection Guided
  by LLM-Informed Evolutionary Monte Carlo Tree Search</h2></a>Authors:  He Wang, Liang Zeng</br>Comments: 89 pages (37 main), 6+6 figures, 1 table. Initial submission; subject
  to revision</br>Primary Category: cs.AI</br>All Categories: cs.AI, astro-ph.HE, astro-ph.IM, gr-qc</br><p>Computational scientific discovery increasingly relies on algorithms to
process complex data and identify meaningful patterns - yet faces persistent
challenges in gravitational-wave signal identification. While existing
algorithmic approaches like matched filtering (MF) and deep neural networks
(DNNs) have achieved partial success, their limitations directly stem from
fundamental limitations: MF's excessive computational demands arise from its
reliance on predefined theoretical waveform templates, while DNNs' black-box
architectures obscure decision logic and introduce hidden biases. We propose
Evolutionary Monte Carlo Tree Search (Evo-MCTS), a framework that addresses
these limitations through systematic algorithm space exploration guided by
domain-aware physical constraints. Our approach combines tree-structured search
with evolutionary optimization and large language model heuristics to create
interpretable algorithmic solutions. Our Evo-MCTS framework demonstrates
substantial improvements, achieving a 20.2\% improvement over state-of-the-art
gravitational wave detection algorithms on the MLGWSC-1 benchmark dataset.
High-performing algorithm variants consistently exceed thresholds. The
framework generates human-interpretable algorithmic pathways that reveal
distinct performance patterns. Beyond performance improvements, our framework
discovers novel algorithmic combinations, thereby establishing a transferable
methodology for automated algorithmic discovery across computational science
domains.</p></br><a href="http://arxiv.org/pdf/2508.02602v1"><h2>Trustworthy scientific inference for inverse problems with generative
  models</h2></a>Authors:  James Carzon, Luca Masserano, Joshua D. Ingram, Alex Shen, Antonio Carlos Herling Ribeiro Junior, Tommaso Dorigo, Michele Doro, Joshua S. Speagle, Rafael Izbicki, Ann B. Lee</br>Comments: No comment found</br>Primary Category: stat.ML</br>All Categories: stat.ML, astro-ph.IM, cs.LG, stat.AP, stat.ME</br><p>Generative artificial intelligence (AI) excels at producing complex data
structures (text, images, videos) by learning patterns from training examples.
Across scientific disciplines, researchers are now applying generative models
to ``inverse problems'' to infer hidden parameters from observed data. While
these methods can handle intractable models and large-scale studies, they can
also produce biased or overconfident conclusions. We present a solution with
Frequentist-Bayes (FreB), a mathematically rigorous protocol that reshapes
AI-generated probability distributions into confidence regions that
consistently include true parameters with the expected probability, while
achieving minimum size when training and target data align. We demonstrate
FreB's effectiveness by tackling diverse case studies in the physical sciences:
identifying unknown sources under dataset shift, reconciling competing
theoretical models, and mitigating selection bias and systematics in
observational studies. By providing validity guarantees with interpretable
diagnostics, FreB enables trustworthy scientific inference across fields where
direct likelihood evaluation remains impossible or prohibitively expensive.</p></br>
