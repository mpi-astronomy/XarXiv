search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202512172000+TO+202512232000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.LG, physics.data-an, stat.*, cs.AI staritng 202512172000 and ending 202512232000</h1>Feed last updated: 2025-12-23T04:29:49Z<a href="https://arxiv.org/pdf/2512.19386v1"><h2>Machine learning for the early classification of broad-lined Ic supernovae</h2></a>Authors:  Laura Cotter, Antonio Martin Carrillo, Joseph Fisher, Gabriel Finneran, Gregory Corcoran, Jennifer Lebron</br>Comments: There are 10 pages and 8 figures (2 individual figures and 3 where there are 2 subfigures)</br>Primary Category: astro-ph.HE</br>All Categories: astro-ph.HE, physics.data-an</br><p>Science is currently at an age where there is more data than we know how to deal with. Machine learning (ML) is an emerging tool that is useful in drawing valuable science out of incomprehensibly large datasets, identifying complex trends in data that are otherwise overlooked. Moreover, ML can potentially enhance the quality and quantity of scientific data as it is collected. This paper explores how a new ML method can improve the rate of classification of rare Ic-BL supernovae (SNe). New parameters called magnitude rates were introduced to train ML models to identify SNe Ic-BL in large datasets. The same methodology was applied to a population of SN Ia transients to see if the methodology could be reproducible with another SN class. Three magnitudes, three time differences, two magnitude rates and the second derivative of these rates were calculated using the first three available photometric data points in a single filter. Initial investigations show that the Random Forest algorithm provides a strong foundation for the early classifications SNe Ic-BL and SNe Ia. Testing this model again on an unseen dataset shows that the model can identify upward of 13% of the total true SN Ic-BL population, significantly improving upon current methods. By implementing a dedicated observation campaign using this model, the number of SN Ic-BL classified and the quality of early-time data collected each year will see considerable growth in the near future.</p></br><a href="https://arxiv.org/pdf/2512.16175v1"><h2>Physics-Informed Neural Networks for Modeling the Martian Induced Magnetosphere</h2></a>Authors:  Jiawei Gao, Chuanfei Dong, Chi Zhang, Yilan Qin, Simin Shekarpaz, Xinmin Li, Liang Wang, Hongyang Zhou, Abigail Tadlock</br>Comments: No comment found</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, cs.LG, physics.space-ph</br><p>Understanding the magnetic field environment around Mars and its response to upstream solar wind conditions provide key insights into the processes driving atmospheric ion escape. To date, global models of Martian induced magnetosphere have been exclusively physics-based, relying on computationally intensive simulations. For the first time, we develop a data-driven model of the Martian induced magnetospheric magnetic field using Physics-Informed Neural Network (PINN) combined with MAVEN observations and physical laws. Trained under varying solar wind conditions, including B_IMF, P_SW, and Î¸_cone, the data-driven model accurately reconstructs the three-dimensional magnetic field configuration and its variability in response to upstream solar wind drivers. Based on the PINN results, we identify key dependencies of magnetic field configuration on solar wind parameters, including the hemispheric asymmetries of the draped field line strength in the Mars-Solar-Electric coordinates. These findings demonstrate the capability of PINNs to reconstruct complex magnetic field structures in the Martian induced magnetosphere, thereby offering a promising tool for advancing studies of solar wind-Mars interactions.</p></br><a href="https://arxiv.org/pdf/2512.16051v1"><h2>Graph Neural Networks for Interferometer Simulations</h2></a>Authors:  Sidharth Kannan, Pooyan Goodarzi, Evangelos E. Papalexakis, Jonathan W. Richardson</br>Comments: No comment found</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.LG</br><p>In recent years, graph neural networks (GNNs) have shown tremendous promise in solving problems in high energy physics, materials science, and fluid dynamics. In this work, we introduce a new application for GNNs in the physical sciences: instrumentation design. As a case study, we apply GNNs to simulate models of the Laser Interferometer Gravitational-Wave Observatory (LIGO) and show that they are capable of accurately capturing the complex optical physics at play, while achieving runtimes 815 times faster than state of the art simulation packages. We discuss the unique challenges this problem provides for machine learning models. In addition, we provide a dataset of high-fidelity optical physics simulations for three interferometer topologies, which can be used as a benchmarking suite for future work in this direction.</p></br><a href="https://arxiv.org/pdf/2512.18290v1"><h2>Robust and scalable simulation-based inference for gravitational wave signals with gaps</h2></a>Authors:  Ruiting Mao, Jeong Eun Lee, Matthew C. Edwards</br>Comments: 28 pages, 13 figures</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, gr-qc, physics.data-an, physics.ins-det</br><p>The Laser Interferometer Space Antenna (LISA) data stream will inevitably contain gaps due to maintenance and environmental disturbances, introducing nonstationarities and spectral leakage that compromise standard frequency-domain likelihood evaluations. We present a scalable Simulation-Based Inference (SBI) framework capable of robust parameter estimation directly from gapped time-series data. We employ Flow Matching Posterior Estimation (FMPE) conditioned on a learned summary of the data, optimized through an end-to-end training strategy. To address the computational challenges of long-duration signals, we propose a dual-pathway summarizer architecture: a 1D Convolutional Neural Network (CNN) operating on the time domain for high precision, and a novel wavelet-based 2D CNN utilizing asymmetric, dilated kernels to achieve scalability for datasets spanning months. We demonstrate the efficacy of this framework on simulated Galactic Binary-like signals, showing that our joint training approach yields tighter, unbiased posteriors compared to two-stage reconstruction pipelines. Furthermore, we provide the first systematic comparison showing that FMPE offers superior stability and coverage calibration over conventional Normalizing Flows in the presence of severe data artifacts.</p></br>
