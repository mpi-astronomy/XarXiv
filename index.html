search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202602142000+TO+202602202000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, physics.data-an, stat.*, cs.LG staritng 202602142000 and ending 202602202000</h1>Feed last updated: 2026-02-20T05:11:13Z<a href="https://arxiv.org/pdf/2602.15021v1"><h2>Generalization from Low- to Moderate-Resolution Spectra with Neural Networks for Stellar Parameter Estimation: A Case Study with DESI</h2></a>Authors:  Xiaosheng Zhao, Yuan-Sen Ting, Rosemary F. G. Wyse, Alexander S. Szalay, Yang Huang, László Dobos, Tamás Budavári, Viska Wei</br>Comments: 20 pages, 13 figures, 4 tables. Submitted to AAS journals. Comments welcome</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, astro-ph.GA, cs.LG</br><p>Cross-survey generalization is a critical challenge in stellar spectral analysis, particularly in cases such as transferring from low- to moderate-resolution surveys. We investigate this problem using pre-trained models, focusing on simple neural networks such as multilayer perceptrons (MLPs), with a case study transferring from LAMOST low-resolution spectra (LRS) to DESI medium-resolution spectra (MRS). Specifically, we pre-train MLPs on either LRS or their embeddings and fine-tune them for application to DESI stellar spectra. We compare MLPs trained directly on spectra with those trained on embeddings derived from transformer-based models (self-supervised foundation models pre-trained for multiple downstream tasks). We also evaluate different fine-tuning strategies, including residual-head adapters, LoRA, and full fine-tuning. We find that MLPs pre-trained on LAMOST LRS achieve strong performance, even without fine-tuning, and that modest fine-tuning with DESI spectra further improves the results. For iron abundance, embeddings from a transformer-based model yield advantages in the metal-rich ([Fe/H] > -1.0) regime, but underperform in the metal-poor regime compared to MLPs trained directly on LRS. We also show that the optimal fine-tuning strategy depends on the specific stellar parameter under consideration. These results highlight that simple pre-trained MLPs can provide competitive cross-survey generalization, while the role of spectral foundation models for cross-survey stellar parameter estimation requires further exploration.</p></br><a href="https://arxiv.org/pdf/2602.15780v1"><h2>Deep Learning for Point Spread Function Modeling in Cosmology</h2></a>Authors:  Dayana Andrea Henao Arbeláez, Pierre-François Léget, Andrés Alejandro Plazas Malagón</br>Comments: Published in Revista eSpectra (Observatorio Astronómico Nacional de Colombia; https://espectra.astronomiaoan.co/revista-espectra-ediciones.html). Research conducted as part of the RECA Internship Program 2025 (https://www.astroreca.org/en/internship)</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.CO, physics.data-an</br><p>We present the development of a data-driven, AI-based model of the Point Spread Function (PSF) that achieves higher accuracy than the current state-of-the-art approach, "PSF in the Full Field-of-View'' (PIFF). PIFF is widely used in leading weak-lensing surveys, including the Dark Energy Survey (DES), the Hyper Suprime-Cam (HSC) Survey, and the Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST). The PSF characterizes how a point source, such as a star, is imaged after its light traverses the atmosphere and telescope optics, effectively representing the "blurred fingerprint'' of the entire imaging system. Accurate PSF modeling is essential for weak gravitational lensing analyses, as biases in its estimation propagate directly into cosmic shear measurements -- one of the primary cosmological probes of the expansion history of the Universe and the growth of large-scale structure for dark energy studies. To address the limitations of PIFF, which constructs PSF models independently for each CCD and therefore loses spatial coherence across the focal plane, we introduce a deep-learning-based framework for PSF reconstruction. In this approach, an autoencoder is trained on stellar images obtained with the Hyper Suprime-Cam (HSC) of the Subaru Telescope and combined with a Gaussian process to interpolate the PSF across the telescope's full field of view. This hybrid model captures systematic variations across the focal plane and achieves a reconstruction error of $3.4 \times 10^{-6}$ compared to PIFF's $3.7 \times 10^{-6}$, laying the foundation for integration into the LSST Science Pipelines.</p></br><a href="https://arxiv.org/pdf/2602.15296v1"><h2>GPS constellation search for exotic physics messengers coincident with the binary neutron star merger GW170817</h2></a>Authors:  Arko P. Sen, Geoffrey Blewitt, Andrey Sarantsev, Paul Ries, Andrei Derevianko</br>Comments: No comment found</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.HE, physics.atom-ph, physics.data-an, physics.ins-det</br><p>The Global Positioning System (GPS) includes a continuously operating, planet-scale network of atomic clocks that, beyond navigation and time dissemination, enables precision tests of fundamental physics. Here we use GPS carrier phase archival data to perform a retrospective search for exotic low-mass fields (ELFs) that might be emitted by the binary neutron-star merger GW170817, complementing gravitational wave and electromagnetic modalitiesnin multi-messenger astronomy. Such ultra-relativistic fields would imprint a dispersive, anti-chirp signature in clock-frequency time series, delayed with respect to the LIGO-Virgo gravitational wave detection. We construct network-median pseudo-frequency data from eighteen Rb satellite clocks referenced to a terrestrial hydrogen maser and conduct a template-bank search spanning ELF pulse duration, arrival delay, and characteristic frequency. No statistically significant signal is observed after accounting for noise statistics and template-bank trials. We derive 95\% confidence-level lower bounds on the interaction energy scale $Λ_α$ of quadratic couplings driving variations in electromagnetic fine-structure constant. These limits improve upon existing astrophysical and gravity-test constraints across the ELF-energy range $\approx10^{-18}$--$10^{-14}\,\mathrm{eV}$. This demonstrates that mature global satellite-clock networks provide an observational capability for retrospective, multi-messenger searches for new physics using decades of archival timing data.</p></br><a href="https://arxiv.org/pdf/2602.17205v1"><h2>Deeper detection limits in astronomical imaging using self-supervised spatiotemporal denoising</h2></a>Authors:  Yuduo Guo, Hao Zhang, Mingyu Li, Fujiang Yu, Yunjing Wu, Yuhan Hao, Song Huang, Yongming Liang, Xiaojing Lin, Xinyang Li, Jiamin Wu, Zheng Cai, Qionghai Dai</br>Comments: Published in Science. This is the author's version of the work. It is posted here by permission of the AAAS for personal use, not for redistribution</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.CO, astro-ph.GA, cs.AI</br><p>The detection limit of astronomical imaging observations is limited by several noise sources. Some of that noise is correlated between neighbouring image pixels and exposures, so in principle could be learned and corrected. We present an astronomical self-supervised transformer-based denoising algorithm (ASTERIS), that integrates spatiotemporal information across multiple exposures. Benchmarking on mock data indicates that ASTERIS improves detection limits by 1.0 magnitude at 90% completeness and purity, while preserving the point spread function and photometric accuracy. Observational validation using data from the James Webb Space Telescope (JWST) and Subaru telescope identifies previously undetectable features, including low-surface-brightness galaxy structures and gravitationally-lensed arcs. Applied to deep JWST images, ASTERIS identifies three times more redshift > 9 galaxy candidates, with rest-frame ultraviolet luminosity 1.0 magnitude fainter, than previous methods.</p></br><a href="https://arxiv.org/pdf/2602.15088v1"><h2>IT-DPC-SRI: A Cloud-Optimized Archive of Italian Radar Precipitation (2010-2025)</h2></a>Authors:  Gabriele Franch, Elena Tomasi, Uladzislau Azhel, Giacomo Tomezzoli, Alessandro Camilletti, Virginia Poli, Renata Pelosini, Gianfranco Vulpiani, Gabriella Scipione, Giuseppe Trotta, Matteo Angelinelli, Leif Denby, Irene Livia Kruse, Marco Cristoforetti</br>Comments: 15 pages, 7 figures</br>Primary Category: physics.ao-ph</br>All Categories: physics.ao-ph, astro-ph.IM, cs.LG</br><p>We present IT-DPC-SRI, the first publicly available long-term archive of Italian weather radar precipitation estimates, spanning 16 years (2010--2025). The dataset contains Surface Rainfall Intensity (SRI) observations from the Italian Civil Protection Department's national radar mosaic, harmonized into a coherent Analysis-Ready Cloud-Optimized (ARCO) Zarr datacube. The archive comprises over one million timesteps at temporal resolutions from 15 to 5 minutes, covering a $1200\times1400$ kilometer domain at 1 kilometer spatial resolution, compressed from 7TB to 51GB on disk. We address the historical fragmentation of Italian radar data - previously scattered across heterogeneous formats (OPERA BUFR, HDF5, GeoTIFF) with varying spatial domains and projections - by reprocessing the entire record into a unified store. The dataset is accessible as a static versioned snapshot on Zenodo, via cloud-native access on the ECMWF European Weather Cloud, and as a continuously updated live version on the ArcoDataHub platform. This release fills a significant gap in European radar data availability, as Italy does not participate in the EUMETNET OPERA pan-European radar composite. The dataset is released under a CC BY-SA 4.0 license.</p></br><a href="https://arxiv.org/pdf/2602.16264v1"><h2>Prediction of Major Solar Flares Using Interpretable Class-dependent Reward Framework with Active Region Magnetograms and Domain Knowledge</h2></a>Authors:  Zixian Wu, Xuebao Li, Yanfang Zheng, Rui Wang, Shunhuang Zhang, Jinfang Wei, Yongshang Lv, Liang Dong, Zamri Zainal Abidin, Noraisyah Mohamed Shah, Hongwei Ye, Pengchao Yan, Xuefeng Li, Xiaojia Ji, Xusheng Huang, Xiaotian Wang, Honglei Jin</br>Comments: 24 pages,12 figures</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.SR</br><p>In this work, we develop, for the first time, a supervised classification framework with class-dependent rewards (CDR) to predict $\geq$MM flares within 24 hr. We construct multiple datasets, covering knowledge-informed features and line-of sight (LOS) magnetograms. We also apply three deep learning models (CNN, CNN-BiLSTM, and Transformer) and three CDR counterparts (CDR-CNN, CDR-CNN-BiLSTM, and CDR-Transformer). First, we analyze the importance of LOS magnetic field parameters with the Transformer, then compare its performance using LOS-only, vector-only, and combined magnetic field parameters. Second, we compare flare prediction performance based on CDR models versus deep learning counterparts. Third, we perform sensitivity analysis on reward engineering for CDR models. Fourth, we use the SHAP method for model interpretability. Finally, we conduct performance comparison between our models and NASA/CCMC. The main findings are: (1)Among LOS feature combinations, R_VALUE and AREA_ACR consistently yield the best results. (2)Transformer achieves better performance with combined LOS and vector magnetic field data than with either alone. (3)Models using knowledge-informed features outperform those using magnetograms. (4)While CNN and CNN-BiLSTM outperform their CDR counterparts on magnetograms, CDR-Transformer is slightly superior to its deep learning counterpart when using knowledge-informed features. Among all models, CDR-Transformer achieves the best performance. (5)The predictive performance of the CDR models is not overly sensitive to the reward choices.(6)Through SHAP analysis, the CDR model tends to regard TOTUSJH as more important, while the Transformer tends to prioritize R_VALUE more.(7)Under identical prediction time and active region (AR) number, the CDR-Transformer shows superior predictive capabilities compared to NASA/CCMC.</p></br><a href="https://arxiv.org/pdf/2602.16656v1"><h2>Investigating Nonlinear Quenching Effects on Polar Field Buildup in the Sun Using Physics-Informed Neural Networks</h2></a>Authors:  Jithu J. Athalathil, Mohammed H. Talafha, Bhargav Vaidya</br>Comments: Accepted for publication in The Astrophysical Journal</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, cs.LG</br><p>The solar dynamo relies on the regeneration of the poloidal magnetic field through processes strongly modulated by nonlinear feedbacks such as tilt quenching (TQ) and latitude quenching (LQ). These mechanisms play a decisive role in regulating the buildup of the Sun's polar field and, in turn, the amplitude of future solar cycles. In this work, we employ Physics-Informed Neural Networks (PINN) to solve the surface flux transport (SFT) equation, embedding physical constraints directly into the neural network framework. By systematically varying transport parameters, we isolate the relative contributions of TQ and LQ to polar dipole buildup. We use the residual dipole moment as a diagnostic for cycle-to-cycle amplification and show that TQ suppression strengthens with increasing diffusivity, while LQ dominates in advection-dominated regimes. The ratio $ΔD_{\mathrm{LQ}}/ΔD_{\mathrm{TQ}}$ exhibits a smooth inverse-square dependence on the dynamo effectivity range, refining previous empirical fits with improved accuracy and reduced scatter. The results further reveal that the need for a decay term is not essential for PINN set-up due to the training process. Compared with the traditional 1D SFT model, the PINN framework achieves significantly lower error metrics and more robust recovery of nonlinear trends. Our results suggest that the nonlinear interplay between LQ and TQ can naturally produce alternations between weak and strong cycles, providing a physical explanation for the observed even-odd cycle modulation. These findings demonstrate the potential of PINN as an accurate, efficient, and physically consistent tool for solar cycle prediction.</p></br><a href="https://arxiv.org/pdf/2602.15951v1"><h2>MadEvolve: Evolutionary Optimization of Cosmological Algorithms with Large Language Models</h2></a>Authors:  Tianyi Li, Shihui Zang, Moritz Münchmeyer</br>Comments: No comment found</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, cs.LG</br><p>We develop a general framework to discover scientific algorithms and apply it to three problems in computational cosmology. Our code, MadEvolve, is similar to Google's AlphaEvolve, but places a stronger emphasis on free parameters and their optimization. Our code starts with a baseline human algorithm implementation, and then optimizes its performance metrics by making iterative changes to its code. As a further convenient feature, MadEvolve automatically generates a report that compares the input algorithm with the evolved algorithm, describes the algorithmic innovations and lists the free parameters and their function. Our code supports both auto-differentiable, gradient-based parameter optimization and gradient-free optimization methods. We apply MadEvolve to the reconstruction of cosmological initial conditions, 21cm foreground contamination reconstruction and effective baryonic physics in N-body simulations. In all cases, we find substantial improvements over the base algorithm. We make MadEvolve and our three tasks publicly available at madevolve.org.</p></br>
