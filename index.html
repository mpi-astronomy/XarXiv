search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202501312000+TO+202502062000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, cs.LG, stat.*, physics.data-an staritng 202501312000 and ending 202502062000</h1>Feed last updated: 2025-02-05T00:00:00-05:00<a href="http://arxiv.org/pdf/2502.01500v1"><h2>Gamma/hadron separation in the TAIGA experiment with neural network
  methods</h2></a>Authors:  E. O. Gres, A. P. Kryukov, P. A. Volchugov, J. J. Dubenskaya, D. P. Zhurov, S. P. Polyakov, E. B. Postnikov, A. A. Vlaskina</br>Comments: 7 pages, 5 figures, Proceedings of The 8th International Conference
  on Deep Learning in Computational Physics, June 19-21, 2024, Moscow, Russia</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.HE, cs.LG</br><p>In this work, the ability of rare VHE gamma ray selection with neural network
methods is investigated in the case when cosmic radiation flux strongly
prevails (ratio up to {10^4} over the gamma radiation flux from a point
source). This ratio is valid for the Crab Nebula in the TeV energy range, since
the Crab is a well-studied source for calibration and test of various methods
and installations in gamma astronomy. The part of TAIGA experiment which
includes three Imaging Atmospheric Cherenkov Telescopes observes this
gamma-source too. Cherenkov telescopes obtain images of Extensive Air Showers.
Hillas parameters can be used to analyse images in standard processing method,
or images can be processed with convolutional neural networks. In this work we
would like to describe the main steps and results obtained in the gamma/hadron
separation task from the Crab Nebula with neural network methods. The results
obtained are compared with standard processing method applied in the TAIGA
collaboration and using Hillas parameter cuts. It is demonstrated that a signal
was received at the level of higher than 5.5{\sigma} in 21 hours of Crab Nebula
observations after processing the experimental data with the neural network
method.</p></br><a href="http://arxiv.org/pdf/2502.03139v1"><h2>Fast Sampling of Cosmological Initial Conditions with Gaussian Neural
  Posterior Estimation</h2></a>Authors:  Oleg Savchenko, Guillermo Franco Abellán, Florian List, Noemi Anau Montel, Christoph Weniger</br>Comments: 9 + 2 pages, 7 figures, 1 table. Comments welcome!</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, astro-ph.IM, cs.LG</br><p>Knowledge of the primordial matter density field from which the large-scale
structure of the Universe emerged over cosmic time is of fundamental importance
for cosmology. However, reconstructing these cosmological initial conditions
from late-time observations is a notoriously difficult task, which requires
advanced cosmological simulators and sophisticated statistical methods to
explore a multi-million-dimensional parameter space. We show how
simulation-based inference (SBI) can be used to tackle this problem and to
obtain data-constrained realisations of the primordial dark matter density
field in a simulation-efficient way with general non-differentiable simulators.
Our method is applicable to full high-resolution dark matter $N$-body
simulations and is based on modelling the posterior distribution of the
constrained initial conditions to be Gaussian with a diagonal covariance matrix
in Fourier space. As a result, we can generate thousands of posterior samples
within seconds on a single GPU, orders of magnitude faster than existing
methods, paving the way for sequential SBI for cosmological fields.
Furthermore, we perform an analytical fit of the estimated dependence of the
covariance on the wavenumber, effectively transforming any point-estimator of
initial conditions into a fast sampler. We test the validity of our obtained
samples by comparing them to the true values with summary statistics and
performing a Bayesian consistency test.</p></br><a href="http://arxiv.org/pdf/2502.01510v1"><h2>Grid-based exoplanet atmospheric mass loss predictions through neural
  network</h2></a>Authors:  Amit Reza, Daria Kubyshkina, Luca Fossati, Christiane Helling</br>Comments: Accepted for publication on A&A</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, cs.LG</br><p>The fast and accurate estimation of planetary mass-loss rates is critical for
planet population and evolution modelling. We use machine learning (ML) for
fast interpolation across an existing large grid of hydrodynamic upper
atmosphere models, providing mass-loss rates for any planet inside the grid
boundaries with superior accuracy compared to previously published
interpolation schemes. We consider an already available grid comprising about
11000 hydrodynamic upper atmosphere models for training and generate an
additional grid of about 250 models for testing purposes. We develop the ML
interpolation scheme (dubbed "atmospheric Mass Loss INquiry frameworK"; MLink)
using a Dense Neural Network, further comparing the results with what was
obtained employing classical approaches (e.g. linear interpolation and radial
basis function-based regression). Finally, we study the impact of the different
interpolation schemes on the evolution of a small sample of carefully selected
synthetic planets. MLink provides high-quality interpolation across the entire
parameter space by significantly reducing both the number of points with large
interpolation errors and the maximum interpolation error compared to previously
available schemes. For most cases, evolutionary tracks computed employing MLink
and classical schemes lead to comparable planetary parameters at
Gyr-timescales. However, particularly for planets close to the top edge of the
radius gap, the difference between the predicted planetary radii at a given age
of tracks obtained employing MLink and classical interpolation schemes can
exceed the typical observational uncertainties. Machine learning can be
successfully used to estimate atmospheric mass-loss rates from model grids
paving the way to explore future larger and more complex grids of models
computed accounting for more physical processes.</p></br><a href="http://arxiv.org/pdf/2502.00243v1"><h2>A Fast Periodicity Detection Algorithm Sensitive to Arbitrary Waveforms</h2></a>Authors:  Douglas P. Finkbeiner, Thomas A. Prince, Samuel E. Whitebook</br>Comments: 17 pages, 7 figures, code attached</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, physics.data-an</br><p>A reexamination of period finding algorithms is prompted by new large area
astronomical sky surveys that can identify billions of individual sources
having a thousand or more observations per source. This large increase in data
necessitates fast and efficient period detection algorithms. In this paper, we
provide an initial description of an algorithm that is being used for detection
of periodic behavior in a sample of 1.5 billion objects using light curves
generated from Zwicky Transient Facility (ZTF) data (Bellm et al. 2019; Masci
et al. 2018). We call this algorithm "Fast Periodicity Weighting" (FPW),
derived using a Gaussian Process (GP) formalism. A major advantage of the FPW
algorithm for ZTF analysis is that it is agnostic to the details of the
phase-folded waveform. Periodic sources in ZTF show a wide variety of
waveforms, some quite complex, including eclipsing objects, sinusoidally
varying objects also exhibiting eclipses, objects with cyclotron emission at
various phases, and accreting objects with complex waveforms. We describe the
FPW algorithm and its application to ZTF, and provide efficient code for both
CPU and GPU.</p></br><a href="http://arxiv.org/pdf/2502.02717v1"><h2>Astromer 2</h2></a>Authors:  Cristobal Donoso-Oliva, Ignacio Becker, Pavlos Protopapas, Guillermo Cabrera-Vives, Martina Cádiz-Leyton, Daniel Moreno-Cartagena</br>Comments: 10 pages, 17 figures</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI, cs.LG</br><p>Foundational models have emerged as a powerful paradigm in deep learning
field, leveraging their capacity to learn robust representations from
large-scale datasets and effectively to diverse downstream applications such as
classification. In this paper, we present Astromer 2 a foundational model
specifically designed for extracting light curve embeddings. We introduce
Astromer 2 as an enhanced iteration of our self-supervised model for light
curve analysis. This paper highlights the advantages of its pre-trained
embeddings, compares its performance with that of its predecessor, Astromer 1,
and provides a detailed empirical analysis of its capabilities, offering deeper
insights into the model's representations. Astromer 2 is pretrained on 1.5
million single-band light curves from the MACHO survey using a self-supervised
learning task that predicts randomly masked observations within sequences.
Fine-tuning on a smaller labeled dataset allows us to assess its performance in
classification tasks. The quality of the embeddings is measured by the F1 score
of an MLP classifier trained on Astromer-generated embeddings. Our results
demonstrate that Astromer 2 significantly outperforms Astromer 1 across all
evaluated scenarios, including limited datasets of 20, 100, and 500 samples per
class. The use of weighted per-sample embeddings, which integrate intermediate
representations from Astromer's attention blocks, is particularly impactful.
Notably, Astromer 2 achieves a 15% improvement in F1 score on the ATLAS dataset
compared to prior models, showcasing robust generalization to new datasets.
This enhanced performance, especially with minimal labeled data, underscores
the potential of Astromer 2 for more efficient and scalable light curve
analysis.</p></br><a href="http://arxiv.org/pdf/2502.01929v1"><h2>Exploring blazars through sonification. Visual and auditory insights
  into multifrequency variability</h2></a>Authors:  Gustavo Magallanes-Guijón, Sergio Mendoza</br>Comments: 12 pages, 9 figures</br>Primary Category: astro-ph.HE</br>All Categories: astro-ph.HE, physics.data-an, physics.soc-ph</br><p>Using open astronomical multifrequency databases, we constructed light curves
and developed a comprehensive visualisation and sonification analysis for the
blazars Mrk~501, Mrk~1501, Mrk~421, BL~Lacerta, AO~0235+164, 3C~66A, OJ~049,
OJ~287, and PKS~J2134-0153. This study employed Musical Instrument Digital
Interface (MIDI) and Parameter Mapping Sonification (PMSon) techniques to
generate waveforms, spectrograms, and sonifications. These representations
demonstrate that data visualisation and sonification are powerful tools for
analysing astronomical objects like blazers, providing insights into their
multifrequency variability. This work highlights how sonification and
visualisation can aid in identifying potential patterns, power variations,
regularities, and gaps in the data. This multimodal approach also underscores
the importance of inclusivity in scientific communication, offering accessible
methods for exploring the complex behaviour of blazers.</p></br>
