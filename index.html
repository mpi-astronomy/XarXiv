search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202510082000+TO+202510142000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, stat.*, cs.LG, physics.data-an staritng 202510082000 and ending 202510142000</h1>Feed last updated: 2025-10-14T00:00:00-04:00<a href="http://arxiv.org/pdf/2510.10713v1"><h2>Deep Learning in Astrophysics</h2></a>Authors:  Yuan-Sen Ting</br>Comments: Manuscript submitted to Annual Review of Astronomy and Astrophysics
  for Volume 64. This is the authors' version. Revisions and the final version
  will be available at https://www.annualreviews.org/content/journals/astro</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.CO, astro-ph.EP, astro-ph.GA, astro-ph.HE, cs.AI</br><p>Deep learning has generated diverse perspectives in astronomy, with ongoing
discussions between proponents and skeptics motivating this review. We examine
how neural networks complement classical statistics, extending our data
analytical toolkit for modern surveys. Astronomy offers unique opportunities
through encoding physical symmetries, conservation laws, and differential
equations directly into architectures, creating models that generalize beyond
training data. Yet challenges persist as unlabeled observations number in
billions while confirmed examples with known properties remain scarce and
expensive. This review demonstrates how deep learning incorporates domain
knowledge through architectural design, with built-in assumptions guiding
models toward physically meaningful solutions. We evaluate where these methods
offer genuine advances versus claims requiring careful scrutiny. - Neural
architectures overcome trade-offs between scalability, expressivity, and data
efficiency by encoding physical symmetries and conservation laws into network
structure, enabling learning from limited labeled data. - Simulation-based
inference and anomaly detection extract information from complex, non-Gaussian
distributions where analytical likelihoods fail, enabling field-level
cosmological analysis and systematic discovery of rare phenomena. - Multi-scale
neural modeling bridges resolution gaps in astronomical simulations, learning
effective subgrid physics from expensive high-fidelity runs to enhance
large-volume calculations where direct computation remains prohibitive. -
Emerging paradigms-reinforcement learning for telescope operations, foundation
models learning from minimal examples, and large language model agents for
research automation-show promise though are still developing in astronomical
applications.</p></br><a href="http://arxiv.org/pdf/2510.08766v1"><h2>Understanding Exoplanet Habitability: A Bayesian ML Framework for
  Predicting Atmospheric Absorption Spectra</h2></a>Authors:  Vasuda Trehan, Kevin H. Knuth, M. J. Way</br>Comments: No comment found</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>The evolution of space technology in recent years, fueled by advancements in
computing such as Artificial Intelligence (AI) and machine learning (ML), has
profoundly transformed our capacity to explore the cosmos. Missions like the
James Webb Space Telescope (JWST) have made information about distant objects
more easily accessible, resulting in extensive amounts of valuable data. As
part of this work-in-progress study, we are working to create an atmospheric
absorption spectrum prediction model for exoplanets. The eventual model will be
based on both collected observational spectra and synthetic spectral data
generated by the ROCKE-3D general circulation model (GCM) developed by the
climate modeling program at NASA's Goddard Institute for Space Studies (GISS).
In this initial study, spline curves are used to describe the bin heights of
simulated atmospheric absorption spectra as a function of one of the values of
the planetary parameters. Bayesian Adaptive Exploration is then employed to
identify areas of the planetary parameter space for which more data are needed
to improve the model. The resulting system will be used as a forward model so
that planetary parameters can be inferred given a planet's atmospheric
absorption spectrum. This work is expected to contribute to a better
understanding of exoplanetary properties and general exoplanet climates and
habitability.</p></br><a href="http://arxiv.org/pdf/2510.11242v1"><h2>Analyzing Data Quality and Decay in Mega-Constellations: A
  Physics-Informed Machine Learning Approach</h2></a>Authors:  Katarina Dyreby, Francisco Caldas, Cl√°udia Soares</br>Comments: 76th International Astronautical Congress</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>In the era of mega-constellations, the need for accurate and publicly
available information has become fundamental for satellite operators to
guarantee the safety of spacecrafts and the Low Earth Orbit (LEO) space
environment. This study critically evaluates the accuracy and reliability of
publicly available ephemeris data for a LEO mega-constellation - Starlink. The
goal of this work is twofold: (i) compare and analyze the quality of the data
against high-precision numerical propagation. (ii) Leverage Physics-Informed
Machine Learning to extract relevant satellite quantities, such as
non-conservative forces, during the decay process. By analyzing two months of
real orbital data for approximately 1500 Starlink satellites, we identify
discrepancies between high precision numerical algorithms and the published
ephemerides, recognizing the use of simplified dynamics at fixed thresholds,
planned maneuvers, and limitations in uncertainty propagations. Furthermore, we
compare data obtained from multiple sources to track and analyze deorbiting
satellites over the same period. Empirically, we extract the acceleration
profile of satellites during deorbiting and provide insights relating to the
effects of non-conservative forces during reentry. For non-deorbiting
satellites, the position Root Mean Square Error (RMSE) was approximately 300 m,
while for deorbiting satellites it increased to about 600 m. Through this
in-depth analysis, we highlight potential limitations in publicly available
data for accurate and robust Space Situational Awareness (SSA), and
importantly, we propose a data-driven model of satellite decay in
mega-constellations.</p></br><a href="http://arxiv.org/pdf/2510.09362v1"><h2>deep-REMAP: Probabilistic Parameterization of Stellar Spectra Using
  Regularized Multi-Task Learning</h2></a>Authors:  Sankalp Gilda</br>Comments: 14 pages. Accepted for publication in RASTI</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.SR, cs.AI</br><p>In the era of exploding survey volumes, traditional methods of spectroscopic
analysis are being pushed to their limits. In response, we develop deep-REMAP,
a novel deep learning framework that utilizes a regularized, multi-task
approach to predict stellar atmospheric parameters from observed spectra. We
train a deep convolutional neural network on the PHOENIX synthetic spectral
library and use transfer learning to fine-tune the model on a small subset of
observed FGK dwarf spectra from the MARVELS survey. We then apply the model to
732 uncharacterized FGK giant candidates from the same survey. When validated
on 30 MARVELS calibration stars, deep-REMAP accurately recovers the effective
temperature ($T_{\rm{eff}}$), surface gravity ($\log \rm{g}$), and metallicity
([Fe/H]), achieving a precision of, for instance, approximately 75 K in
$T_{\rm{eff}}$. By combining an asymmetric loss function with an embedding
loss, our regression-as-classification framework is interpretable, robust to
parameter imbalances, and capable of capturing non-Gaussian uncertainties.
While developed for MARVELS, the deep-REMAP framework is extensible to other
surveys and synthetic libraries, demonstrating a powerful and automated pathway
for stellar characterization.</p></br><a href="http://arxiv.org/pdf/2510.08317v1"><h2>Iterated Agent for Symbolic Regression</h2></a>Authors:  Zhuo-Yang Song, Zeyu Cai, Shutao Zhang, Jiashen Wei, Jichen Pan, Shi Qiu, Qing-Hong Cao, Tie-Jiun Hou, Xiaohui Liu, Ming-xing Luo, Hua Xing Zhu</br>Comments: 45 pages, 22 figures, 8 tables</br>Primary Category: physics.comp-ph</br>All Categories: physics.comp-ph, astro-ph.IM, cs.AI, cs.LG, hep-ph</br><p>Symbolic regression (SR), the automated discovery of mathematical expressions
from data, is a cornerstone of scientific inquiry. However, it is often
hindered by the combinatorial explosion of the search space and a tendency to
overfit. Popular methods, rooted in genetic programming, explore this space
syntactically, often yielding overly complex, uninterpretable models. This
paper introduces IdeaSearchFitter, a framework that employs Large Language
Models (LLMs) as semantic operators within an evolutionary search. By
generating candidate expressions guided by natural-language rationales, our
method biases discovery towards models that are not only accurate but also
conceptually coherent and interpretable. We demonstrate IdeaSearchFitter's
efficacy across diverse challenges: it achieves competitive, noise-robust
performance on the Feynman Symbolic Regression Database (FSReD), outperforming
several strong baselines; discovers mechanistically aligned models with good
accuracy-complexity trade-offs on real-world data; and derives compact,
physically-motivated parametrizations for Parton Distribution Functions in a
frontier high-energy physics application. IdeaSearchFitter is a specialized
module within our broader iterated agent framework, IdeaSearch, which is
publicly available at https://www.ideasearch.cn/.</p></br><a href="http://arxiv.org/pdf/2510.08573v1"><h2>Reconstructing the local density field with combined convolutional and
  point cloud architecture</h2></a>Authors:  Baptiste Barthe-Gold, Nhat-Minh Nguyen, Leander Thiele</br>Comments: 6 pages, 4 figures, 1 table. Accepted at the NeurIPS 2025 Workshop:
  ML4PS. Comments welcome!</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, cs.LG, stat.ML</br><p>We construct a neural network to perform regression on the local dark-matter
density field given line-of-sight peculiar velocities of dark-matter halos,
biased tracers of the dark matter field. Our architecture combines a
convolutional U-Net with a point-cloud DeepSets. This combination enables
efficient use of small-scale information and improves reconstruction quality
relative to a U-Net-only approach. Specifically, our hybrid network recovers
both clustering amplitudes and phases better than the U-Net on small scales.</p></br>
