search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202505032000+TO+202505092000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, cs.LG, physics.data-an, stat.* staritng 202505032000 and ending 202505092000</h1>Feed last updated: 2025-05-09T00:00:00-04:00<a href="http://arxiv.org/pdf/2505.03385v1"><h2>Solar Flare Forecast: A Comparative Analysis of Machine Learning
  Algorithms for Solar Flare Class Prediction</h2></a>Authors:  Julia Bringewald</br>Comments: No comment found</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, astro-ph.IM, cs.LG, I.5.0</br><p>Solar flares are among the most powerful and dynamic events in the solar
system, resulting from the sudden release of magnetic energy stored in the
Sun's atmosphere. These energetic bursts of electromagnetic radiation can
release up to 10^32 erg of energy, impacting space weather and posing risks to
technological infrastructure and therefore require accurate forecasting of
solar flare occurrences and intensities. This study evaluates the predictive
performance of three machine learning algorithms: Random Forest, k-Nearest
Neighbors (KNN), and Extreme Gradient Boosting (XGBoost) for classifying solar
flares into 4 categories (B, C, M, X). Using the dataset of 13 SHARP
parameters, the effectiveness of the models was evaluated in binary and
multiclass classification tasks. The analysis utilized 8 principal components
(PC), capturing 95% of data variance, and 100 PCs, capturing 97.5% of variance.
Our approach uniquely combines binary and multiclass classification with
different levels of dimensionality reduction, an innovative methodology not
previously explored in the context of solar flare prediction. Employing a
10-fold stratified cross-validation and grid search for hyperparameter tuning
ensured robust model evaluation. Our findings indicate that Random Forest and
XGBoost consistently demonstrate strong performance across all metrics,
benefiting significantly from increased dimensionality. The insights of this
study enhance future research by optimizing dimensionality reduction techniques
and informing model selection for astrophysical tasks. By integrating this
newly acquired knowledge into future research, more accurate space weather
forecasting systems can be developed, along with a deeper understanding of
solar physics.</p></br><a href="http://arxiv.org/pdf/2505.03509v1"><h2>AnomalyMatch: Discovering Rare Objects of Interest with Semi-supervised
  and Active Learning</h2></a>Authors:  Pablo GÃ³mez, David O'Ryan</br>Comments: Journal submission in preparation</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.IM</br><p>Anomaly detection in large datasets is essential in fields such as astronomy
and computer vision; however, supervised methods typically require extensive
anomaly labelling, which is often impractical. We present AnomalyMatch, an
anomaly detection framework combining the semi-supervised FixMatch algorithm
using EfficientNet classifiers with active learning. By treating anomaly
detection as a semi-supervised binary classification problem, we efficiently
utilise limited labelled and abundant unlabelled images. We allow iterative
model refinement in a user interface for expert verification of high-confidence
anomalies and correction of false positives. Built for astronomical data,
AnomalyMatch generalises readily to other domains facing similar data
challenges. Evaluations on the GalaxyMNIST astronomical dataset and the
miniImageNet natural-image benchmark under severe class imbalance (1% anomalies
for miniImageNet) display strong performance: starting from five to ten
labelled anomalies and after three active learning cycles, we achieve an
average AUROC of 0.95 (miniImageNet) and 0.86 (GalaxyMNIST), with respective
AUPRC of 0.77 and 0.71. After active learning cycles, anomalies are ranked with
71% (miniImageNet) to 93% precision in the 1% of the highest-ranked images.
AnomalyMatch is tailored for large-scale applications, efficiently processing
predictions for 100 million images within three days on a single GPU.
Integrated into ESAs Datalabs platform, AnomalyMatch facilitates targeted
discovery of scientifically valuable anomalies in vast astronomical datasets.
Our results underscore the exceptional utility and scalability of this approach
for anomaly discovery, highlighting the value of specialised approaches for
domains characterised by severe label scarcity.</p></br><a href="http://arxiv.org/pdf/2505.05310v1"><h2>A comparative analysis of GNSS-inferred precipitable water vapour at the
  potential sites for the Africa Millimetre Telescope</h2></a>Authors:  Lott Frans, Michael Backes, Heino Falcke, Tiziana Venturi</br>Comments: 12 pages, 12 figures, article published in MNRAS</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, physics.data-an</br><p>The Event Horizon Telescope (EHT) is a network of antennas across the globe
currently used to image super-massive black holes (SMBHs) at a frequency of 230
GHz. Since the release of the image of M87$^\ast$ in 2019 and, subsequently,
that of Sgr A$^\ast$ in 2022 by the EHT collaboration, the focus has shifted to
dynamically imaging SMBHs. This has led to a search for potential sites to
extend and fill in the gaps within the EHT network. The Gamsberg Mountain and
the H.E.S.S. site are both located within the Khomas highlands and have been
identified as potential sites for the Africa Millimetre Telescope (AMT).
Precipitable water vapour (PWV) in the atmosphere is the main source of opacity
and noise from atmospheric emissions when observing at millimetre to
sub-millimetre wavelengths. This study aims to establish the PWV content and
the atmospheric transmission at 86, 230, and 345 GHz at the AMT potential sites
using Global Navigation Satellite System (GNSS) derived PWV data. Results show
both sites have potential for observations at 86 and 230 GHz, with 345 GHz
possible at the Gamsberg Mountain during winter. The overall median PWV of
14.27 mm and 9.25 mm was calculated at the H.E.S.S. site and the Gamsberg
Mountain, respectively. The EHT window had PWV medians of 16.62 mm and 11.20 mm
at the H.E.S.S. site and Gamsberg Mountain, respectively. Among the two sites,
the Gamsberg Mountain had the lowest PWV conditions, therefore making it the
most suitable site for the AMT.</p></br><a href="http://arxiv.org/pdf/2505.03849v1"><h2>Improved Dimensionality Reduction for Inverse Problems in Nuclear Fusion
  and High-Energy Astrophysics</h2></a>Authors:  Jonathan Gorard, Ammar Hakim, Hong Qin, Kyle Parfrey, Shantenu Jha</br>Comments: 2 pages. Position paper accepted to DOE-ASCR Inverse Methods for
  Complex Systems under Uncertainty Workshop (Rockville, MD, United States,
  June 10-12, 2025)</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.IM, nucl-th, physics.comp-ph</br><p>Many inverse problems in nuclear fusion and high-energy astrophysics
research, such as the optimization of tokamak reactor geometries or the
inference of black hole parameters from interferometric images, necessitate
high-dimensional parameter scans and large ensembles of simulations to be
performed. Such inverse problems typically involve large uncertainties, both in
the measurement parameters being inverted and in the underlying physics models
themselves. Monte Carlo sampling, when combined with modern non-linear
dimensionality reduction techniques such as autoencoders and manifold learning,
can be used to reduce the size of the parameter spaces considerably. However,
there is no guarantee that the resulting combinations of parameters will be
physically valid, or even mathematically consistent. In this position paper, we
advocate adopting a hybrid approach that leverages our recent advances in the
development of formal verification methods for numerical algorithms, with the
goal of constructing parameter space restrictions with provable mathematical
and physical correctness properties, whilst nevertheless respecting both
experimental uncertainties and uncertainties in the underlying physical
processes.</p></br><a href="http://arxiv.org/pdf/2505.05346v1"><h2>Analysis of the accuracy of GNSS inferred precipitable water vapour
  against that from a 210 GHz WVR at the H.E.S.S. site</h2></a>Authors:  Lott Frans, Michael Backes, Heino Falcke, Tiziana Venturi</br>Comments: 12 pages, 12 figures, published by RAS Techniques and Instruments</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, physics.ao-ph, physics.data-an</br><p>The High Energy Stereoscopic System (H.E.S.S.) site and the Gamsberg Mountain
have been identified as potential sites for the Africa Millimetre Telescope
(AMT). The AMT is poised to observe at millimetre and possibly at submillimetre
wavelengths. At these wavelengths, precipitable water vapour (PWV) in the
atmosphere is the main source of opacity during observations and therefore
needs to be accurately assessed at the potential sites for the AMT. In order to
investigate the PWV conditions for the AMT, identical Global Navigation
Satellite System (GNSS) stations were installed and used to assess the PWV at
the two potential sites. In this study, the accuracy of those PWV measurements
by the GNSS stations was assessed by comparing the H.E.S.S. installed GNSS
station PWV measurements to that from a 210 GHz Water Vapour Radiometer (WVR)
also installed at the H.E.S.S. site. A correlation of 98% and an offset of 0.34
mm was found between the GNSS station and the 210 GHz WVR PWV data when on-site
pressure and the Nevada Geodetic Laboratory (NGL) weighted mean temperature
($\mathrm{T_m}$) were used calculate the GNSS station PWV data. In comparison,
the offset reduces to 0.15 mm when on-site derived $\mathrm{T_m}$ and pressure
were used to calculate the GNSS station PWV. The results show that the GNSS
station with on-site meteorological data can be used with high accuracy to
reliably determine the PWV conditions at the H.E.S.S. site.</p></br><a href="http://arxiv.org/pdf/2505.04802v1"><h2>ORBIT-2: Scaling Exascale Vision Foundation Models for Weather and
  Climate Downscaling</h2></a>Authors:  Xiao Wang, Jong-Youl Choi, Takuya Kurihaya, Isaac Lyngaas, Hong-Jun Yoon, Ming Fan, Nasik Muhammad Nafi, Aristeidis Tsaris, Ashwin M. Aji, Maliha Hossain, Mohamed Wahib, Dali Wang, Peter Thornton, Prasanna Balaprakash, Moetasim Ashfaq, Dan Lu</br>Comments: No comment found</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.EP, cs.AI, cs.DC, physics.ao-ph</br><p>Sparse observations and coarse-resolution climate models limit effective
regional decision-making, underscoring the need for robust downscaling.
However, existing AI methods struggle with generalization across variables and
geographies and are constrained by the quadratic complexity of Vision
Transformer (ViT) self-attention. We introduce ORBIT-2, a scalable foundation
model for global, hyper-resolution climate downscaling. ORBIT-2 incorporates
two key innovations: (1) Residual Slim ViT (Reslim), a lightweight architecture
with residual learning and Bayesian regularization for efficient, robust
prediction; and (2) TILES, a tile-wise sequence scaling algorithm that reduces
self-attention complexity from quadratic to linear, enabling long-sequence
processing and massive parallelism. ORBIT-2 scales to 10 billion parameters
across 32,768 GPUs, achieving up to 1.8 ExaFLOPS sustained throughput and
92-98% strong scaling efficiency. It supports downscaling to 0.9 km global
resolution and processes sequences up to 4.2 billion tokens. On 7 km resolution
benchmarks, ORBIT-2 achieves high accuracy with R^2 scores in the range of 0.98
to 0.99 against observation data.</p></br>
