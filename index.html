search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202411282000+TO+202412042000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on physics.data-an, cs.LG, stat.*, cs.AI staritng 202411282000 and ending 202412042000</h1>Feed last updated: 2024-12-03T00:00:00-05:00<a href="http://arxiv.org/pdf/2411.19450v1"><h2>Unsupervised Learning Approach to Anomaly Detection in Gravitational
  Wave Data</h2></a>Authors:  Ammar Fayad</br>Comments: No comment found</br>Primary Category: gr-qc</br>All Categories: gr-qc, astro-ph.IM, cs.LG</br><p>Gravitational waves (GW), predicted by Einstein's General Theory of
Relativity, provide a powerful probe of astrophysical phenomena and fundamental
physics. In this work, we propose an unsupervised anomaly detection method
using variational autoencoders (VAEs) to analyze GW time-series data. By
training on noise-only data, the VAE accurately reconstructs noise inputs while
failing to reconstruct anomalies, such as GW signals, which results in
measurable spikes in the reconstruction error. The method was applied to data
from the LIGO H1 and L1 detectors. Evaluation on testing datasets containing
both noise and GW events demonstrated reliable detection, achieving an area
under the ROC curve (AUC) of 0.89. This study introduces VAEs as a robust,
unsupervised approach for identifying anomalies in GW data, which offers a
scalable framework for detecting known and potentially new phenomena in
physics.</p></br><a href="http://arxiv.org/pdf/2411.19475v1"><h2>Effective Fine-Tuning of Vision-Language Models for Accurate Galaxy
  Morphology Analysis</h2></a>Authors:  Ruoqi Wang, Haitao Wang, Qiong Luo</br>Comments: No comment found</br>Primary Category: cs.CV</br>All Categories: cs.CV, astro-ph.GA, cs.AI, cs.LG</br><p>Galaxy morphology analysis involves classifying galaxies by their shapes and
structures. For this task, directly training domain-specific models on large,
annotated astronomical datasets is effective but costly. In contrast,
fine-tuning vision foundation models on a smaller set of astronomical images is
more resource-efficient but generally results in lower accuracy. To harness the
benefits of both approaches and address their shortcomings, we propose
GalaxAlign, a novel method that fine-tunes pre-trained foundation models to
achieve high accuracy on astronomical tasks. Specifically, our method extends a
contrastive learning architecture to align three types of data in fine-tuning:
(1) a set of schematic symbols representing galaxy shapes and structures, (2)
textual labels of these symbols, and (3) galaxy images. This way, GalaxAlign
not only eliminates the need for expensive pretraining but also enhances the
effectiveness of fine-tuning. Extensive experiments on galaxy classification
and similarity search demonstrate that our method effectively fine-tunes
general pre-trained models for astronomical tasks by incorporating
domain-specific multi-modal knowledge.</p></br>
