search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202508162000+TO+202508222000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.LG, cs.AI, stat.*, physics.data-an staritng 202508162000 and ending 202508222000</h1>Feed last updated: 2025-08-22T00:00:00-04:00<a href="http://arxiv.org/pdf/2508.15106v1"><h2>Enhanced Predictive Modeling for Hazardous Near-Earth Object Detection:
  A Comparative Analysis of Advanced Resampling Strategies and Machine Learning
  Algorithms in Planetary Risk Assessment</h2></a>Authors:  Sunkalp Chandra</br>Comments: No comment found</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.AI, cs.LG</br><p>This study evaluates the performance of several machine learning models for
predicting hazardous near-Earth objects (NEOs) through a binary classification
framework, including data scaling, power transformation, and cross-validation.
Six classifiers were compared, namely Random Forest Classifier (RFC), Gradient
Boosting Classifier (GBC), Support Vector Classifier (SVC), Linear Discriminant
Analysis (LDA), Logistic Regression (LR), and K-Nearest Neighbors (KNN). RFC
and GBC performed the best, both with an impressive F2-score of 0.987 and
0.986, respectively, with very small variability. SVC followed, with a lower
but reasonable score of 0.896. LDA and LR had a moderate performance with
scores of around 0.749 and 0.748, respectively, while KNN had a poor
performance with a score of 0.691 due to difficulty in handling complex data
patterns. RFC and GBC also presented great confusion matrices with a negligible
number of false positives and false negatives, which resulted in outstanding
accuracy rates of 99.7% and 99.6%, respectively. These findings highlight the
power of ensemble methods for high precision and recall and further point out
the importance of tailored model selection with regard to dataset
characteristics and chosen evaluation metrics. Future research could focus on
the optimization of hyperparameters with advanced features engineering to
further the accuracy and robustness of the model on NEO hazard predictions.</p></br><a href="http://arxiv.org/pdf/2508.14107v1"><h2>SuryaBench: Benchmark Dataset for Advancing Machine Learning in
  Heliophysics and Space Weather Prediction</h2></a>Authors:  Sujit Roy, Dinesha V. Hegde, Johannes Schmude, Amy Lin, Vishal Gaur, Rohit Lal, Kshitiz Mandal, Talwinder Singh, Andrés Muñoz-Jaramillo, Kang Yang, Chetraj Pandey, Jinsu Hong, Berkay Aydin, Ryan McGranaghan, Spiridon Kasapis, Vishal Upendran, Shah Bahauddin, Daniel da Silva, Marcus Freitag, Iksha Gurung, Nikolai Pogorelov, Campbell Watson, Manil Maskey, Juan Bernabe-Moreno, Rahul Ramachandran</br>Comments: No comment found</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, astro-ph.IM, cs.AI</br><p>This paper introduces a high resolution, machine learning-ready heliophysics
dataset derived from NASA's Solar Dynamics Observatory (SDO), specifically
designed to advance machine learning (ML) applications in solar physics and
space weather forecasting. The dataset includes processed imagery from the
Atmospheric Imaging Assembly (AIA) and Helioseismic and Magnetic Imager (HMI),
spanning a solar cycle from May 2010 to July 2024. To ensure suitability for ML
tasks, the data has been preprocessed, including correction of spacecraft roll
angles, orbital adjustments, exposure normalization, and degradation
compensation. We also provide auxiliary application benchmark datasets
complementing the core SDO dataset. These provide benchmark applications for
central heliophysics and space weather tasks such as active region
segmentation, active region emergence forecasting, coronal field extrapolation,
solar flare prediction, solar EUV spectra prediction, and solar wind speed
estimation. By establishing a unified, standardized data collection, this
dataset aims to facilitate benchmarking, enhance reproducibility, and
accelerate the development of AI-driven models for critical space weather
prediction tasks, bridging gaps between solar physics, machine learning, and
operational forecasting.</p></br>
