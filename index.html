search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202601212000+TO+202601272000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, physics.data-an, stat.*, cs.LG staritng 202601212000 and ending 202601272000</h1>Feed last updated: 2026-01-27T04:38:40Z<a href="https://arxiv.org/pdf/2601.17222v1"><h2>Improving Generalization and Uncertainty Quantification of Photometric Redshift Models</h2></a>Authors:  Jonathan Soriano, Tuan Do, Srinath Saikrishnan, Vikram Seenivasan, Bernie Boscoe, Jack Singal, Evan Jones</br>Comments: 27 pages, 16 figures, 7 Tables, accepted for publication in AJ</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.CO, cs.LG</br><p>Accurate redshift estimates are a vital component in understanding galaxy evolution and precision cosmology. In this paper, we explore approaches to increase the applicability of machine learning models for photometric redshift estimation on a broader range of galaxy types. Typical models are trained with ground-truth redshifts from spectroscopy. We test the utility and effectiveness of two approaches for combining spectroscopic redshifts and redshifts derived from multiband ($\sim$35 filters) photometry, which sample different types of galaxies compared to spectroscopic surveys. The two approaches are (1) training on a composite dataset and (2) transfer learning from one dataset to another. We compile photometric redshifts from the COSMOS2020 catalog (TransferZ) to complement an established spectroscopic redshift dataset (GalaxiesML). We used two architectures, deterministic neural networks (NN) and Bayesian neural networks (BNN), to examine and evaluate their performance with respect to the Legacy Survey of Space and Time (LSST) photo-$z$ science requirements. We also use split conformal prediction for calibrating uncertainty estimates and producing prediction intervals for the BNN and NN, respectively. We find that a NN trained on a composite dataset predicts photo-$z$'s that are 4.5 times less biased within the redshift range $0.3<z<1.5$, 1.1 times less scattered, and has a 1.4 times lower outlier rate than a model trained on only spectroscopic ground truths. We also find that BNNs produce reliable uncertainty estimates, but are sensitive to the different ground truths. This investigation leverages different sources of ground truths to develop models that can accurately predict photo-$z$'s for a broader population of galaxies crucial for surveys such as Euclid and LSST.</p></br><a href="https://arxiv.org/pdf/2601.15949v1"><h2>Natural Language-Driven Global Mapping of Martian Landforms</h2></a>Authors:  Yiran Wang, Shuoyuan Wang, Zhaoran Wei, Jiannan Zhao, Zhonghua Yao, Zejian Xie, Songxin Zhang, Jun Huang, Bingyi Jing, Hongxin Wei</br>Comments: No comment found</br>Primary Category: cs.AI</br>All Categories: cs.AI, astro-ph.IM</br><p>Planetary surfaces are typically analyzed using high-level semantic concepts in natural language, yet vast orbital image archives remain organized at the pixel level. This mismatch limits scalable, open-ended exploration of planetary surfaces. Here we present MarScope, a planetary-scale vision-language framework enabling natural language-driven, label-free mapping of Martian landforms. MarScope aligns planetary images and text in a shared semantic space, trained on over 200,000 curated image-text pairs. This framework transforms global geomorphic mapping on Mars by replacing pre-defined classifications with flexible semantic retrieval, enabling arbitrary user queries across the entire planet in 5 seconds with F1 scores up to 0.978. Applications further show that it extends beyond morphological classification to facilitate process-oriented analysis and similarity-based geomorphological mapping at a planetary scale. MarScope establishes a new paradigm where natural language serves as a direct interface for scientific discovery over massive geospatial datasets.</p></br><a href="https://arxiv.org/pdf/2601.18627v1"><h2>Constraining Reionization Morphology and Source Properties with 21cm-Galaxy Cross-Correlation Surveys</h2></a>Authors:  Yannic Pietschke, Anne Hutter, Caroline Heneka</br>Comments: 12 pages, 6 figures, prepared for submission to A&A</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, physics.data-an</br><p>Cross-correlations between 21cm observations and galaxy surveys provide a powerful probe of reionization by reducing foreground sensitivity while linking ionization morphology to galaxies. We quantify the constraining power of 21cm-Galaxy cross-power spectra for inferring neutral hydrogen fraction $x_\mathrm{HI}(z)$ and mean overdensity $\langle 1+δ_\mathrm{HI} \rangle(z)$, exploring dependence on field of view, redshift precision $σ_z$, and minimum halo mass $M_\mathrm{h,min}$. We employ our simulation-based inference framework EoRFlow for likelihood-free parameter estimation. Mock observations include thermal noise for 100h SKA-Low with foreground avoidance and realistic galaxy survey effects. For a fiducial survey ($\mathrm{FOV}=100\,\mathrm{deg}^2$, $σ_z=0.001$, $M_\mathrm{h,min}=10^{11}\mathrm{M}_\odot$), cross-power spectra yield unbiased constraints with posterior volumes (PV) of $\sim$10% relative to priors. Cross-power measurements reduce PV by 20-30% versus 21cm auto-power alone. With foreground avoidance, spectroscopic redshift precision is essential; photometric redshifts render cross-correlations uninformative. Notably, cross-power spectra constrain ionizing source properties, the escape fraction $f_\mathrm{esc}$ and star formation efficiency $f_*$, which remain degenerate in auto-power (PV $>$60%). Tight constraints require either deep surveys detecting faint galaxies ($M_\mathrm{h,min} \sim 10^{10}\mathrm{M}_\odot$) with moderate foregrounds, or conservative mass limits with optimistic foreground removal (PV $<$15%). 21cm-Galaxy cross-correlations enhance morphology constraints beyond auto-power while enabling previously inaccessible source property constraints. Realizing full potential requires precise redshifts and either faint galaxy detection limits or improved 21cm foreground cleaning.</p></br><a href="https://arxiv.org/pdf/2601.18683v1"><h2>Learned harmonic mean estimation of the marginal likelihood for multimodal posteriors with flow matching</h2></a>Authors:  Alicja Polanska, Jason D. McEwen</br>Comments: Submitted to 44th International Workshop on Bayesian Inference and Maximum Entropy Methods in Science and Engineering</br>Primary Category: stat.ME</br>All Categories: stat.ME, astro-ph.IM, cs.LG</br><p>The marginal likelihood, or Bayesian evidence, is a crucial quantity for Bayesian model comparison but its computation can be challenging for complex models, even in parameters space of moderate dimension. The learned harmonic mean estimator has been shown to provide accurate and robust estimates of the marginal likelihood simply using posterior samples. It is agnostic to the sampling strategy, meaning that the samples can be obtained using any method. This enables marginal likelihood calculation and model comparison with whatever sampling is most suitable for the task. However, the internal density estimators considered previously for the learned harmonic mean can struggle with highly multimodal posteriors. In this work we introduce flow matching-based continuous normalizing flows as a powerful architecture for the internal density estimation of the learned harmonic mean. We demonstrate the ability to handle challenging multimodal posteriors, including an example in 20 parameter dimensions, showcasing the method's ability to handle complex posteriors without the need for fine-tuning or heuristic modifications to the base distribution.</p></br>
