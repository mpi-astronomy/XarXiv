search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202601172000+TO+202601232000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on physics.data-an, stat.*, cs.LG, cs.AI staritng 202601172000 and ending 202601232000</h1>Feed last updated: 2026-01-23T04:34:05Z<a href="https://arxiv.org/pdf/2601.14377v1"><h2>Cosmo-FOLD: Fast generation and upscaling of field-level cosmological maps with overlap latent diffusion</h2></a>Authors:  Satvik Mishra, Roberto Trotta, Matteo Viel</br>Comments: 15 pages, 10 figures</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, astro-ph.IM, cs.LG</br><p>We demonstrate the capabilities of probabilistic diffusion models to reduce dramatically the computational cost of expensive hydrodynamical simulations to study the relationship between observable baryonic cosmological probes and dark matter at field level and well into the non-linear regime. We introduce a novel technique, Cosmo-FOLD (Cosmological Fields via Overlap Latent Diffusion) to rapidly generate accurate and arbitrarily large cosmological and astrophysical 3-dimensional fields, conditioned on a given input field. We are able to generate TNG300-2 dark matter density and gas temperature fields from a model trained only on ~1% of the volume (a process we refer to as `upscaling'), reproducing both large scale coherent dark matter filaments and power spectra to within 10% for wavenumbers k <= 5 h Mpc^-1. These results are obtained within a small fraction of the original simulation cost and produced on a single GPU. Beyond one and two points statistics, the bispectrum is also faithfully reproduced through the inclusion of positional encodings. Finally, we demonstrate Cosmo-FOLD's generalisation capabilities by upscaling a CAMELS volume of 25 (Mpc h^-1)^3 to a full TNG300-2 volume of 205 (Mpc h^-1)^3$ with no fine-tuning. Cosmo-FOLD opens the door to full field-level simulation-based inference on cosmological scale.</p></br><a href="https://arxiv.org/pdf/2601.14235v1"><h2>Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration</h2></a>Authors:  LSST Dark Energy Science Collaboration, Eric Aubourg, Camille Avestruz, Matthew R. Becker, Biswajit Biswas, Rahul Biswas, Boris Bolliet, Adam S. Bolton, Clecio R. Bom, Raphaël Bonnet-Guerrini, Alexandre Boucaud, Jean-Eric Campagne, Chihway Chang, Aleksandra Ćiprijanović, Johann Cohen-Tanugi, Michael W. Coughlin, John Franklin Crenshaw, Juan C. Cuevas-Tello, Juan de Vicente, Seth W. Digel, Steven Dillmann, Mariano Javier de León Dominguez Romero, Alex Drlica-Wagner, Sydney Erickson, Alexander T. Gagliano, Christos Georgiou, Aritra Ghosh, Matthew Grayling, Kirill A. Grishin, Alan Heavens, Lindsay R. House, Mustapha Ishak, Wassim Kabalan, Arun Kannawadi, François Lanusse, C. Danielle Leonard, Pierre-François Léget, Michelle Lochner, Yao-Yuan Mao, Peter Melchior, Grant Merz, Martin Millon, Anais Möller, Gautham Narayan, Yuuki Omori, Hiranya Peiris, Laurence Perreault-Levasseur, Andrés A. Plazas Malagón, Nesar Ramachandra, Benjamin Remy, Cécile Roucelle, Jaime Ruiz-Zapatero, Stefan Schuldt, Ignacio Sevilla-Noarbe, Ved G. Shah, Tjitske Starkenburg, Stephen Thorp, Laura Toribio San Cipriano, Tilman Tröster, Roberto Trotta, Padma Venkatraman, Amanda Wasserman, Tim White, Justine Zeghal, Tianqing Zhang, Yuanyuan Zhang</br>Comments: 84 pages. This is v1.0 of the DESC's white paper on AI/ML, a collaboration document that is being made public but which is not planned for submission to a journal</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.CO, cs.AI, cs.LG, stat.ML</br><p>The Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST) will produce unprecedented volumes of heterogeneous astronomical data (images, catalogs, and alerts) that challenge traditional analysis pipelines. The LSST Dark Energy Science Collaboration (DESC) aims to derive robust constraints on dark energy and dark matter from these data, requiring methods that are statistically powerful, scalable, and operationally reliable. Artificial intelligence and machine learning (AI/ML) are already embedded across DESC science workflows, from photometric redshifts and transient classification to weak lensing inference and cosmological simulations. Yet their utility for precision cosmology hinges on trustworthy uncertainty quantification, robustness to covariate shift and model misspecification, and reproducible integration within scientific pipelines. This white paper surveys the current landscape of AI/ML across DESC's primary cosmological probes and cross-cutting analyses, revealing that the same core methodologies and fundamental challenges recur across disparate science cases. Since progress on these cross-cutting challenges would benefit multiple probes simultaneously, we identify key methodological research priorities, including Bayesian inference at scale, physics-informed methods, validation frameworks, and active learning for discovery. With an eye on emerging techniques, we also explore the potential of the latest foundation model methodologies and LLM-driven agentic AI systems to reshape DESC workflows, provided their deployment is coupled with rigorous evaluation and governance. Finally, we discuss critical software, computing, data infrastructure, and human capital requirements for the successful deployment of these new methodologies, and consider associated risks and opportunities for broader coordination with external actors.</p></br><a href="https://arxiv.org/pdf/2601.14036v1"><h2>Evaluating state-of-the-art cloud quantum computers for quantum neural networks in gravitational waves data analysis</h2></a>Authors:  Maria-Catalina Isfan, Laurentiu-Ioan Caramete, Ana Caramete</br>Comments: No comment found</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, astro-ph.IM, physics.data-an</br><p>In this work, we explore the possibility of using quantum computers provided for usage in cloud by big companies (such as IBM, IonQ, IQM Quantum Computers, etc.) to run our quantum neural network (QNN) developed for data analysis in the context of LISA Space Mission, developed with the Qiskit library in Python. Our previous work demonstrated that our QNN learns patterns in gravitational wave (GW) data much faster than a classical neural network, making it suitable for fast GW signal detection in future LISA data streams. Analyzing the fees from hardware providers like IBM Quantum, Amazon Braket and Microsoft Azure, we found that the fees for running the first segment of our QNN sum up to \$2000, \$60000, and \$1000000 respectively. Using free plans, we succeed to run the 3-qubit feature map of the QNN for one random data sample on {\fontfamily{qcr} \selectfont ibm\_kyoto} and {\fontfamily{qcr}\selectfont IQM Quantum Computers\_Garnet} quantum computers, obtaining a fidelity of 99\%; we could also run the first prediction segment of our QNN on {\fontfamily{qcr} \selectfont ibm\_kyoto}, implemented for 4 qubits, and obtained a prediction accuracy of 20\%. We queried providers such as IBM Quantum, Amazon Braket, Pasqal, and Munich Quantum Valley to obtain access to their plans, but, with the exception of Amazon Braket, our applications remain unanswered to this day. Other major setbacks in using the quantum computers we had access to included Qiskit library version issues (as in the cases of IBM Quantum and IQM Quantum Computers) and the frequent unavailability of the devices, as was the case with the Microsoft Azure provider. All the results presented in this paper were accumulated in 2024.</p></br><a href="https://arxiv.org/pdf/2601.14877v1"><h2>ExoMiner++ 2.0: Vetting TESS Full-Frame Image Transit Signals</h2></a>Authors:  Miguel J. S. Martinho, Hamed Valizadegan, Jon M. Jenkins, Douglas A. Caldwell, Joseph D. Twicken, Ben Tofflemire, Marziye Jafariyazani</br>Comments: No comment found</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>The Transiting Exoplanet Survey Satellite (TESS) Full-Frame Images (FFIs) provide photometric time series for millions of stars, enabling transit searches beyond the limited set of pre-selected 2-minute targets. However, FFIs present additional challenges for transit identification and vetting. In this work, we apply ExoMiner++ 2.0, an adaptation of the ExoMiner++ framework originally developed for TESS 2-minute data, to FFI light curves. The model is used to perform large-scale planet versus non-planet classification of Threshold Crossing Events across the sectors analyzed in this study. We construct a uniform vetting catalog of all evaluated signals and assess model performance under different observing conditions. We find that ExoMiner++ 2.0 generalizes effectively to the FFI domain, providing robust discrimination between planetary signals, astrophysical false positives, and instrumental artifacts despite the limitations inherent to longer cadence data. This work extends the applicability of ExoMiner++ to the full TESS dataset and supports future population studies and follow-up prioritization.</p></br><a href="https://arxiv.org/pdf/2601.15351v1"><h2>OmniSpectra: A Unified Foundation Model for Native Resolution Astronomical Spectra</h2></a>Authors:  Md Khairul Islam, Judy Fox</br>Comments: No comment found</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI</br><p>We present OmniSpectra, the first native-resolution foundation model for astronomy spectra. Unlike traditional models, which are limited to fixed-length input sizes or configurations, OmniSpectra handles spectra of any length at their original size, without resampling or interpolation. Despite the large-scale spectroscopic data from diverse surveys fueling the rapid growth of astronomy, existing foundation models are limited to a fixed wavelength range and specific instruments. OmniSpectra is the first foundation model to learn simultaneously from multiple real-world spectra surveys with different configurations at a large scale. We achieve this by designing a novel architecture with adaptive patching across variable lengths, sinusoidal global wavelength encoding, local positional embeddings through depthwise convolution, and validity-aware self-attention masks. Allowing us to learn multi-scale spatial patterns while skipping attention for invalid patches. Even with a limited training example, OmniSpectra demonstrates excellent zero-shot generalization compared to methods tailored for specific tasks. This transfer learning capability makes this model the state-of-the-art across various astronomy tasks, including source classification, redshift estimation, and properties prediction for stars and galaxies. OmniSpectra reduces the need for training individual models for different tasks from scratch, establishing itself as the next-generation astronomy foundation model.</p></br><a href="https://arxiv.org/pdf/2601.14542v1"><h2>New techniques to investigate the AGN-SF connection with integral field spectroscopy</h2></a>Authors:  Aman Chopra, Henry R. M. Zovaro, Rebecca L. Davies</br>Comments: 26 pages, 23 figures</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, physics.data-an, stat.AP</br><p>Understanding the connection between active galactic nuclei and star-formation (the AGN-SF connection) is one of the longest standing problems in modern astrophysics. In the age of large Integral Field Unit (IFU) surveys, studies of the AGN-SF connection greatly benefit from spatially resolving AGN and SF contributions to study the two processes independently. Using IFU data for 54 local active galaxies from the S7 sample, we present a new method to separate emission from AGN activity and SF using mixing sequences observed in the [NII]$λ6584$/H$α$ vs. [OIII]$λ5007$/H$β$ Baldwin-Phillips-Terlevich (BPT) diagram. We use the new decomposition method to calculate the H$α$ star-formation rate and AGN [OIII] luminosity for the galaxies. Our new method is robust to outliers in the line-ratio distribution and can be applied to large galaxy samples with little manual intervention. We infer star-formation histories (SFHs) using pPXF, conducting detailed recovery tests to determine the quantities that can be considered robust. We test the correlation between the AGN Eddington ratio, using the proxy L[OIII]/$σ_*^4$, and star-formation properties. We find a moderately strong correlation between the Eddington ratio and the star-formation rate (SFR). We also observe marginally significant correlations between the AGN Eddington ratio and the light-weighted stellar age under 100 Myr. Our results point to higher AGN accretion being associated with young nuclear star formation under 100 Myr, consistent with timelines presented in previous studies. The correlations found in this paper are relatively weak; extending our methods to larger samples, including radio-quiet galaxies, will help better constrain the physical mechanisms and timescales of the AGN-SF connection.</p></br><a href="https://arxiv.org/pdf/2601.15949v1"><h2>Natural Language-Driven Global Mapping of Martian Landforms</h2></a>Authors:  Yiran Wang, Shuoyuan Wang, Zhaoran Wei, Jiannan Zhao, Zhonghua Yao, Zejian Xie, Songxin Zhang, Jun Huang, Bingyi Jing, Hongxin Wei</br>Comments: No comment found</br>Primary Category: cs.AI</br>All Categories: cs.AI, astro-ph.IM</br><p>Planetary surfaces are typically analyzed using high-level semantic concepts in natural language, yet vast orbital image archives remain organized at the pixel level. This mismatch limits scalable, open-ended exploration of planetary surfaces. Here we present MarScope, a planetary-scale vision-language framework enabling natural language-driven, label-free mapping of Martian landforms. MarScope aligns planetary images and text in a shared semantic space, trained on over 200,000 curated image-text pairs. This framework transforms global geomorphic mapping on Mars by replacing pre-defined classifications with flexible semantic retrieval, enabling arbitrary user queries across the entire planet in 5 seconds with F1 scores up to 0.978. Applications further show that it extends beyond morphological classification to facilitate process-oriented analysis and similarity-based geomorphological mapping at a planetary scale. MarScope establishes a new paradigm where natural language serves as a direct interface for scientific discovery over massive geospatial datasets.</p></br><a href="https://arxiv.org/pdf/2601.13145v1"><h2>SolARED: Solar Active Region Emergence Dataset for Machine Learning Aided Predictions</h2></a>Authors:  Spiridon Kasapis, Eren Dogan, Irina N. Kitiashvili, Alexander G. Kosovichev, John T. Stefan, Jake D. Butler, Jonas Tirona, Sarang Patil, Mengjia Xu</br>Comments: 15 pages, 6 figures, submitted to the Springer Nature - Solar Physics Journal</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, cs.LG</br><p>The development of accurate forecasts of solar eruptive activity has become increasingly important for preventing potential impacts on space technologies and exploration. Therefore, it is crucial to detect Active Regions (ARs) before they start forming on the solar surface. This will enable the development of early-warning capabilities for upcoming space weather disturbances. For this reason, we prepared the Solar Active Region Emergence Dataset (SolARED). The dataset is derived from full-disk maps of the Doppler velocity, magnetic field, and continuum intensity, obtained by the Helioseismic and Magnetic Imager (HMI) onboard the Solar Dynamics Observatory (SDO). SolARED includes time series of remapped, tracked, and binned data that characterize the evolution of acoustic power of solar oscillations, unsigned magnetic flux, and continuum intensity for 50 large ARs before, during, and after their emergence on the solar surface, as well as surrounding areas observed on the solar disc between 2010 and 2023. The resulting ML-ready SolARED dataset is designed to support enhancements of predictive capabilities, enabling the development of operational forecasts for the emergence of active regions. The SolARED dataset is available at https://sun.njit.edu/sarportal/, through an interactive visualization web application.</p></br><a href="https://arxiv.org/pdf/2601.13144v1"><h2>Forecasting Continuum Intensity for Solar Active Region Emergence Prediction using Transformers</h2></a>Authors:  Jonas Tirona, Sarang Patil, Spiridon Kasapis, Eren Dogan, John Stefan, Irina N. Kitiashvili, Alexander G. Kosovichev, Mengjia Xu</br>Comments: 30 pages, 7 figures, submitted to JGR: Machine Learning and Computation</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, cs.LG</br><p>Early and accurate prediction of solar active region (AR) emergence is crucial for space weather forecasting. Building on established Long Short-Term Memory (LSTM) based approaches for forecasting the continuum intensity decrease associated with AR emergence, this work expands the modeling with new architectures and targets. We investigate a sliding-window Transformer architecture to forecast continuum intensity evolution up to 12 hours ahead using data from 46 ARs observed by SDO/HMI. We conduct a systematic ablation study to evaluate two key components: (1) the inclusion of a temporal 1D convolutional (Conv1D) front-end and (2) a novel `Early Detection' architecture featuring attention biases and a timing-aware loss function. Our best-performing model, combining the Early Detection architecture without the Conv1D layer, achieved a Root Mean Square Error (RMSE) of 0.1189 (representing a 10.6% improvement over the LSTM baseline) and an average advance warning time of 4.73 hours (timing difference of -4.73h), even under a stricter emergence criterion than previous studies. While the Transformer demonstrates superior aggregate timing and accuracy, we note that this high-sensitivity detection comes with increased variance compared to smoother baseline models. However, this volatility is a necessary trade-off for operational warning systems: the model's ability to detect micro-changes in precursor signals enables significantly earlier detection, outweighing the cost of increased noise. Our results demonstrate that Transformer architectures modified with early detection biases, when used without temporal smoothing layers, provide a high-sensitivity alternative for forecasting AR emergence that prioritizes advance warning over statistical smoothness.</p></br>
