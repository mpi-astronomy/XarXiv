search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202507112000+TO+202507172000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.LG, physics.data-an, cs.AI, stat.* staritng 202507112000 and ending 202507172000</h1>Feed last updated: 2025-07-17T00:00:00-04:00<a href="http://arxiv.org/pdf/2507.11400v1"><h2>The model is the message: Lightweight convolutional autoencoders applied
  to noisy imaging data for planetary science and astrobiology</h2></a>Authors:  Caleb Scharf</br>Comments: 28 pages, 8 figures, accepted for publication in Icarus</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>The application of convolutional autoencoder deep learning to imaging data
for planetary science and astrobiological use is briefly reviewed and explored
with a focus on the need to understand algorithmic rationale, process, and
results when machine learning is utilized. Successful autoencoders train to
build a model that captures the features of data in a dimensionally reduced
form (the latent representation) that can then be used to recreate the original
input. One application is the reconstruction of incomplete or noisy data. Here
a baseline, lightweight convolutional autoencoder is used to examine the
utility for planetary image reconstruction or inpainting in situations where
there is destructive random noise (i.e., either luminance noise with zero
returned data in some image pixels, or color noise with random additive levels
across pixel channels). It is shown that, in certain use cases, multi-color
image reconstruction can be usefully applied even with extensive random
destructive noise with 90% areal coverage and higher. This capability is
discussed in the context of intentional masking to reduce data bandwidth, or
situations with low-illumination levels and other factors that obscure image
data (e.g., sensor degradation or atmospheric conditions). It is further
suggested that for some scientific use cases the model latent space and
representations have more utility than large raw imaging datasets.</p></br><a href="http://arxiv.org/pdf/2507.10738v1"><h2>Information Field Theory based Event Reconstruction for Cosmic Ray Radio
  Detectors</h2></a>Authors:  Simon Strähnz, Tim Huege, Torsten Enßlin, Karen Terveer, Anna Nelles</br>Comments: No comment found</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.HE, physics.data-an</br><p>Detection of extensive air showers with radio antennas is an appealing
technique in cosmic ray physics. However, because of the high level of
measurement noise, current reconstruction methods still leave room for
improvement. Furthermore, reconstruction efforts typically focus only on a
single aspect of the signal, such as the energy fluence or arrival time.
Bayesian inference is then a natural choice for a holistic approach to
reconstruction, yet, this problem would be ill-posed, since the electric field
is a continuous quantity. Information Field Theory provides the solution for
this by providing a statistical framework to deal with discretised fields in
the continuum limit. We are currently developing models for this novel approach
to reconstructing extensive air showers. The model described here is based on
the best current understanding of the emission mechanisms: It uses
parametrisations of the lateral signal strength distribution, charge-excess
contribution and spectral shape. Shower-to-shower fluctuations and narrowband
RFI are modelled using Gaussian processes. Combined with a detailed detector
description, this model can infer not only the electric field, but also the
shower geometry, electromagnetic energy and position of shower maximum. Another
big achievement of this approach is its ability to naturally provide
uncertainties for the reconstruction, which has been shown to be difficult in
more traditional methods. With such an open framework and robust computational
methods based in Information Field Theory, it will also be easy to incorporate
new insights and additional data, such as timing distributions or particle
detector data, in the future. This approach has a high potential to exploit the
full information content of a complex detector with rigorous statistical
methods, in a way that directly includes domain knowledge.</p></br><a href="http://arxiv.org/pdf/2507.11620v1"><h2>Learning Representations of Event Time Series with Sparse Autoencoders
  for Anomaly Detection, Similarity Search, and Unsupervised Classification</h2></a>Authors:  Steven Dillmann, Juan Rafael Martínez-Galarza</br>Comments: Accepted at the 2025 ICML Workshop on Machine Learning for
  Astrophysics, Code available at:
  https://github.com/StevenDillmann/ml-xraytransients-mnras</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.HE, astro-ph.IM, cs.AI</br><p>Event time series are sequences of discrete events occurring at irregular
time intervals, each associated with a domain-specific observational modality.
They are common in domains such as high-energy astrophysics, computational
social science, cybersecurity, finance, healthcare, neuroscience, and
seismology. Their unstructured and irregular structure poses significant
challenges for extracting meaningful patterns and identifying salient phenomena
using conventional techniques. We propose novel two- and three-dimensional
tensor representations for event time series, coupled with sparse autoencoders
that learn physically meaningful latent representations. These embeddings
support a variety of downstream tasks, including anomaly detection,
similarity-based retrieval, semantic clustering, and unsupervised
classification. We demonstrate our approach on a real-world dataset from X-ray
astronomy, showing that these representations successfully capture temporal and
spectral signatures and isolate diverse classes of X-ray transients. Our
framework offers a flexible, scalable, and generalizable solution for analyzing
complex, irregular event time series across scientific and industrial domains.</p></br><a href="http://arxiv.org/pdf/2507.11692v1"><h2>Galaxy image simplification using Generative AI</h2></a>Authors:  Sai Teja Erukude, Lior Shamir</br>Comments: Astronomy and Computing, accepted</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, astro-ph.IM, cs.AI, cs.LG</br><p>Modern digital sky surveys have been acquiring images of billions of
galaxies. While these images often provide sufficient details to analyze the
shape of the galaxies, accurate analysis of such high volumes of images
requires effective automation. Current solutions often rely on machine learning
annotation of the galaxy images based on a set of pre-defined classes. Here we
introduce a new approach to galaxy image analysis that is based on generative
AI. The method simplifies the galaxy images and automatically converts them
into a ``skeletonized" form. The simplified images allow accurate measurements
of the galaxy shapes and analysis that is not limited to a certain pre-defined
set of classes. We demonstrate the method by applying it to galaxy images
acquired by the DESI Legacy Survey. The code and data are publicly available.
The method was applied to 125,000 DESI Legacy Survey images, and the catalog of
the simplified images is publicly available.</p></br><a href="http://arxiv.org/pdf/2507.11192v1"><h2>Recent Advances in Simulation-based Inference for Gravitational Wave
  Data Analysis</h2></a>Authors:  Bo Liang, He Wang</br>Comments: 30 pages, 6 figures, 1 table. Published version accepted by
  Astronomical Techniques and Instruments (ATI)</br>Primary Category: gr-qc</br>All Categories: gr-qc, astro-ph.HE, astro-ph.IM, cs.LG, stat.ML</br><p>The detection of gravitational waves by the LIGO-Virgo-KAGRA collaboration
has ushered in a new era of observational astronomy, emphasizing the need for
rapid and detailed parameter estimation and population-level analyses.
Traditional Bayesian inference methods, particularly Markov chain Monte Carlo,
face significant computational challenges when dealing with the
high-dimensional parameter spaces and complex noise characteristics inherent in
gravitational wave data. This review examines the emerging role of
simulation-based inference methods in gravitational wave astronomy, with a
focus on approaches that leverage machine-learning techniques such as
normalizing flows and neural posterior estimation. We provide a comprehensive
overview of the theoretical foundations underlying various simulation-based
inference methods, including neural posterior estimation, neural ratio
estimation, neural likelihood estimation, flow matching, and consistency
models. We explore the applications of these methods across diverse
gravitational wave data processing scenarios, from single-source parameter
estimation and overlapping signal analysis to testing general relativity and
conducting population studies. Although these techniques demonstrate speed
improvements over traditional methods in controlled studies, their
model-dependent nature and sensitivity to prior assumptions are barriers to
their widespread adoption. Their accuracy, which is similar to that of
conventional methods, requires further validation across broader parameter
spaces and noise conditions.</p></br><a href="http://arxiv.org/pdf/2507.10091v1"><h2>Non-Gaussian Expansion of Minkowski Tensors in Redshift Space</h2></a>Authors:  Stephen Appleby, Christophe Pichon, Pravabati Chingangbam, Dmitri Pogosyan, Changbom Park</br>Comments: 22 pages, 9 figures, submitted to ApJ</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, physics.data-an</br><p>This paper focuses on extending the use of Minkowski Tensors to analyze
anisotropic signals in cosmological data, focusing on those introduced by
redshift space distortion. We derive the ensemble average of the two
translation-invariant, rank-2 Minkowski Tensors for a matter density field that
is perturbatively non-Gaussian in redshift space. This is achieved through the
Edgeworth expansion of the joint probability density function of the field and
its derivatives, expressing the ensemble averages in terms of cumulants up to
cubic order. Our goal is to connect these theoretical predictions to the
underlying cosmological parameters, allowing for parameter estimation by
measuring them from galaxy surveys. The work builds on previous analyses of
Minkowski Functionals in both real and redshift space and addresses the effects
of Finger-of-God velocity dispersion and shot noise. We validate our
predictions by matching them to measurements of the Minkowski Tensors from dark
matter simulation data, finding that perturbation theory is a qualified
success. Non-perturbative Finger-of-God effects remain significant at
relatively large scales (R< 20 Mpc/h) and are particularly pronounced in the
components parallel to the line of sight.</p></br><a href="http://arxiv.org/pdf/2507.11842v1"><h2>CosmoFlow: Scale-Aware Representation Learning for Cosmology with Flow
  Matching</h2></a>Authors:  Sidharth Kannan, Tian Qiu, Carolina Cuesta-Lazaro, Haewon Jeong</br>Comments: No comment found</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, cs.LG</br><p>Generative machine learning models have been demonstrated to be able to learn
low dimensional representations of data that preserve information required for
downstream tasks. In this work, we demonstrate that flow matching based
generative models can learn compact, semantically rich latent representations
of field level cold dark matter (CDM) simulation data without supervision. Our
model, CosmoFlow, learns representations 32x smaller than the raw field data,
usable for field level reconstruction, synthetic data generation, and parameter
inference. Our model also learns interpretable representations, in which
different latent channels correspond to features at different cosmological
scales.</p></br>
