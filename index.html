search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202406222000+TO+202406282000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on stat.*, cs.AI, cs.LG, physics.data-an staritng 202406222000 and ending 202406282000</h1>Feed last updated: 2024-06-28T00:00:00-04:00<a href="http://arxiv.org/pdf/2406.17057v1"><h2>At First Sight: Zero-Shot Classification of Astronomical Images with
  Large Multimodal Models</h2></a>Authors:  Dimitrios Tanoglidis, Bhuvnesh Jain</br>Comments: 5 pages, 3 images. Prepared for submission to RNAAS</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.GA, cs.AI</br><p>Vision-Language multimodal Models (VLMs) offer the possibility for zero-shot
classification in astronomy: i.e. classification via natural language prompts,
with no training. We investigate two models, GPT-4o and LLaVA-NeXT, for
zero-shot classification of low-surface brightness galaxies and artifacts, as
well as morphological classification of galaxies. We show that with natural
language prompts these models achieved significant accuracy (above 80 percent
typically) without additional training/fine tuning. We discuss areas that
require improvement, especially for LLaVA-NeXT, which is an open source model.
Our findings aim to motivate the astronomical community to consider VLMs as a
powerful tool for both research and pedagogy, with the prospect that future
custom-built or fine-tuned models could perform better.</p></br><a href="http://arxiv.org/pdf/2406.18175v1"><h2>Galaxy spectroscopy without spectra: Galaxy properties from photometric
  images with conditional diffusion models</h2></a>Authors:  Lars Doorenbos, Eva Sextl, Kevin Heng, Stefano Cavuoti, Massimo Brescia, Olena Torbaniuk, Giuseppe Longo, Raphael Sznitman, Pablo Márquez-Neila</br>Comments: Code is available here:
  https://github.com/LarsDoorenbos/generate-spectra</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, astro-ph.IM, cs.AI</br><p>Modern spectroscopic surveys can only target a small fraction of the vast
amount of photometrically cataloged sources in wide-field surveys. Here, we
report the development of a generative AI method capable of predicting optical
galaxy spectra from photometric broad-band images alone. This method draws from
the latest advances in diffusion models in combination with contrastive
networks. We pass multi-band galaxy images into the architecture to obtain
optical spectra. From these, robust values for galaxy properties can be derived
with any methods in the spectroscopic toolbox, such as standard population
synthesis techniques and Lick indices. When trained and tested on 64x64-pixel
images from the Sloan Digital Sky Survey, the global bimodality of star-forming
and quiescent galaxies in photometric space is recovered, as well as a
mass-metallicity relation of star-forming galaxies. The comparison between the
observed and the artificially created spectra shows good agreement in overall
metallicity, age, Dn4000, stellar velocity dispersion, and E(B-V) values.
Photometric redshift estimates of our generative algorithm can compete with
other current, specialized deep-learning techniques. Moreover, this work is the
first attempt in the literature to infer velocity dispersion from photometric
images. Additionally, we can predict the presence of an active galactic nucleus
up to an accuracy of 82%. With our method, scientifically interesting galaxy
properties, normally requiring spectroscopic inputs, can be obtained in future
data sets from large-scale photometric surveys alone. The spectra prediction
via AI can further assist in creating realistic mock catalogs.</p></br><a href="http://arxiv.org/pdf/2406.17316v1"><h2>A review of unsupervised learning in astronomy</h2></a>Authors:  Sotiria Fotopoulou</br>Comments: 30 pages, 6 figures. Invited contribution to special issue in
  Astronomy & Computing</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.LG</br><p>This review summarizes popular unsupervised learning methods, and gives an
overview of their past, current, and future uses in astronomy. Unsupervised
learning aims to organise the information content of a dataset, in such a way
that knowledge can be extracted. Traditionally this has been achieved through
dimensionality reduction techniques that aid the ranking of a dataset, for
example through principal component analysis or by using auto-encoders, or
simpler visualisation of a high dimensional space, for example through the use
of a self organising map. Other desirable properties of unsupervised learning
include the identification of clusters, i.e. groups of similar objects, which
has traditionally been achieved by the k-means algorithm and more recently
through density-based clustering such as HDBSCAN. More recently, complex
frameworks have emerged, that chain together dimensionality reduction and
clustering methods. However, no dataset is fully unknown. Thus, nowadays a lot
of research has been directed towards self-supervised and semi-supervised
methods that stand to gain from both supervised and unsupervised learning.</p></br><a href="http://arxiv.org/pdf/2406.17323v1"><h2>XAMI -- A Benchmark Dataset for Artefact Detection in XMM-Newton Optical
  Images</h2></a>Authors:  Elisabeta-Iulia Dima, Pablo Gómez, Sandor Kruk, Peter Kretschmar, Simon Rosen, Călin-Adrian Popa</br>Comments: submitted to SPAICE 2024</br>Primary Category: cs.CV</br>All Categories: cs.CV, astro-ph.IM, cs.LG</br><p>Reflected or scattered light produce artefacts in astronomical observations
that can negatively impact the scientific study. Hence, automated detection of
these artefacts is highly beneficial, especially with the increasing amounts of
data gathered. Machine learning methods are well-suited to this problem, but
currently there is a lack of annotated data to train such approaches to detect
artefacts in astronomical observations. In this work, we present a dataset of
images from the XMM-Newton space telescope Optical Monitoring camera showing
different types of artefacts. We hand-annotated a sample of 1000 images with
artefacts which we use to train automated ML methods. We further demonstrate
techniques tailored for accurate detection and masking of artefacts using
instance segmentation. We adopt a hybrid approach, combining knowledge from
both convolutional neural networks (CNNs) and transformer-based models and use
their advantages in segmentation. The presented method and dataset will advance
artefact detection in astronomical observations by providing a reproducible
baseline. All code and data are made available
(https://github.com/ESA-Datalabs/XAMI-model and
https://github.com/ESA-Datalabs/XAMI-dataset).</p></br><a href="http://arxiv.org/pdf/2406.16730v1"><h2>Convolutional neural network for Lyman break galaxies classification and
  redshift regression in DESI (Dark Energy Spectroscopic Instrument)</h2></a>Authors:  Julien Taran</br>Comments: No comment found</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, cs.AI</br><p>DESI is a groundbreaking international project to observe more than 40
million quasars and galaxies over a 5-year period to create a 3D map of the
sky. This map will enable us to probe multiple aspects of cosmology, from dark
energy to neutrino mass. We are focusing here on one type of object observed by
DESI, the Lyman Break Galaxies (LBGs). The aim is to use their spectra to
determine whether they are indeed LBGs, and if so, to determine their distance
from the Earth using a phenomenon called redshift. This will enable us to place
these galaxies on the DESI 3D map.
  The aim is therefore to develop a convolutional neural network (CNN) inspired
by QuasarNET (See arXiv:1808.09955), performing simultaneously a classification
(LBG type or not) and a regression task (determine the redshift of the LBGs).
Initially, data augmentation techniques such as shifting the spectra in
wavelengths, adding noise to the spectra, or adding synthetic spectra were used
to increase the model training dataset from 3,019 data to over 66,000. In a
second phase, modifications to the QuasarNET architecture, notably through
transfer learning and hyperparameter tuning with Bayesian optimization, boosted
model performance.
  Gains of up to 26% were achieved on the Purity/Efficiency curve, which is
used to evaluate model performance, particularly in areas with interesting
redshifts, at low (around 2) and high (around 4) redshifts. The best model
obtained an average score of 94%, compared with 75% for the initial model.</p></br>
