search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202506182000+TO+202506242000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on physics.data-an, cs.LG, cs.AI, stat.* staritng 202506182000 and ending 202506242000</h1>Feed last updated: 2025-06-24T00:00:00-04:00<a href="http://arxiv.org/pdf/2506.17665v1"><h2>Advanced Modeling for Exoplanet Detection and Characterization</h2></a>Authors:  Krishna Chamarthy</br>Comments: No comment found</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>Research into light curves from stars (temporal variation of brightness) has
completely changed how exoplanets are discovered or characterised. This study
including star light curves from the Kepler dataset as a way to discover
exoplanets (planetary transits) and derive some estimate of their physical
characteristics by the light curve and machine learning methods. The dataset
consists of measured flux (recordings) for many individual stars and we will
examine the light curve of each star and look for periodic dips in brightness
due to an astronomical body making a transit. We will apply variables derived
from an established method for deriving measurements from light curve data to
derive key parameters related to the planet we observed during the transit,
such as distance to the host star, orbital period, radius. The orbital period
will typically be measured based on the time between transit of the subsequent
timelines and the radius will be measured based on the depth of transit. The
density of the star and planet can also be estimated from the transit event, as
well as very limited information on the albedo (reflectivity) and atmosphere of
the planet based on transmission spectroscopy and/or the analysis of phase
curve for levels of flux. In addition to these methods, we will employ some
machine learning classification of the stars (i.e. likely have an exoplanet or
likely do not have an exoplanet) based on flux change. This could help fulfil
both the process of looking for exoplanets more efficient as well as providing
important parameters for the planet. This will provide a much quicker means of
searching the vast astronomical datasets for the likelihood of exoplanets.</p></br><a href="http://arxiv.org/pdf/2506.16255v1"><h2>Category-based Galaxy Image Generation via Diffusion Models</h2></a>Authors:  Xingzhong Fan, Hongming Tang, Yue Zeng, M. B. N. Kouwenhoven, Guangquan Zeng</br>Comments: 18 pages, 6 figures. Submitted to AAS Astronomical Journal (AJ) and
  is under revision. See another indenpdent work for furthur reference -- Can
  AI Dream of Unseen Galaxies? Conditional Diffusion Model for Galaxy
  Morphology Augmentation (Ma, Sun et al.). Comments are welcome</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI</br><p>Conventional galaxy generation methods rely on semi-analytical models and
hydrodynamic simulations, which are highly dependent on physical assumptions
and parameter tuning. In contrast, data-driven generative models do not have
explicit physical parameters pre-determined, and instead learn them efficiently
from observational data, making them alternative solutions to galaxy
generation. Among these, diffusion models outperform Variational Autoencoders
(VAEs) and Generative Adversarial Networks (GANs) in quality and diversity.
Leveraging physical prior knowledge to these models can further enhance their
capabilities. In this work, we present GalCatDiff, the first framework in
astronomy to leverage both galaxy image features and astrophysical properties
in the network design of diffusion models. GalCatDiff incorporates an enhanced
U-Net and a novel block entitled Astro-RAB (Residual Attention Block), which
dynamically combines attention mechanisms with convolution operations to ensure
global consistency and local feature fidelity. Moreover, GalCatDiff uses
category embeddings for class-specific galaxy generation, avoiding the high
computational costs of training separate models for each category. Our
experimental results demonstrate that GalCatDiff significantly outperforms
existing methods in terms of the consistency of sample color and size
distributions, and the generated galaxies are both visually realistic and
physically consistent. This framework will enhance the reliability of galaxy
simulations and can potentially serve as a data augmentor to support future
galaxy classification algorithm development.</p></br><a href="http://arxiv.org/pdf/2506.16314v1"><h2>Signatures to help interpretability of anomalies</h2></a>Authors:  Emmanuel Gangler, Emille E. O. Ishida, Matwey V. Kornilov, Vladimir Korolev, Anastasia Lavrukhina, Konstantin Malanchev, Maria V. Pruzhinskaya, Etienne Russeil, Timofey Semenikhin, Sreevarsha Sreejith, Alina A. Volnova</br>Comments: 7 pages, 3 figure, proceedings of the International Conference on
  Machine Learning for Astrophysics (ML4ASTRO2)</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.IM</br><p>Machine learning is often viewed as a black box when it comes to
understanding its output, be it a decision or a score. Automatic anomaly
detection is no exception to this rule, and quite often the astronomer is left
to independently analyze the data in order to understand why a given event is
tagged as an anomaly. We introduce here idea of anomaly signature, whose aim is
to help the interpretability of anomalies by highlighting which features
contributed to the decision.</p></br><a href="http://arxiv.org/pdf/2506.17360v1"><h2>Algorithm to extract direction in 2D discrete distributions and a
  continuous Frobenius norm</h2></a>Authors:  Jeffrey G. Yepez, Jackson D. Seligman, Max A. A. Dornfest, Brian C. Crow, John G. Learned, Viacheslav A. Li</br>Comments: No comment found</br>Primary Category: physics.data-an</br>All Categories: physics.data-an, astro-ph.IM</br><p>In this study, we present a novel algorithm for determining directionality in
2D distributions of discrete data. We compare a reference dataset with a known
direction to a measured dataset with an unknown direction by the Frobenius norm
of the difference (FND) to find the unknown direction. To generalize this
concept, we develop a continuous Frobenius norm of the difference (CFND) as a
continuous analog of the FND and derive its analytical expression. By relating
fitted and normalized 2D Gaussian distributions, we show that the CFND
approximates the FND, and we validate this relationship with computer
simulations. We find that a first-order approximation of the CFND between two
similar Gaussian distributions takes the form of an absolute sine function,
offering a simple analytical form with potential for specialized applications
in segmented inverse beta decay (IBD) neutrino detectors, astronomy, machine
learning, and more. Although this method may easily extend to 3D scalar fields,
our focus here is on 2D real-valued fields as it directly applies to
directionality. Our methodology consists of modeling a 2D Gaussian
distribution, binning the data into a histogram, and encoding it as a square
matrix. Rotating this matrix around its geometric center and comparing it to a
measured dataset using the FND gives us rotational data that we fit with an
absolute sine function. The location of the minimum of this fit is the angle
closest to the true angle of the direction in the measured dataset. We present
the derivation and discuss initial applications of the CFND in our novel
algorithm, demonstrating its success in approximating directionality in 2D
distributions.</p></br><a href="http://arxiv.org/pdf/2506.16233v1"><h2>Can AI Dream of Unseen Galaxies? Conditional Diffusion Model for Galaxy
  Morphology Augmentation</h2></a>Authors:  Chenrui Ma, Zechang Sun, Tao Jing, Zheng Cai, Yuan-Sen Ting, Song Huang, Mingyu Li</br>Comments: We have submitted to AAS journals. See another independent work for
  further reference -- Category-based Galaxy Image Generation via Diffusion
  Models (Fan, Tang et al.). Comments are welcome</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, cs.LG</br><p>Observational astronomy relies on visual feature identification to detect
critical astrophysical phenomena. While machine learning (ML) increasingly
automates this process, models often struggle with generalization in
large-scale surveys due to the limited representativeness of labeled datasets
-- whether from simulations or human annotation -- a challenge pronounced for
rare yet scientifically valuable objects. To address this, we propose a
conditional diffusion model to synthesize realistic galaxy images for
augmenting ML training data. Leveraging the Galaxy Zoo 2 dataset which contains
visual feature -- galaxy image pairs from volunteer annotation, we demonstrate
that our model generates diverse, high-fidelity galaxy images closely adhere to
the specified morphological feature conditions. Moreover, this model enables
generative extrapolation to project well-annotated data into unseen domains and
advancing rare object detection. Integrating synthesized images into ML
pipelines improves performance in standard morphology classification, boosting
completeness and purity by up to 30\% across key metrics. For rare object
detection, using early-type galaxies with prominent dust lane features (
$\sim$0.1\% in GZ2 dataset) as a test case, our approach doubled the number of
detected instances from 352 to 872, compared to previous studies based on
visual inspection. This study highlights the power of generative models to
bridge gaps between scarce labeled data and the vast, uncharted parameter space
of observational astronomy and sheds insight for future astrophysical
foundation model developments. Our project homepage is available at
https://galaxysd-webpage.streamlit.app/.</p></br>
