search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202507162000+TO+202507222000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, stat.*, cs.LG, physics.data-an staritng 202507162000 and ending 202507222000</h1>Feed last updated: 2025-07-22T00:00:00-04:00<a href="http://arxiv.org/pdf/2507.13033v1"><h2>(Exhaustive) Symbolic Regression and model selection by minimum
  description length</h2></a>Authors:  Harry Desmond</br>Comments: 15 pages, 4 figures; Invited review for the Royal Society
  Philosophical Transactions A special issue "Symbolic regression in the
  physical sciences"</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.CO, astro-ph.GA, cs.LG</br><p>Symbolic regression is the machine learning method for learning functions
from data. After a brief overview of the symbolic regression landscape, I will
describe the two main challenges that traditional algorithms face: they have an
unknown (and likely significant) probability of failing to find any given good
function, and they suffer from ambiguity and poorly-justified assumptions in
their function-selection procedure. To address these I propose an exhaustive
search and model selection by the minimum description length principle, which
allows accuracy and complexity to be directly traded off by measuring each in
units of information. I showcase the resulting publicly available Exhaustive
Symbolic Regression algorithm on three open problems in astrophysics: the
expansion history of the universe, the effective behaviour of gravity in
galaxies and the potential of the inflaton field. In each case the algorithm
identifies many functions superior to the literature standards. This general
purpose methodology should find widespread utility in science and beyond.</p></br><a href="http://arxiv.org/pdf/2507.15032v1"><h2>The hunt for new pulsating ultraluminous X-ray sources: a clustering
  approach</h2></a>Authors:  Nicolò Oreste Pinciroli Vago, Roberta Amato, Matteo Imbrogno, GianLuca Israel, Andrea Belfiore, Konstantinos Kovlakas, Piero Fraternali, Mario Pasquato</br>Comments: 16 pages, 8 figures; accepted in A&A</br>Primary Category: astro-ph.HE</br>All Categories: astro-ph.HE, astro-ph.IM, cs.AI, cs.LG</br><p>The discovery of fast and variable coherent signals in a handful of
ultraluminous X-ray sources (ULXs) testifies to the presence of super-Eddington
accreting neutron stars, and drastically changed the understanding of the ULX
class. Our capability of discovering pulsations in ULXs is limited, among
others, by poor statistics. However, catalogues and archives of high-energy
missions contain information which can be used to identify new candidate
pulsating ULXs (PULXs). The goal of this research is to single out candidate
PULXs among those ULXs which have not shown pulsations due to an unfavourable
combination of factors. We applied an AI approach to an updated database of
ULXs detected by XMM-Newton. We first used an unsupervised clustering algorithm
to sort out sources with similar characteristics into two clusters. Then, the
sample of known PULX observations has been used to set the separation threshold
between the two clusters and to identify the one containing the new candidate
PULXs. We found that only a few criteria are needed to assign the membership of
an observation to one of the two clusters. The cluster of new candidate PULXs
counts 85 unique sources for 355 observations, with $\sim$85% of these new
candidates having multiple observations. A preliminary timing analysis found no
new pulsations for these candidates. This work presents a sample of new
candidate PULXs observed by XMM-Newton, the properties of which are similar (in
a multi-dimensional phase space) to those of the known PULXs, despite the
absence of pulsations in their light curves. While this result is a clear
example of the predictive power of AI-based methods, it also highlights the
need for high-statistics observational data to reveal coherent signals from the
sources in this sample and thus validate the robustness of the approach.</p></br><a href="http://arxiv.org/pdf/2507.12784v1"><h2>A Semi-Supervised Learning Method for the Identification of Bad
  Exposures in Large Imaging Surveys</h2></a>Authors:  Yufeng Luo, Adam D. Myers, Alex Drlica-Wagner, Dario Dematties, Salma Borchani, Frank Valdes, Arjun Dey, David Schlegel, Rongpu Zhou, DESI Legacy Imaging Surveys Team</br>Comments: 21 pages, 12 figures</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI</br><p>As the data volume of astronomical imaging surveys rapidly increases,
traditional methods for image anomaly detection, such as visual inspection by
human experts, are becoming impractical. We introduce a machine-learning-based
approach to detect poor-quality exposures in large imaging surveys, with a
focus on the DECam Legacy Survey (DECaLS) in regions of low extinction (i.e.,
$E(B-V)<0.04$). Our semi-supervised pipeline integrates a vision transformer
(ViT), trained via self-supervised learning (SSL), with a k-Nearest Neighbor
(kNN) classifier. We train and validate our pipeline using a small set of
labeled exposures observed by surveys with the Dark Energy Camera (DECam). A
clustering-space analysis of where our pipeline places images labeled in
``good'' and ``bad'' categories suggests that our approach can efficiently and
accurately determine the quality of exposures. Applied to new imaging being
reduced for DECaLS Data Release 11, our pipeline identifies 780 problematic
exposures, which we subsequently verify through visual inspection. Being highly
efficient and adaptable, our method offers a scalable solution for quality
control in other large imaging surveys.</p></br><a href="http://arxiv.org/pdf/2507.14788v1"><h2>Impact of Geant4's Electromagnetic Physics Constructors on Accuracy and
  Performance of Simulations for Rare Event Searches</h2></a>Authors:  H. Kluck, R. Breier, A. Fuß, V. Mokina, V. Palušová, P. Povinec</br>Comments: 20 pages, 9 figures</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, physics.comp-ph, physics.data-an</br><p>A primary objective in contemporary low background physics is the search for
rare and novel phenomena beyond the Standard Model of particle physics, e.g.
the scattering off of a potential Dark Matter particle or the neutrinoless
double beta decay. The success of such searches depends on a reliable
background prediction via Monte Carlo simulations. A widely used toolkit to
construct these simulations is Geant4, which offers the user a wide choice of
how to model the physics of particle interactions. For example, for
electromagnetic interactions, Geant4 provides pre-defined sets of models:
physics constructors. As decay products of radioactive contaminants contribute
to the background mainly via electromagnetic interactions, the physics
constructor used in a Geant4 simulation may have an impact on the total energy
deposition inside the detector target. To facilitate the selection of physics
constructors for simulations of experiments that are using CaWO$_\mathrm{4}$
and Ge targets, we quantify their impact on the total energy deposition for
several test cases. These cases consist of radioactive contaminants commonly
encountered, covering energy depositions via $\alpha$, $\beta$, and $\gamma$
particles, as well as two examples for the target thickness: thin and bulky. We
also consider the computing performance of the studied physics constructors.</p></br><a href="http://arxiv.org/pdf/2507.15775v1"><h2>Learning Null Geodesics for Gravitational Lensing Rendering in General
  Relativity</h2></a>Authors:  Mingyuan Sun, Zheng Fang, Jiaxu Wang, Kunyi Zhang, Qiang Zhang, Renjing Xu</br>Comments: ICCV 2025</br>Primary Category: gr-qc</br>All Categories: gr-qc, astro-ph.IM, cs.AI</br><p>We present GravLensX, an innovative method for rendering black holes with
gravitational lensing effects using neural networks. The methodology involves
training neural networks to fit the spacetime around black holes and then
employing these trained models to generate the path of light rays affected by
gravitational lensing. This enables efficient and scalable simulations of black
holes with optically thin accretion disks, significantly decreasing the time
required for rendering compared to traditional methods. We validate our
approach through extensive rendering of multiple black hole systems with
superposed Kerr metric, demonstrating its capability to produce accurate
visualizations with significantly $15\times$ reduced computational time. Our
findings suggest that neural networks offer a promising alternative for
rendering complex astrophysical phenomena, potentially paving a new path to
astronomical visualization.</p></br><a href="http://arxiv.org/pdf/2507.15027v1"><h2>Harnessing PyStoch potential: detecting continuous gravitational waves
  from interesting supernova remnant targets</h2></a>Authors:  Claudio Salvadore, Iuri La Rosa, Paola Leaci, Francesco Amicucci, Pia Astone, Sabrina D'Antonio, Luca D'Onofrio, Cristiano Palomba, Lorenzo Pierini, Francesco Safai Tehrani</br>Comments: 10 pages, 5 figures</br>Primary Category: astro-ph.HE</br>All Categories: astro-ph.HE, physics.data-an</br><p>Detecting continuous gravitational waves (CWs) is challenging due to their
weak amplitude and high computational demands, especially with poorly
constrained source parameters. Stochastic gravitational-wave background (SGWB)
searches using cross-correlation techniques can identify unresolved
astrophysical sources, including CWs, at lower computational cost, albeit with
reduced sensitivity. This motivates a hybrid approach where SGWB algorithms act
as a first-pass filter to identify CW candidates for follow-up with dedicated
CW pipelines.
  We evaluated the discovery potential of the SGWB analysis tool PyStoch for
detecting CWs, using simulated signals from spinning down NSs. We then applied
the method to data from the third LIGO-Virgo-KAGRA observing run (O3), covering
the (20-1726) Hz frequency band, and targeting four supernova remnants: Vela
Jr., G347.3-0.5, Cassiopeia A, and the NS associated with the 1987A supernova
remnant. If necessary, significant candidates are followed up using the
5-vector Resampling and Band-Sampled Data Frequency-Hough techniques. However,
since no interesting candidates were identified in the real O3 analysis, we set
95\% confidence-level upper limits on the CW strain amplitude $h_0$. The most
stringent limit was obtained for Cassiopeia A, and is $h_0 = 1.13 \times
10^{-25}$ at $201.57$ Hz with a frequency resolution of $1/32$ Hz. As for the
other targets, the best upper limits have been set with the same frequency
resolution, and correspond to $h_0 = 1.20 \times 10^{-25} $ at $202.16$ Hz for
G347.3-0.5, $1.20 \times 10^{-25}$ at $217.81$ Hz for Vela Jr., and $1.47
\times 10^{-25}$ at $186.41$ Hz for the NS in the 1987A supernova remnant.</p></br>
