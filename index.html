search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202502042000+TO+202502102000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, stat.*, cs.LG, physics.data-an staritng 202502042000 and ending 202502102000</h1>Feed last updated: 2025-02-09T00:00:00-05:00<a href="http://arxiv.org/pdf/2502.03139v1"><h2>Fast Sampling of Cosmological Initial Conditions with Gaussian Neural
  Posterior Estimation</h2></a>Authors:  Oleg Savchenko, Guillermo Franco Abellán, Florian List, Noemi Anau Montel, Christoph Weniger</br>Comments: 9 + 2 pages, 7 figures, 1 table. Comments welcome!</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, astro-ph.IM, cs.LG</br><p>Knowledge of the primordial matter density field from which the large-scale
structure of the Universe emerged over cosmic time is of fundamental importance
for cosmology. However, reconstructing these cosmological initial conditions
from late-time observations is a notoriously difficult task, which requires
advanced cosmological simulators and sophisticated statistical methods to
explore a multi-million-dimensional parameter space. We show how
simulation-based inference (SBI) can be used to tackle this problem and to
obtain data-constrained realisations of the primordial dark matter density
field in a simulation-efficient way with general non-differentiable simulators.
Our method is applicable to full high-resolution dark matter $N$-body
simulations and is based on modelling the posterior distribution of the
constrained initial conditions to be Gaussian with a diagonal covariance matrix
in Fourier space. As a result, we can generate thousands of posterior samples
within seconds on a single GPU, orders of magnitude faster than existing
methods, paving the way for sequential SBI for cosmological fields.
Furthermore, we perform an analytical fit of the estimated dependence of the
covariance on the wavenumber, effectively transforming any point-estimator of
initial conditions into a fast sampler. We test the validity of our obtained
samples by comparing them to the true values with summary statistics and
performing a Bayesian consistency test.</p></br><a href="http://arxiv.org/pdf/2502.02717v1"><h2>Astromer 2</h2></a>Authors:  Cristobal Donoso-Oliva, Ignacio Becker, Pavlos Protopapas, Guillermo Cabrera-Vives, Martina Cádiz-Leyton, Daniel Moreno-Cartagena</br>Comments: 10 pages, 17 figures</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI, cs.LG</br><p>Foundational models have emerged as a powerful paradigm in deep learning
field, leveraging their capacity to learn robust representations from
large-scale datasets and effectively to diverse downstream applications such as
classification. In this paper, we present Astromer 2 a foundational model
specifically designed for extracting light curve embeddings. We introduce
Astromer 2 as an enhanced iteration of our self-supervised model for light
curve analysis. This paper highlights the advantages of its pre-trained
embeddings, compares its performance with that of its predecessor, Astromer 1,
and provides a detailed empirical analysis of its capabilities, offering deeper
insights into the model's representations. Astromer 2 is pretrained on 1.5
million single-band light curves from the MACHO survey using a self-supervised
learning task that predicts randomly masked observations within sequences.
Fine-tuning on a smaller labeled dataset allows us to assess its performance in
classification tasks. The quality of the embeddings is measured by the F1 score
of an MLP classifier trained on Astromer-generated embeddings. Our results
demonstrate that Astromer 2 significantly outperforms Astromer 1 across all
evaluated scenarios, including limited datasets of 20, 100, and 500 samples per
class. The use of weighted per-sample embeddings, which integrate intermediate
representations from Astromer's attention blocks, is particularly impactful.
Notably, Astromer 2 achieves a 15% improvement in F1 score on the ATLAS dataset
compared to prior models, showcasing robust generalization to new datasets.
This enhanced performance, especially with minimal labeled data, underscores
the potential of Astromer 2 for more efficient and scalable light curve
analysis.</p></br>
