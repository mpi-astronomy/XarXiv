search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202505132000+TO+202505192000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, cs.LG, stat.*, physics.data-an staritng 202505132000 and ending 202505192000</h1>Feed last updated: 2025-05-19T00:00:00-04:00<a href="http://arxiv.org/pdf/2505.11053v1"><h2>Conceptual framework for the application of deep neural networks to
  surface composition reconstruction from Mercury's exospheric data</h2></a>Authors:  Adrian Kazakov, Anna Milillo, Alessandro Mura, Stavro Ivanovski, Valeria Mangano, Alessandro Aronica, Elisabetta De Angelis, Pier Paolo Di Bartolomeo, Alessandro Brin, Luca Colasanti, Miguel Escalona-Moran, Francesco Lazzarotto, Stefano Massetti, Martina Moroni, Raffaella Noschese, Fabrizio Nuccilli, Stefano Orsini, Christina Plainaki, Rosanna Rispoli, Roberto Sordini, Mirko Stumpo, Nello Vertolli</br>Comments: All versions of this article can be explored in the collection: DOI
  https://doi.org/10.5281/zenodo.15394849 . This article is identical to v2.5
  of the aforementioned collection: DOI https://doi.org/10.5281/zenodo.15425584</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>Surface information derived from exospheric measurements at planetary bodies
complements surface mapping provided by dedicated imagers, offering critical
insights into surface release processes, interactions within the planetary
environment, space weathering, and planetary evolution. This study explores the
feasibility of deriving Mercury's regolith elemental composition from in-situ
measurements of its neutral exosphere using deep neural networks (DNNs). We
present a supervised feed-forward DNN architecture - a multilayer perceptron
(MLP) - that, starting from exospheric densities and proton precipitation
fluxes, predicts the chemical elements of the surface regolith below. It serves
as an estimator for the surface-exosphere interaction and the processes leading
to exosphere formation. Because the DNN requires a comprehensive exospheric
dataset not available from previous missions, this study uses simulated
exosphere components and simulated drivers. Extensive training and testing
campaigns demonstrate the MLP's ability to accurately predict and reconstruct
surface composition maps from these simulated measurements. Although this
initial version does not aim to reproduce Mercury's actual surface composition,
it provides a proof of concept, showcasing the algorithm's robustness and
capacity for handling complex datasets to create estimators for exospheric
generation models. Moreover, our tests reveal substantial potential for further
development, suggesting that this method could significantly enhance the
analysis of complex surface-exosphere interactions and complement planetary
exosphere models. This work anticipates applying the approach to data from the
BepiColombo mission, specifically the SERENA package, whose nominal phase
begins in 2027.</p></br><a href="http://arxiv.org/pdf/2505.09365v1"><h2>ARCANE -- Early Detection of Interplanetary Coronal Mass Ejections</h2></a>Authors:  H. T. Rüdisser, G. Nguyen, J. Le Louëdec, C. Möstl</br>Comments: 25 pages, 9 figures, 1 table, submitted to AGU Space Weather on 14th
  May 2025</br>Primary Category: physics.space-ph</br>All Categories: physics.space-ph, astro-ph.IM, astro-ph.SR, cs.LG</br><p>Interplanetary coronal mass ejections (ICMEs) are major drivers of space
weather disturbances, posing risks to both technological infrastructure and
human activities. Automatic detection of ICMEs in solar wind in situ data is
essential for early warning systems. While several methods have been proposed
to identify these structures in time series data, robust real-time detection
remains a significant challenge. In this work, we present ARCANE - the first
framework explicitly designed for early ICME detection in streaming solar wind
data under realistic operational constraints, enabling event identification
without requiring observation of the full structure. Our approach evaluates the
strengths and limitations of detection models by comparing a machine
learning-based method to a threshold-based baseline. The ResUNet++ model,
previously validated on science data, significantly outperforms the baseline,
particularly in detecting high-impact events, while retaining solid performance
on lower-impact cases. Notably, we find that using real-time solar wind (RTSW)
data instead of high-resolution science data leads to only minimal performance
degradation. Despite the challenges of operational settings, our detection
pipeline achieves an F1 score of 0.53, with an average detection delay of 21.5%
of the event's duration while only seeing a minimal amount of data. As more
data becomes available, the performance increases significantly. These results
mark a substantial step forward in automated space weather monitoring and lay
the groundwork for enhanced real-time forecasting capabilities.</p></br><a href="http://arxiv.org/pdf/2505.08940v1"><h2>NeurIPS 2024 Ariel Data Challenge: Characterisation of Exoplanetary
  Atmospheres Using a Data-Centric Approach</h2></a>Authors:  Jeremie Blanchard, Lisa Casino, Jordan Gierschendorf</br>Comments: 12 pages</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.IM</br><p>The characterization of exoplanetary atmospheres through spectral analysis is
a complex challenge. The NeurIPS 2024 Ariel Data Challenge, in collaboration
with the European Space Agency's (ESA) Ariel mission, provided an opportunity
to explore machine learning techniques for extracting atmospheric compositions
from simulated spectral data. In this work, we focus on a data-centric business
approach, prioritizing generalization over competition-specific optimization.
We briefly outline multiple experimental axes, including feature extraction,
signal transformation, and heteroskedastic uncertainty modeling. Our
experiments demonstrate that uncertainty estimation plays a crucial role in the
Gaussian Log-Likelihood (GLL) score, impacting performance by several
percentage points. Despite improving the GLL score by 11%, our results
highlight the inherent limitations of tabular modeling and feature engineering
for this task, as well as the constraints of a business-driven approach within
a Kaggle-style competition framework. Our findings emphasize the trade-offs
between model simplicity, interpretability, and generalization in astrophysical
data analysis.</p></br><a href="http://arxiv.org/pdf/2505.10283v1"><h2>Comparative Analysis of Richardson-Lucy Deconvolution and Data Unfolding
  with Mean Integrated Square Error Optimization</h2></a>Authors:  Nikolay D. Gagunashvili</br>Comments: 15 pages, 18 figures</br>Primary Category: physics.data-an</br>All Categories: physics.data-an, astro-ph.IM, hep-ex, nucl-ex, stat.AP, 62-07 (Primary), 62F03, 62F10, 62P35, 62P30 (Secondary)</br><p>Two maximum likelihood-based algorithms for unfolding or deconvolution are
considered: the Richardson-Lucy method and the Data Unfolding method with Mean
Integrated Square Error (MISE) optimization [10]. Unfolding is viewed as a
procedure for estimating an unknown probability density function. Both external
and internal quality assessment methods can be applied for this purpose. In
some cases, external criteria exist to evaluate deconvolution quality. A
typical example is the deconvolution of a blurred image, where the sharpness of
the restored image serves as an indicator of quality. However, defining such
external criteria can be challenging, particularly when a measurement has not
been performed previously. In such instances, internal criteria are necessary
to assess the quality of the result independently of external information. The
article discusses two internal criteria: MISE for the unfolded distribution and
the condition number of the correlation matrix of the unfolded distribution.
These internal quality criteria are applied to a comparative analysis of the
two methods using identical numerical data. The results of the analysis
demonstrate the superiority of the Data Unfolding method with MISE optimization
over the Richardson-Lucy method.</p></br><a href="http://arxiv.org/pdf/2505.10299v1"><h2>Nature-inspired optimization, the Philippine Eagle, and cosmological
  parameter estimation</h2></a>Authors:  Reginald Christian Bernardo, Erika Antonette Enriquez, Renier Mendoza, Reinabelle Reyes, Arrianne Crystal Velasco</br>Comments: 24 pages + refs, 13 figures, comments welcome</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, physics.comp-ph, physics.data-an</br><p>Precise and accurate estimation of cosmological parameters is crucial for
understanding the Universe's dynamics and addressing cosmological tensions. In
this methods paper, we explore bio-inspired metaheuristic algorithms, including
the Improved Multi-Operator Differential Evolution scheme and the Philippine
Eagle Optimization Algorithm (PEOA), alongside the relatively known genetic
algorithm, for cosmological parameter estimation. Using mock data that underlay
a true fiducial cosmology, we test the viability of each optimization method to
recover the input cosmological parameters with confidence regions generated by
bootstrapping on top of optimization. We compare the results with Markov chain
Monte Carlo (MCMC) in terms of accuracy and precision, and show that PEOA
performs comparably well under the specific circumstances provided.
Understandably, Bayesian inference and optimization serve distinct purposes,
but comparing them highlights the potential of nature-inspired algorithms in
cosmological analysis, offering alternative pathways to explore parameter
spaces and validate standard results.</p></br>
