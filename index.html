search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202409042000+TO+202409102000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, physics.data-an, stat.*, cs.LG staritng 202409042000 and ending 202409102000</h1>Feed last updated: 2024-09-10T00:00:00-04:00<a href="http://arxiv.org/pdf/2409.05482v1"><h2>Advancing Machine Learning for Stellar Activity and Exoplanet Period
  Rotation</h2></a>Authors:  Fatemeh Fazel Hesar, Bernard Foing, Ana M. Heras, Mojtaba Raouf, Victoria Foing, Shima Javanmardi, Fons J. Verbeek</br>Comments: 15 pages, 8 figures. Submitted for publication in A&A</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, astro-ph.EP, astro-ph.IM, cs.LG</br><p>This study applied machine learning models to estimate stellar rotation
periods from corrected light curve data obtained by the NASA Kepler mission.
Traditional methods often struggle to estimate rotation periods accurately due
to noise and variability in the light curve data. The workflow involved using
initial period estimates from the LS-Periodogram and Transit Least Squares
techniques, followed by splitting the data into training, validation, and
testing sets. We employed several machine learning algorithms, including
Decision Tree, Random Forest, K-Nearest Neighbors, and Gradient Boosting, and
also utilized a Voting Ensemble approach to improve prediction accuracy and
robustness.
  The analysis included data from multiple Kepler IDs, providing detailed
metrics on orbital periods and planet radii. Performance evaluation showed that
the Voting Ensemble model yielded the most accurate results, with an RMSE
approximately 50\% lower than the Decision Tree model and 17\% better than the
K-Nearest Neighbors model. The Random Forest model performed comparably to the
Voting Ensemble, indicating high accuracy. In contrast, the Gradient Boosting
model exhibited a worse RMSE compared to the other approaches. Comparisons of
the predicted rotation periods to the photometric reference periods showed
close alignment, suggesting the machine learning models achieved high
prediction accuracy. The results indicate that machine learning, particularly
ensemble methods, can effectively solve the problem of accurately estimating
stellar rotation periods, with significant implications for advancing the study
of exoplanets and stellar astrophysics.</p></br><a href="http://arxiv.org/pdf/2409.03466v1"><h2>Panopticon: a novel deep learning model to detect single transit events
  with no prior data filtering in PLATO light curves</h2></a>Authors:  H. G. Vivien, M. Deleuil, N. Jannsen, J. De Ridder, D. Seynaeve, M. -A. Carpine, Y. Zerah</br>Comments: Submitted to A&A</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>To prepare for the analyses of the future PLATO light curves, we develop a
deep learning model, Panopticon, to detect transits in high precision
photometric light curves. Since PLATO's main objective is the detection of
temperate Earth-size planets around solar-type stars, the code is designed to
detect individual transit events. The filtering step, required by conventional
detection methods, can affect the transit, which could be an issue for long and
shallow transits. To protect transit shape and depth, the code is also designed
to work on unfiltered light curves. We trained the model on a set of simulated
PLATO light curves in which we injected, at pixel level, either planetary,
eclipsing binary, or background eclipsing binary signals. We also include a
variety of noises in our data, such as granulation, stellar spots or cosmic
rays. The approach is able to recover 90% of our test population, including
more than 25% of the Earth-analogs, even in the unfiltered light curves. The
model also recovers the transits irrespective of the orbital period, and is
able to retrieve transits on a unique event basis. These figures are obtained
when accepting a false alarm rate of 1%. When keeping the false alarm rate low
(<0.01%), it is still able to recover more than 85% of the transit signals. Any
transit deeper than 180ppm is essentially guaranteed to be recovered. This
method is able to recover transits on a unique event basis, and does so with a
low false alarm rate. Thanks to light curves being one-dimensional, model
training is fast, on the order of a few hours per model. This speed in training
and inference, coupled to the recovery effectiveness and precision of the model
make it an ideal tool to complement, or be used ahead of, classical approaches.</p></br><a href="http://arxiv.org/pdf/2409.04557v1"><h2>DeepTTV: Deep Learning Prediction of Hidden Exoplanet From Transit
  Timing Variations</h2></a>Authors:  Chen Chen, Lingkai Kong, Gongjie Li, Molei Tao</br>Comments: 13 pages, 6 figures and 5 tables submitted to AAS journals, comments
  welcome</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>Transit timing variation (TTV) provides rich information about the mass and
orbital properties of exoplanets, which are often obtained by solving an
inverse problem via Markov Chain Monte Carlo (MCMC). In this paper, we design a
new data-driven approach, which potentially can be applied to problems that are
hard to traditional MCMC methods, such as the case with only one planet
transiting. Specifically, we use a deep learning approach to predict the
parameters of non-transit companion for the single transit system with transit
information (i.e., TTV, and Transit Duration Variation (TDV)) as input. Thanks
to a newly constructed \textit{Transformer}-based architecture that can extract
long-range interactions from TTV sequential data, this previously difficult
task can now be accomplished with high accuracy, with an overall fractional
error of $\sim$2\% on mass and eccentricity.</p></br><a href="http://arxiv.org/pdf/2409.04542v1"><h2>Towards Hybrid Embedded Feature Selection and Classification Approach
  with Slim-TSF</h2></a>Authors:  Anli Ji, Chetraj Pandey, Berkay Aydin</br>Comments: This is a preprint accepted at the 26th International Conference on
  Big Data Analytics and Knowledge Discovery (DAWAK 2024)</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.IM, astro-ph.SR</br><p>Traditional solar flare forecasting approaches have mostly relied on
physics-based or data-driven models using solar magnetograms, treating flare
predictions as a point-in-time classification problem. This approach has
limitations, particularly in capturing the evolving nature of solar activity.
Recognizing the limitations of traditional flare forecasting approaches, our
research aims to uncover hidden relationships and the evolutionary
characteristics of solar flares and their source regions. Our previously
proposed Sliding Window Multivariate Time Series Forest (Slim-TSF) has shown
the feasibility of usage applied on multivariate time series data. A
significant aspect of this study is the comparative analysis of our updated
Slim-TSF framework against the original model outcomes. Preliminary findings
indicate a notable improvement, with an average increase of 5\% in both the
True Skill Statistic (TSS) and Heidke Skill Score (HSS). This enhancement not
only underscores the effectiveness of our refined methodology but also suggests
that our systematic evaluation and feature selection approach can significantly
advance the predictive accuracy of solar flare forecasting models.</p></br><a href="http://arxiv.org/pdf/2409.03833v1"><h2>AI forecasting of higher-order wave modes of spinning binary black hole
  mergers</h2></a>Authors:  Victoria Tiki, Kiet Pham, Eliu Huerta</br>Comments: 27 pages, 1 appendix, 10 figures</br>Primary Category: gr-qc</br>All Categories: gr-qc, astro-ph.IM, cs.AI, 68T10, 85-08, 83C35, 83C57, I.2</br><p>We present a physics-inspired transformer model that predicts the non-linear
dynamics of higher-order wave modes emitted by quasi-circular, spinning,
non-precessing binary black hole mergers. The model forecasts the waveform
evolution from the pre-merger phase through the ringdown, starting with an
input time-series spanning $ t \in [-5000\textrm{M}, -100\textrm{M}) $. The
merger event, defined as the peak amplitude of waveforms that include the $l =
|m| = 2$ modes, occurs at $ t = 0\textrm{M} $. The transformer then generates
predictions over the time range $ t \in [-100\textrm{M}, 130\textrm{M}] $. We
produced training, evaluation and test sets using the NRHybSur3dq8 model,
considering a signal manifold defined by mass ratios $ q \in [1, 8] $; spin
components $ s^z_{\{1,2\}} \in [-0.8, 0.8] $; modes up to $l \leq 4$, including
the $(5,5)$ mode but excluding the $(4,0)$ and $(4,1)$ modes; and inclination
angles $\theta \in [0, \pi]$. We trained the model on 14,440,761 waveforms,
completing the training in 15 hours using 16 NVIDIA A100 GPUs in the Delta
supercomputer. We used 4 H100 GPUs in the DeltaAI supercomputer to compute,
within 7 hours, the overlap between ground truth and predicted waveforms using
a test set of 840,000 waveforms, finding that the mean and median overlaps over
the test set are 0.996 and 0.997, respectively. Additionally, we conducted
interpretability studies to elucidate the waveform features utilized by our
transformer model to produce accurate predictions. The scientific software used
for this work is released with this manuscript.</p></br>
