search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202502222000+TO+202502282000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, stat.*, cs.LG, physics.data-an staritng 202502222000 and ending 202502282000</h1>Feed last updated: 2025-02-27T00:00:00-05:00<a href="http://arxiv.org/pdf/2502.17563v1"><h2>Utilizing Machine Learning to Predict Host Stars and the Key Elemental
  Abundances of Small Planets</h2></a>Authors:  Am√≠lcar R. Torres-Quijano, Natalie R. Hinkel, Caleb H. Wheeler III, Patrick A. Young, Luan Ghezzi, Augusto P. Baldo</br>Comments: 22 pages, 9 figures, 3 tables, accepted to AJ</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, astro-ph.SR, cs.LG</br><p>Stars and their associated planets originate from the same cloud of gas and
dust, making a star's elemental composition a valuable indicator for indirectly
studying planetary compositions. While the connection between a star's iron
(Fe) abundance and the presence of giant exoplanets is established (e.g.
Gonzalez 1997; Fischer & Valenti 2005), the relationship with small planets
remains unclear. The elements Mg, Si, and Fe are important in forming small
planets. Employing machine learning algorithms like XGBoost, trained on the
abundances (e.g., the Hypatia Catalog, Hinkel et al. 2014) of known
exoplanet-hosting stars (NASA Exoplanet Archive), allows us to determine
significant "features" (abundances or molar ratios) that may indicate the
presence of small planets. We test on three groups of exoplanets: (a) all
small, R$_{P}$ $<$ 3.5 $R_{\oplus}$, (b) sub-Neptunes, 2.0 $R_{\oplus}$ $<$
R$_{P}$ $<$ 3.5 $R_{\oplus}$, and (c) super-Earths, 1.0 $R_{\oplus}$ $<$
R$_{P}$ $<$ 2.0 $R_{\oplus}$ -- each subdivided into 7 ensembles to test
different combinations of features. We created a list of stars with $\geq90\%$
probability of hosting small planets across all ensembles and experiments
("overlap stars"). We found abundance trends for stars hosting small planets,
possibly indicating star-planet chemical interplay during formation. We also
found that Na and V are key features regardless of planetary radii. We expect
our results to underscore the importance of elements in exoplanet formation and
machine learning's role in target selection for future NASA missions: e.g., the
James Webb Space Telescope (JWST), Nancy Grace Roman Space Telescope (NGRST),
Habitable Worlds Observatory (HWO) -- all of which are aimed at small planet
detection.</p></br><a href="http://arxiv.org/pdf/2502.16455v1"><h2>Asteroid shape inversion with light curves using deep learning</h2></a>Authors:  YiJun Tang, ChenChen Ying, ChengZhe Xia, XiaoMing Zhang, XiaoJun Jiang</br>Comments: No comment found</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>Asteroid shape inversion using photometric data has been a key area of study
in planetary science and astronomical research.However, the current methods for
asteroid shape inversion require extensive iterative calculations, making the
process time-consuming and prone to becoming stuck in local optima. We directly
established a mapping between photometric data and shape distribution through
deep neural networks. In addition, we used 3D point clouds to represent
asteroid shapes and utilized the deviation between the light curves of
non-convex asteroids and their convex hulls to predict the concave areas of
non-convex asteroids. We compared the results of different shape models using
the Chamfer distance between traditional methods and ours and found that our
method performs better, especially when handling special shapes. For the
detection of concave areas on the convex hull, the intersection over union
(IoU) of our predictions reached 0.89. We further validated this method using
observational data from the Lowell Observatory to predict the convex shapes of
the asteroids 3337 Milo and 1289 Kuta, and conducted light curve fitting
experiments. The experimental results demonstrated the robustness and
adaptability of the method</p></br><a href="http://arxiv.org/pdf/2502.18045v1"><h2>Near-instantaneous Atmospheric Retrievals and Model Comparison with
  FASTER</h2></a>Authors:  Anna Lueber, Konstantin Karchev, Chloe Fisher, Matthias Heim, Roberto Trotta, Kevin Heng</br>Comments: 14 pages, 7 figures, 1 table. Comments welcome</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, physics.data-an</br><p>In the era of the James Webb Space Telescope (JWST), the dramatic improvement
in the spectra of exoplanetary atmospheres demands a corresponding leap forward
in our ability to analyze them: atmospheric retrievals need to be performed on
thousands of spectra, applying to each large ensembles of models (that explore
atmospheric chemistry, thermal profiles and cloud models) to identify the best
one(s). In this limit, traditional Bayesian inference methods such as nested
sampling become prohibitively expensive. We introduce FASTER (Fast Amortized
Simulation-based Transiting Exoplanet Retrieval), a neural-network based method
for performing atmospheric retrieval and Bayesian model comparison at a
fraction of the computational cost of classical techniques. We demonstrate that
the marginal posterior distributions of all parameters within a model as well
as the posterior probabilities of the models we consider match those computed
using nested sampling both on mock spectra, and for the real NIRSpec PRISM
spectrum of WASP-39b. The true power of the FASTER framework comes from its
amortized nature, which allows the trained networks to perform practically
instantaneous Bayesian inference and model comparison over ensembles of spectra
-- real or simulated -- at minimal additional computational cost. This offers
valuable insight into the expected results of model comparison (e.g.,
distinguishing cloudy from cloud-free and isothermal from non-isothermal
models), as well as their dependence on the underlying parameters, which is
computationally unfeasible with nested sampling. This approach will constitute
as large a leap in spectral analysis as the original retrieval methods based on
Markov Chain Monte Carlo have proven to be.</p></br><a href="http://arxiv.org/pdf/2502.18558v1"><h2>Transfer Learning for Transient Classification: From Simulations to Real
  Data and ZTF to LSST</h2></a>Authors:  Rithwik Gupta, Daniel Muthukrishna</br>Comments: 6 pages, 3 figures, 1 table</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.HE, cs.LG</br><p>Machine learning has become essential for automated classification of
astronomical transients, but current approaches face significant limitations:
classifiers trained on simulations struggle with real data, models developed
for one survey cannot be easily applied to another, and new surveys require
prohibitively large amounts of labelled training data. These challenges are
particularly pressing as we approach the era of the Vera Rubin Observatory's
Legacy Survey of Space and Time (LSST), where existing classification models
will need to be retrained using LSST observations. We demonstrate that transfer
learning can overcome these challenges by repurposing existing models trained
on either simulations or data from other surveys. Starting with a model trained
on simulated Zwicky Transient Facility (ZTF) light curves, we show that
transfer learning reduces the amount of labelled real ZTF transients needed by
75\% while maintaining equivalent performance to models trained from scratch.
Similarly, when adapting ZTF models for LSST simulations, transfer learning
achieves 95\% of the baseline performance while requiring only 30\% of the
training data. These findings have significant implications for the early
operations of LSST, suggesting that reliable automated classification will be
possible soon after the survey begins, rather than waiting months or years to
accumulate sufficient training data.</p></br><a href="http://arxiv.org/pdf/2502.18218v1"><h2>FLARE: A Framework for Stellar Flare Forecasting using Stellar Physical
  Properties and Historical Records</h2></a>Authors:  Bingke Zhu, Xiaoxiao Wang, Minghui Jia, Yihan Tao, Xiao Kong, Ali Luo, Yingying Chen, Ming Tang, Jinqiao Wang</br>Comments: No comment found</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, astro-ph.IM, cs.AI</br><p>Stellar flare events are critical observational samples for astronomical
research; however, recorded flare events remain limited. Stellar flare
forecasting can provide additional flare event samples to support research
efforts. Despite this potential, no specialized models for stellar flare
forecasting have been proposed to date. In this paper, we present extensive
experimental evidence demonstrating that both stellar physical properties and
historical flare records are valuable inputs for flare forecasting tasks. We
then introduce FLARE (Forecasting Light-curve-based Astronomical Records via
features Ensemble), the first-of-its-kind large model specifically designed for
stellar flare forecasting. FLARE integrates stellar physical properties and
historical flare records through a novel Soft Prompt Module and Residual Record
Fusion Module. Our experiments on the publicly available Kepler light curve
dataset demonstrate that FLARE achieves superior performance compared to other
methods across all evaluation metrics. Finally, we validate the forecast
capability of our model through a comprehensive case study.</p></br><a href="http://arxiv.org/pdf/2502.17087v1"><h2>Conditional Diffusion-Flow models for generating 3D cosmic density
  fields: applications to f(R) cosmologies</h2></a>Authors:  Julieth Katherine Riveros, Paola Saavedra, Hector J. Hortua, Jorge Enrique Garcia-Farieta, Ivan Olier</br>Comments: 13 pages comments welcome</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, cs.AI</br><p>Next-generation galaxy surveys promise unprecedented precision in testing
gravity at cosmological scales. However, realising this potential requires
accurately modelling the non-linear cosmic web. We address this challenge by
exploring conditional generative modelling to create 3D dark matter density
fields via score-based (diffusion) and flow-based methods. Our results
demonstrate the power of diffusion models to accurately reproduce the matter
power spectra and bispectra, even for unseen configurations. They also offer a
significant speed-up with slightly reduced accuracy, when flow-based
reconstructing the probability distribution function, but they struggle with
higher-order statistics. To improve conditional generation, we introduce a
novel multi-output model to develop feature representations of the cosmological
parameters. Our findings offer a powerful tool for exploring deviations from
standard gravity, combining high precision with reduced computational cost,
thus paving the way for more comprehensive and efficient cosmological analyses</p></br><a href="http://arxiv.org/pdf/2502.18327v1"><h2>Sparsity covariance: a source of uncertainty when estimating correlation
  functions with a discrete sample of observations in the sky</h2></a>Authors:  Pierre Fleury</br>Comments: 12 + 4 pages, 6 figures</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, physics.data-an</br><p>Cosmological observables rely heavily on summary statistics such as two-point
correlation functions. In many practical cases (e.g. the weak-lensing cosmic
shear), those correlation functions are estimated from a finite, discrete
sample of measurements that are randomly distributed in the sky. The result
then inevitably depends on the sample at hand, regardless of any experimental
noise. This sample dependence is a source of uncertainty for cosmological
observables which I call sparsity covariance. This article proposes a
mathematical definition and a generic method to compute sparsity covariance. It
is then applied to the concrete case of cosmic shear, showing that sparsity
covariance mostly enhances shape noise, whose amplitude is determined by the
apparent ellipticity of galaxies rather than their intrinsic ellipticity. In
general, sparsity covariance is non-negligible when the signal-to-noise ratio
of individual measurements in the sample is comparable to, or larger than,
unity.</p></br><a href="http://arxiv.org/pdf/2502.19824v1"><h2>Shared Stochastic Gaussian Process Latent Variable Models: A Multi-modal
  Generative Model for Quasar Spectra</h2></a>Authors:  Vidhi Lalchand, Anna-Christina Eilers</br>Comments: Published in TMLR, https://openreview.net/pdf?id=LzmsvRTqaJ. The code
  for this work is available at: https://github.com/vr308/Quasar-GPLVM</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, cs.LG, stat.AP, stat.ME, 85A04 (Primary), 62M45 (Primary), 62H30 (Secondary), 60G15
  (Secondary), 85A40 (Secondary), G.3; I.2.6</br><p>This work proposes a scalable probabilistic latent variable model based on
Gaussian processes (Lawrence, 2004) in the context of multiple observation
spaces. We focus on an application in astrophysics where data sets typically
contain both observed spectral features and scientific properties of
astrophysical objects such as galaxies or exoplanets. In our application, we
study the spectra of very luminous galaxies known as quasars, along with their
properties, such as the mass of their central supermassive black hole,
accretion rate, and luminosity-resulting in multiple observation spaces. A
single data point is then characterized by different classes of observations,
each with different likelihoods. Our proposed model extends the baseline
stochastic variational Gaussian process latent variable model (GPLVM)
introduced by Lalchand et al. (2022) to this setting, proposing a seamless
generative model where the quasar spectra and scientific labels can be
generated simultaneously using a shared latent space as input to different sets
of Gaussian process decoders, one for each observation space. Additionally,
this framework enables training in a missing data setting where a large number
of dimensions per data point may be unknown or unobserved. We demonstrate
high-fidelity reconstructions of the spectra and scientific labels during
test-time inference and briefly discuss the scientific interpretations of the
results, along with the significance of such a generative model.</p></br>
