search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202407112000+TO+202407172000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, cs.LG, physics.data-an, stat.* staritng 202407112000 and ending 202407172000</h1>Feed last updated: 2024-07-17T00:00:00-04:00<a href="http://arxiv.org/pdf/2407.11194v1"><h2>AstroMLab 1: Who Wins Astronomy Jeopardy!?</h2></a>Authors:  Yuan-Sen Ting, Tuan Dung Nguyen, Tirthankar Ghosal, Rui Pan, Hardik Arora, Zechang Sun, Tijmen de Haan, Nesar Ramachandra, Azton Wells, Sandeep Madireddy, Alberto Accomazzi</br>Comments: 45 pages, 12 figures, 7 tables. Submitted to ApJ. Comments welcome.
  AstroMLab homepage: https://astromlab.org/</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.EP, astro-ph.GA, astro-ph.SR, cs.AI, cs.CL</br><p>We present a comprehensive evaluation of proprietary and open-weights large
language models using the first astronomy-specific benchmarking dataset. This
dataset comprises 4,425 multiple-choice questions curated from the Annual
Review of Astronomy and Astrophysics, covering a broad range of astrophysical
topics. Our analysis examines model performance across various astronomical
subfields and assesses response calibration, crucial for potential deployment
in research environments. Claude-3.5-Sonnet outperforms competitors by up to
4.6 percentage points, achieving 85.0% accuracy. For proprietary models, we
observed a universal reduction in cost every 3-to-12 months to achieve similar
score in this particular astronomy benchmark. Open-source models have rapidly
improved, with LLaMA-3-70b (80.6%) and Qwen-2-72b (77.7%) now competing with
some of the best proprietary models. We identify performance variations across
topics, with non-English-focused models generally struggling more in
exoplanet-related fields, stellar astrophysics, and instrumentation related
questions. These challenges likely stem from less abundant training data,
limited historical context, and rapid recent developments in these areas. This
pattern is observed across both open-weights and proprietary models, with
regional dependencies evident, highlighting the impact of training data
diversity on model performance in specialized scientific domains.
Top-performing models demonstrate well-calibrated confidence, with correlations
above 0.9 between confidence and correctness, though they tend to be slightly
underconfident. The development for fast, low-cost inference of open-weights
models presents new opportunities for affordable deployment in astronomy. The
rapid progress observed suggests that LLM-driven research in astronomy may
become feasible in the near future.</p></br><a href="http://arxiv.org/pdf/2407.11659v1"><h2>Magnetogram-to-Magnetogram: Generative Forecasting of Solar Evolution</h2></a>Authors:  Francesco Pio Ramunno, Hyun-Jin Jeong, Stefan Hackstein, André Csillaghy, Svyatoslav Voloshynovskiy, Manolis K. Georgoulis</br>Comments: Conference paper accepted for an oral presentation to the ESA SPAICE
  CONFERENCE 17 19 September 2024</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, astro-ph.IM, cs.LG</br><p>Investigating the solar magnetic field is crucial to understand the physical
processes in the solar interior as well as their effects on the interplanetary
environment. We introduce a novel method to predict the evolution of the solar
line-of-sight (LoS) magnetogram using image-to-image translation with Denoising
Diffusion Probabilistic Models (DDPMs). Our approach combines "computer science
metrics" for image quality and "physics metrics" for physical accuracy to
evaluate model performance. The results indicate that DDPMs are effective in
maintaining the structural integrity, the dynamic range of solar magnetic
fields, the magnetic flux and other physical features such as the size of the
active regions, surpassing traditional persistence models, also in flaring
situation. We aim to use deep learning not only for visualisation but as an
integrative and interactive tool for telescopes, enhancing our understanding of
unexpected physical events like solar flares. Future studies will aim to
integrate more diverse solar data to refine the accuracy and applicability of
our generative model.</p></br><a href="http://arxiv.org/pdf/2407.09427v1"><h2>Flow-Based Generative Emulation of Grids of Stellar Evolutionary Models</h2></a>Authors:  Marc Hon, Yaguang Li, Joel Ong</br>Comments: 27 pages, 18 figures. Accepted for publication in ApJ. Code,
  animation, and interactive visualizations are available at
  https://github.com/mtyhon/modelflows/. Table 4 is also available as ancillary
  file attached to this submission</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, astro-ph.GA, cs.LG</br><p>We present a flow-based generative approach to emulate grids of stellar
evolutionary models. By interpreting the input parameters and output properties
of these models as multi-dimensional probability distributions, we train
conditional normalizing flows to learn and predict the complex relationships
between grid inputs and outputs in the form of conditional joint distributions.
Leveraging the expressive power and versatility of these flows, we showcase
their ability to emulate a variety of evolutionary tracks and isochrones across
a continuous range of input parameters. In addition, we describe a simple
Bayesian approach for estimating stellar parameters using these flows and
demonstrate its application to asteroseismic datasets of red giants observed by
the Kepler mission. By applying this approach to red giants in open clusters
NGC 6791 and NGC 6819, we illustrate how large age uncertainties can arise when
fitting only to global asteroseismic and spectroscopic parameters without prior
information on initial helium abundances and mixing length parameter values. We
also conduct inference using the flow at a large scale by determining revised
estimates of masses and radii for 15,388 field red giants. These estimates show
improved agreement with results from existing grid-based modelling, reveal
distinct population-level features in the red clump, and suggest that the
masses of Kepler red giants previously determined using the corrected
asteroseismic scaling relations have been overestimated by 5-10%.</p></br><a href="http://arxiv.org/pdf/2407.09602v1"><h2>Real-time gravitational-wave inference for binary neutron stars using
  machine learning</h2></a>Authors:  Maximilian Dax, Stephen R. Green, Jonathan Gair, Nihar Gupte, Michael Pürrer, Vivien Raymond, Jonas Wildberger, Jakob H. Macke, Alessandra Buonanno, Bernhard Schölkopf</br>Comments: 8+7 pages, 3+5 figures</br>Primary Category: gr-qc</br>All Categories: gr-qc, astro-ph.IM, cs.LG</br><p>Mergers of binary neutron stars (BNSs) emit signals in both the
gravitational-wave (GW) and electromagnetic (EM) spectra. Famously, the 2017
multi-messenger observation of GW170817 led to scientific discoveries across
cosmology, nuclear physics, and gravity. Central to these results were the sky
localization and distance obtained from GW data, which, in the case of
GW170817, helped to identify the associated EM transient, AT 2017gfo, 11 hours
after the GW signal. Fast analysis of GW data is critical for directing
time-sensitive EM observations; however, due to challenges arising from the
length and complexity of signals, it is often necessary to make approximations
that sacrifice accuracy. Here, we develop a machine learning approach that
performs complete BNS inference in just one second without making any such
approximations. This is enabled by a new method for explicit integration of
physical domain knowledge into neural networks. Our approach enhances
multi-messenger observations by providing (i) accurate localization even before
the merger; (ii) improved localization precision by $\sim30\%$ compared to
approximate low-latency methods; and (iii) detailed information on luminosity
distance, inclination, and masses, which can be used to prioritize expensive
telescope time. Additionally, the flexibility and reduced cost of our method
open new opportunities for equation-of-state and waveform systematics studies.
Finally, we demonstrate that our method scales to extremely long signals, up to
an hour in length, thus serving as a blueprint for data analysis for
next-generation ground- and space-based detectors.</p></br>
