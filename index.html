search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202503202000+TO+202503262000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.LG, cs.AI, stat.*, physics.data-an staritng 202503202000 and ending 202503262000</h1>Feed last updated: 2025-03-26T00:00:00-04:00<a href="http://arxiv.org/pdf/2503.16690v1"><h2>Making the unmodulated pyramid wavefront sensor smart II. First on-sky
  demonstration of extreme adaptive optics with deep learning</h2></a>Authors:  R. Landman, S. Y. Haffert, J. D. Long, J. R. Males, L. M. Close, W. B. Foster, K. Van Gorkom, O. Guyon, A. D. Hedglen, P. T. Johnson, M. Y. Kautz, J. K. Kueny, J. Li, J. Liberman, J. Lumbres, E. A. McEwen, A. McLeod, L. Schatz, E. Tonucci, K. Twitchell</br>Comments: Accepted for publication in A&A</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.EP, cs.LG, physics.optics</br><p>Pyramid wavefront sensors (PWFSs) are the preferred choice for current and
future extreme adaptive optics (XAO) systems. Almost all instruments use the
PWFS in its modulated form to mitigate its limited linearity range. However,
this modulation comes at the cost of a reduction in sensitivity, a blindness to
petal-piston modes, and a limit to the sensor's ability to operate at high
speeds. Therefore, there is strong interest to use the PWFS without modulation,
which can be enabled with nonlinear reconstructors. Here, we present the first
on-sky demonstration of XAO with an unmodulated PWFS using a nonlinear
reconstructor based on convolutional neural networks. We discuss the real-time
implementation on the Magellan Adaptive Optics eXtreme (MagAO-X) instrument
using the optimized TensorRT framework and show that inference is fast enough
to run the control loop at >2 kHz frequencies. Our on-sky results demonstrate a
successful closed-loop operation using a model calibrated with internal source
data that delivers stable and robust correction under varying conditions.
Performance analysis reveals that our smart PWFS achieves nearly the same
Strehl ratio as the highly optimized modulated PWFS under favorable conditions
on bright stars. Notably, we observe an improvement in performance on a fainter
star under the influence of strong winds. These findings confirm the
feasibility of using the PWFS in its unmodulated form and highlight its
potential for next-generation instruments. Future efforts will focus on
achieving even higher control loop frequencies (>3 kHz), optimizing the
calibration procedures, and testing its performance on fainter stars, where
more gain is expected for the unmodulated PWFS compared to its modulated
counterpart.</p></br><a href="http://arxiv.org/pdf/2503.18617v1"><h2>Scaling Laws for Emulation of Stellar Spectra</h2></a>Authors:  Tomasz Różański, Yuan-Sen Ting</br>Comments: 25 pages, 11 figures, submitted to OJA</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.SR, cs.LG</br><p>Neural network-based emulators for the inference of stellar parameters and
elemental abundances represent an increasingly popular methodology in modern
spectroscopic surveys. However, these approaches are often constrained by their
emulation precision and domain transfer capabilities. Greater generalizability
has previously been achieved only with significantly larger model
architectures, as demonstrated by Transformer-based models in natural language
processing. This observation aligns with neural scaling laws, where model
performance predictably improves with increased model size, computational
resources allocated to model training, and training data volume. In this study,
we demonstrate that these scaling laws also apply to Transformer-based spectral
emulators in astronomy. Building upon our previous work with TransformerPayne
and incorporating Maximum Update Parametrization techniques from natural
language models, we provide training guidelines for scaling models to achieve
optimal performance. Our results show that within the explored parameter space,
clear scaling relationships emerge. These findings suggest that optimal
computational resource allocation requires balanced scaling. Specifically,
given a tenfold increase in training compute, achieving an optimal seven-fold
reduction in mean squared error necessitates an approximately 2.5-fold increase
in dataset size and a 3.8-fold increase in model size. This study establishes a
foundation for developing spectral foundational models with enhanced domain
transfer capabilities.</p></br><a href="http://arxiv.org/pdf/2503.17117v1"><h2>A New Statistical Model of Star Speckles for Learning to Detect and
  Characterize Exoplanets in Direct Imaging Observations</h2></a>Authors:  Théo Bodrito, Olivier Flasseur, Julien Mairal, Jean Ponce, Maud Langlois, Anne-Marie Lagrange</br>Comments: Accepted to CVPR 2025</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.EP, cs.CV, cs.LG, stat.AP</br><p>The search for exoplanets is an active field in astronomy, with direct
imaging as one of the most challenging methods due to faint exoplanet signals
buried within stronger residual starlight. Successful detection requires
advanced image processing to separate the exoplanet signal from this nuisance
component. This paper presents a novel statistical model that captures nuisance
fluctuations using a multi-scale approach, leveraging problem symmetries and a
joint spectral channel representation grounded in physical principles. Our
model integrates into an interpretable, end-to-end learnable framework for
simultaneous exoplanet detection and flux estimation. The proposed algorithm is
evaluated against the state of the art using datasets from the SPHERE
instrument operating at the Very Large Telescope (VLT). It significantly
improves the precision-recall trade-off, notably on challenging datasets that
are otherwise unusable by astronomers. The proposed approach is computationally
efficient, robust to varying data quality, and well suited for large-scale
observational surveys.</p></br><a href="http://arxiv.org/pdf/2503.18670v1"><h2>Deep learning-based identification of precipitation clouds from all-sky
  camera data for observatory safety</h2></a>Authors:  Mohammad H. Zhoolideh Haghighi, Alireza Ghasrimanesh, Habib Khosroshahi</br>Comments: A version of this work has been published in Machine Learning with
  Applications (MLWA)</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, physics.data-an, stat.ML</br><p>For monitoring the night sky conditions, wide-angle all-sky cameras are used
in most astronomical observatories to monitor the sky cloudiness. In this
manuscript, we apply a deep-learning approach for automating the identification
of precipitation clouds in all-sky camera data as a cloud warning system. We
construct our original training and test sets using the all-sky camera image
archive of the Iranian National Observatory (INO). The training and test set
images are labeled manually based on their potential rainfall and their
distribution in the sky. We train our model on a set of roughly 2445 images
taken by the INO all-sky camera through the deep learning method based on the
EfficientNet network. Our model reaches an average accuracy of 99\% in
determining the cloud rainfall's potential and an accuracy of 96\% for cloud
coverage. To enable a comprehensive comparison and evaluate the performance of
alternative architectures for the task, we additionally trained three models
LeNet, DeiT, and AlexNet. This approach can be used for early warning of
incoming dangerous clouds toward telescopes and harnesses the power of deep
learning to automatically analyze vast amounts of all-sky camera data and
accurately identify precipitation clouds formations. Our trained model can be
deployed for real-time analysis, enabling the rapid identification of potential
threats, and offering a scaleable solution that can improve our ability to
safeguard telescopes and instruments in observatories. This is important now
that numerous small and medium-sized telescopes are increasingly integrated
with smart control systems to reduce manual operation.</p></br>
