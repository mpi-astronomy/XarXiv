search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202510102000+TO+202510162000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, cs.LG, stat.*, physics.data-an staritng 202510102000 and ending 202510162000</h1>Feed last updated: 2025-10-16T00:00:00-04:00<a href="http://arxiv.org/pdf/2510.10713v1"><h2>Deep Learning in Astrophysics</h2></a>Authors:  Yuan-Sen Ting</br>Comments: Manuscript submitted to Annual Review of Astronomy and Astrophysics
  for Volume 64. This is the authors' version. Revisions and the final version
  will be available at https://www.annualreviews.org/content/journals/astro</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.CO, astro-ph.EP, astro-ph.GA, astro-ph.HE, cs.AI</br><p>Deep learning has generated diverse perspectives in astronomy, with ongoing
discussions between proponents and skeptics motivating this review. We examine
how neural networks complement classical statistics, extending our data
analytical toolkit for modern surveys. Astronomy offers unique opportunities
through encoding physical symmetries, conservation laws, and differential
equations directly into architectures, creating models that generalize beyond
training data. Yet challenges persist as unlabeled observations number in
billions while confirmed examples with known properties remain scarce and
expensive. This review demonstrates how deep learning incorporates domain
knowledge through architectural design, with built-in assumptions guiding
models toward physically meaningful solutions. We evaluate where these methods
offer genuine advances versus claims requiring careful scrutiny. - Neural
architectures overcome trade-offs between scalability, expressivity, and data
efficiency by encoding physical symmetries and conservation laws into network
structure, enabling learning from limited labeled data. - Simulation-based
inference and anomaly detection extract information from complex, non-Gaussian
distributions where analytical likelihoods fail, enabling field-level
cosmological analysis and systematic discovery of rare phenomena. - Multi-scale
neural modeling bridges resolution gaps in astronomical simulations, learning
effective subgrid physics from expensive high-fidelity runs to enhance
large-volume calculations where direct computation remains prohibitive. -
Emerging paradigms-reinforcement learning for telescope operations, foundation
models learning from minimal examples, and large language model agents for
research automation-show promise though are still developing in astronomical
applications.</p></br><a href="http://arxiv.org/pdf/2510.12958v1"><h2>Simulation-Based Pretraining and Domain Adaptation for Astronomical Time
  Series with Minimal Labeled Data</h2></a>Authors:  Rithwik Gupta, Daniel Muthukrishna, Jeroen Audenaert</br>Comments: No comment found</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.HE, astro-ph.SR, cs.LG</br><p>Astronomical time-series analysis faces a critical limitation: the scarcity
of labeled observational data. We present a pre-training approach that
leverages simulations, significantly reducing the need for labeled examples
from real observations. Our models, trained on simulated data from multiple
astronomical surveys (ZTF and LSST), learn generalizable representations that
transfer effectively to downstream tasks. Using classifier-based architectures
enhanced with contrastive and adversarial objectives, we create domain-agnostic
models that demonstrate substantial performance improvements over baseline
methods in classification, redshift estimation, and anomaly detection when
fine-tuned with minimal real data. Remarkably, our models exhibit effective
zero-shot transfer capabilities, achieving comparable performance on future
telescope (LSST) simulations when trained solely on existing telescope (ZTF)
data. Furthermore, they generalize to very different astronomical phenomena
(namely variable stars from NASA's \textit{Kepler} telescope) despite being
trained on transient events, demonstrating cross-domain capabilities. Our
approach provides a practical solution for building general models when labeled
data is scarce, but domain knowledge can be encoded in simulations.</p></br><a href="http://arxiv.org/pdf/2510.11242v1"><h2>Analyzing Data Quality and Decay in Mega-Constellations: A
  Physics-Informed Machine Learning Approach</h2></a>Authors:  Katarina Dyreby, Francisco Caldas, Cl√°udia Soares</br>Comments: 76th International Astronautical Congress</br>Primary Category: astro-ph.EP</br>All Categories: astro-ph.EP, astro-ph.IM, cs.LG</br><p>In the era of mega-constellations, the need for accurate and publicly
available information has become fundamental for satellite operators to
guarantee the safety of spacecrafts and the Low Earth Orbit (LEO) space
environment. This study critically evaluates the accuracy and reliability of
publicly available ephemeris data for a LEO mega-constellation - Starlink. The
goal of this work is twofold: (i) compare and analyze the quality of the data
against high-precision numerical propagation. (ii) Leverage Physics-Informed
Machine Learning to extract relevant satellite quantities, such as
non-conservative forces, during the decay process. By analyzing two months of
real orbital data for approximately 1500 Starlink satellites, we identify
discrepancies between high precision numerical algorithms and the published
ephemerides, recognizing the use of simplified dynamics at fixed thresholds,
planned maneuvers, and limitations in uncertainty propagations. Furthermore, we
compare data obtained from multiple sources to track and analyze deorbiting
satellites over the same period. Empirically, we extract the acceleration
profile of satellites during deorbiting and provide insights relating to the
effects of non-conservative forces during reentry. For non-deorbiting
satellites, the position Root Mean Square Error (RMSE) was approximately 300 m,
while for deorbiting satellites it increased to about 600 m. Through this
in-depth analysis, we highlight potential limitations in publicly available
data for accurate and robust Space Situational Awareness (SSA), and
importantly, we propose a data-driven model of satellite decay in
mega-constellations.</p></br><a href="http://arxiv.org/pdf/2510.12920v1"><h2>InferA: A Smart Assistant for Cosmological Ensemble Data</h2></a>Authors:  Justin Z. Tam, Pascal Grosset, Divya Banesh, Nesar Ramachandra, Terece L. Turton, James Ahrens</br>Comments: No comment found</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI</br><p>Analyzing large-scale scientific datasets presents substantial challenges due
to their sheer volume, structural complexity, and the need for specialized
domain knowledge. Automation tools, such as PandasAI, typically require full
data ingestion and lack context of the full data structure, making them
impractical as intelligent data analysis assistants for datasets at the
terabyte scale. To overcome these limitations, we propose InferA, a multi-agent
system that leverages large language models to enable scalable and efficient
scientific data analysis. At the core of the architecture is a supervisor agent
that orchestrates a team of specialized agents responsible for distinct phases
of the data retrieval and analysis. The system engages interactively with users
to elicit their analytical intent and confirm query objectives, ensuring
alignment between user goals and system actions. To demonstrate the framework's
usability, we evaluate the system using ensemble runs from the HACC cosmology
simulation which comprises several terabytes.</p></br>
