search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202406202000+TO+202406262000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on physics.data-an, cs.LG, stat.*, cs.AI staritng 202406202000 and ending 202406262000</h1>Feed last updated: 2024-06-26T00:00:00-04:00<a href="http://arxiv.org/pdf/2406.15594v1"><h2>Detecting and Classifying Flares in High-Resolution Solar Spectra with
  Supervised Machine Learning</h2></a>Authors:  Nicole Hao, Laura Flagg, Ray Jayawardhana</br>Comments: re-submitted to ApJ after responding to referee report</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, astro-ph.EP, astro-ph.IM, cs.LG</br><p>Flares are a well-studied aspect of the Sun's magnetic activity. Detecting
and classifying solar flares can inform the analysis of contamination caused by
stellar flares in exoplanet transmission spectra. In this paper, we present a
standardized procedure to classify solar flares with the aid of supervised
machine learning. Using flare data from the RHESSI mission and solar spectra
from the HARPS-N instrument, we trained several supervised machine learning
models, and found that the best performing algorithm is a C-Support Vector
Machine (SVC) with non-linear kernels, specifically Radial Basis Functions
(RBF). The best-trained model, SVC with RBF kernels, achieves an average
aggregate accuracy score of 0.65, and categorical accuracy scores of over 0.70
for the no-flare and weak-flare classes, respectively. In comparison, a blind
classification algorithm would have an accuracy score of 0.33. Testing showed
that the model is able to detect and classify solar flares in entirely new data
with different characteristics and distributions from those of the training
set. Future efforts could focus on enhancing classification accuracy,
investigating the efficacy of alternative models, particularly deep learning
models, and incorporating more datasets to extend the application of this
framework to stars that host exoplanets.</p></br><a href="http://arxiv.org/pdf/2406.17057v1"><h2>At First Sight: Zero-Shot Classification of Astronomical Images with
  Large Multimodal Models</h2></a>Authors:  Dimitrios Tanoglidis, Bhuvnesh Jain</br>Comments: 5 pages, 3 images. Prepared for submission to RNAAS</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.GA, cs.AI</br><p>Vision-Language multimodal Models (VLMs) offer the possibility for zero-shot
classification in astronomy: i.e. classification via natural language prompts,
with no training. We investigate two models, GPT-4o and LLaVA-NeXT, for
zero-shot classification of low-surface brightness galaxies and artifacts, as
well as morphological classification of galaxies. We show that with natural
language prompts these models achieved significant accuracy (above 80 percent
typically) without additional training/fine tuning. We discuss areas that
require improvement, especially for LLaVA-NeXT, which is an open source model.
Our findings aim to motivate the astronomical community to consider VLMs as a
powerful tool for both research and pedagogy, with the prospect that future
custom-built or fine-tuned models could perform better.</p></br><a href="http://arxiv.org/pdf/2406.17316v1"><h2>A review of unsupervised learning in astronomy</h2></a>Authors:  Sotiria Fotopoulou</br>Comments: 30 pages, 6 figures. Invited contribution to special issue in
  Astronomy & Computing</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.LG</br><p>This review summarizes popular unsupervised learning methods, and gives an
overview of their past, current, and future uses in astronomy. Unsupervised
learning aims to organise the information content of a dataset, in such a way
that knowledge can be extracted. Traditionally this has been achieved through
dimensionality reduction techniques that aid the ranking of a dataset, for
example through principal component analysis or by using auto-encoders, or
simpler visualisation of a high dimensional space, for example through the use
of a self organising map. Other desirable properties of unsupervised learning
include the identification of clusters, i.e. groups of similar objects, which
has traditionally been achieved by the k-means algorithm and more recently
through density-based clustering such as HDBSCAN. More recently, complex
frameworks have emerged, that chain together dimensionality reduction and
clustering methods. However, no dataset is fully unknown. Thus, nowadays a lot
of research has been directed towards self-supervised and semi-supervised
methods that stand to gain from both supervised and unsupervised learning.</p></br><a href="http://arxiv.org/pdf/2406.17323v1"><h2>XAMI -- A Benchmark Dataset for Artefact Detection in XMM-Newton Optical
  Images</h2></a>Authors:  Elisabeta-Iulia Dima, Pablo Gómez, Sandor Kruk, Peter Kretschmar, Simon Rosen, Călin-Adrian Popa</br>Comments: submitted to SPAICE 2024</br>Primary Category: cs.CV</br>All Categories: cs.CV, astro-ph.IM, cs.LG</br><p>Reflected or scattered light produce artefacts in astronomical observations
that can negatively impact the scientific study. Hence, automated detection of
these artefacts is highly beneficial, especially with the increasing amounts of
data gathered. Machine learning methods are well-suited to this problem, but
currently there is a lack of annotated data to train such approaches to detect
artefacts in astronomical observations. In this work, we present a dataset of
images from the XMM-Newton space telescope Optical Monitoring camera showing
different types of artefacts. We hand-annotated a sample of 1000 images with
artefacts which we use to train automated ML methods. We further demonstrate
techniques tailored for accurate detection and masking of artefacts using
instance segmentation. We adopt a hybrid approach, combining knowledge from
both convolutional neural networks (CNNs) and transformer-based models and use
their advantages in segmentation. The presented method and dataset will advance
artefact detection in astronomical observations by providing a reproducible
baseline. All code and data are made available
(https://github.com/ESA-Datalabs/XAMI-model and
https://github.com/ESA-Datalabs/XAMI-dataset).</p></br><a href="http://arxiv.org/pdf/2406.16730v1"><h2>Convolutional neural network for Lyman break galaxies classification and
  redshift regression in DESI (Dark Energy Spectroscopic Instrument)</h2></a>Authors:  Julien Taran</br>Comments: No comment found</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, cs.AI</br><p>DESI is a groundbreaking international project to observe more than 40
million quasars and galaxies over a 5-year period to create a 3D map of the
sky. This map will enable us to probe multiple aspects of cosmology, from dark
energy to neutrino mass. We are focusing here on one type of object observed by
DESI, the Lyman Break Galaxies (LBGs). The aim is to use their spectra to
determine whether they are indeed LBGs, and if so, to determine their distance
from the Earth using a phenomenon called redshift. This will enable us to place
these galaxies on the DESI 3D map.
  The aim is therefore to develop a convolutional neural network (CNN) inspired
by QuasarNET (See arXiv:1808.09955), performing simultaneously a classification
(LBG type or not) and a regression task (determine the redshift of the LBGs).
Initially, data augmentation techniques such as shifting the spectra in
wavelengths, adding noise to the spectra, or adding synthetic spectra were used
to increase the model training dataset from 3,019 data to over 66,000. In a
second phase, modifications to the QuasarNET architecture, notably through
transfer learning and hyperparameter tuning with Bayesian optimization, boosted
model performance.
  Gains of up to 26% were achieved on the Purity/Efficiency curve, which is
used to evaluate model performance, particularly in areas with interesting
redshifts, at low (around 2) and high (around 4) redshifts. The best model
obtained an average score of 94%, compared with 75% for the initial model.</p></br>
