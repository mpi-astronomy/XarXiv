search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202511222000+TO+202511282000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.LG, cs.AI, stat.*, physics.data-an staritng 202511222000 and ending 202511282000</h1>Feed last updated: 2025-11-28T04:14:32Z<a href="https://arxiv.org/pdf/2511.20694v1"><h2>Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning</h2></a>Authors:  Kevin Lee, Russell Spiewak, James Walsh</br>Comments: Accepted at NeurIPS 2025 Machine Learning and the Physical Sciences (ML4PS) Workshop. Dataset: https://huggingface.co/datasets/SpaceML/ReasoningWithAStar</br>Primary Category: cs.AI</br>All Categories: cs.AI, astro-ph.SR, cs.LG, physics.space-ph</br><p>Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall.</p></br><a href="https://arxiv.org/pdf/2511.18590v1"><h2>From Simulations to Surveys: Domain Adaptation for Galaxy Observations</h2></a>Authors:  Kaley Brauer, Aditya Prasad Dash, Meet J. Vyas, Ahmed Salim, Stiven Briand Massala</br>Comments: 8 pages, 4 figures. Will be presented at NeurIPS 2025 ML4PS</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, cs.LG</br><p>Large photometric surveys will image billions of galaxies, but we currently lack quick, reliable automated ways to infer their physical properties like morphology, stellar mass, and star formation rates. Simulations provide galaxy images with ground-truth physical labels, but domain shifts in PSF, noise, backgrounds, selection, and label priors degrade transfer to real surveys. We present a preliminary domain adaptation pipeline that trains on simulated TNG50 galaxies and evaluates on real SDSS galaxies with morphology labels (elliptical/spiral/irregular). We train three backbones (CNN, $E(2)$-steerable CNN, ResNet-18) with focal loss and effective-number class weighting, and a feature-level domain loss $L_D$ built from GeomLoss (entropic Sinkhorn OT, energy distance, Gaussian MMD, and related metrics). We show that a combination of these losses with an OT-based "top_$k$ soft matching" loss that focuses $L_D$ on the worst-matched source-target pairs can further enhance domain alignment. With Euclidean distance, scheduled alignment weights, and top-$k$ matching, target accuracy (macro F1) rises from $\sim$46% ($\sim$30%) at no adaptation to $\sim$87% ($\sim$62.6%), with a domain AUC near 0.5, indicating strong latent-space mixing.</p></br><a href="https://arxiv.org/pdf/2511.18999v1"><h2>Enhancing low energy reconstruction and classification in KM3NeT/ORCA with transformers</h2></a>Authors:  Iván Mozún Mateo</br>Comments: No comment found</br>Primary Category: hep-ex</br>All Categories: hep-ex, astro-ph.IM, cs.AI</br><p>The current KM3NeT/ORCA neutrino telescope, still under construction, has not yet reached its full potential in neutrino reconstruction capability. When training any deep learning model, no explicit information about the physics or the detector is provided, thus they remain unknown to the model. This study leverages the strengths of transformers by incorporating attention masks inspired by the physics and detector design, making the model understand both the telescope design and the neutrino physics measured on it. The study also shows the efficacy of transformers on retaining valuable information between detectors when doing fine-tuning from one configurations to another.</p></br><a href="https://arxiv.org/pdf/2511.18521v1"><h2>Hyperspectral Variational Autoencoders for Joint Data Compression and Component Extraction</h2></a>Authors:  Core Francisco Park, Manuel Perez-Carrasco, Caroline Nowlan, Cecilia Garraffo</br>Comments: No comment found</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.EP, astro-ph.IM</br><p>Geostationary hyperspectral satellites generate terabytes of data daily, creating critical challenges for storage, transmission, and distribution to the scientific community. We present a variational autoencoder (VAE) approach that achieves x514 compression of NASA's TEMPO satellite hyperspectral observations (1028 channels, 290-490nm) with reconstruction errors 1-2 orders of magnitude below the signal across all wavelengths. This dramatic data volume reduction enables efficient archival and sharing of satellite observations while preserving spectral fidelity. Beyond compression, we investigate to what extent atmospheric information is retained in the compressed latent space by training linear and nonlinear probes to extract Level-2 products (NO2, O3, HCHO, cloud fraction). Cloud fraction and total ozone achieve strong extraction performance (R^2 = 0.93 and 0.81 respectively), though these represent relatively straightforward retrievals given their distinct spectral signatures. In contrast, tropospheric trace gases pose genuine challenges for extraction (NO2 R^2 = 0.20, HCHO R^2 = 0.51) reflecting their weaker signals and complex atmospheric interactions. Critically, we find the VAE encodes atmospheric information in a semi-linear manner - nonlinear probes substantially outperform linear ones - and that explicit latent supervision during training provides minimal improvement, revealing fundamental encoding challenges for certain products. This work demonstrates that neural compression can dramatically reduce hyperspectral data volumes while preserving key atmospheric signals, addressing a critical bottleneck for next-generation Earth observation systems. Code - https://github.com/cfpark00/Hyperspectral-VAE</p></br><a href="https://arxiv.org/pdf/2511.19207v1"><h2>Inclinations and Position Angles for Disc Galaxies in the SGA sample</h2></a>Authors:  Megan H. Martinez, Michael S. Petersen, Carrie Filion, Rashid Yaaqib, Claire Larson</br>Comments: 12 pages, 9 figures</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, physics.data-an</br><p>We present a data-driven method for determining the inclination and position angle (PA) of disc galaxies using a Fourier-Laguerre basis decomposition of imaging data. We define a dimensionless metric, $η$, that characterises the ratio of the quadrupole and monopole coefficients in the Fourier-Laguerre basis function expansion. This metric serves as a robust measure which is related to the inclination of a galaxy. We find an empirical relationship between $η$ and inclination which is agnostic to the galaxy morphology. The PA is derived directly from the phase of the quadrupolar Fourier-Laguerre functions. Across a benchmark sample of galaxies, the method reproduces published inclination and PA values to within a median of 10$^\circ$ and 5$^\circ$, respectively, while also demonstrating essentially zero catastrophic failures. Applying this pipeline to galaxies from the Siena Galaxy Atlas (SGA), we report measurements of $η$, scale length and PA for three different bands of 133,942 disc galaxies. Our computationally inexpensive technique automates parametrisation analysis and returns reproducible results for large surveys. We release a Python package ready for application to next generation surveys.</p></br><a href="https://arxiv.org/pdf/2511.19393v1"><h2>Guesswork in the gap: the impact of uncertainty in the compact binary population on source classification</h2></a>Authors:  Utkarsh Mali, Reed Essick</br>Comments: 26 pages, 12 figures, 5 tables</br>Primary Category: astro-ph.HE</br>All Categories: astro-ph.HE, gr-qc, physics.comp-ph, physics.data-an, physics.space-ph</br><p>The nature of the compact objects within the supposed "lower mass gap" remains uncertain. Observations of GW190814 and GW230529 highlight the challenges gravitational waves face in distinguishing neutron stars from black holes. Interpreting these systems is especially difficult because classifications depend simultaneously on measurement noise, compact binary population models, and equation of state (EOS) constraints on the maximum neutron star mass. We analyze 66 confident events from GWTC-3 to quantify how the probability of a component being a neutron star, P(NS), varies across the population. The effects are substantial, the dominant drivers of classification are the pairing preferences of neutron stars with other compact objects, and the neutron star spin distributions. The data reveals that P(NS) varies between 1% - 67% for GW230529's primary and between 51% - 100% for GW190425's primary. By contrast, P(NS) for GW190814's secondary varies by <10%, demonstrating robustness from its high signal-to-noise ratio and small mass ratio. Analysis using EOS information tends to affect P(NS) through the inferred maximum neutron star mass rather than the maximum spin. As it stands, P(NS) remains sensitive to numerous population parameters, limiting its reliability and potentially leading to ambiguous classifications of future GW events.</p></br><a href="https://arxiv.org/pdf/2511.19364v1"><h2>Neural surrogates for designing gravitational wave detectors</h2></a>Authors:  Carlos Ruiz-Gonzalez, Sören Arlt, Sebastian Lehner, Arturs Berzins, Yehonathan Drori, Rana X Adhikari, Johannes Brandstetter, Mario Krenn</br>Comments: 20 pages, 7 figures, 4 tables</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.IM, gr-qc, quant-ph</br><p>Physics simulators are essential in science and engineering, enabling the analysis, control, and design of complex systems. In experimental sciences, they are increasingly used to automate experimental design, often via combinatorial search and optimization. However, as the setups grow more complex, the computational cost of traditional, CPU-based simulators becomes a major limitation. Here, we show how neural surrogate models can significantly reduce reliance on such slow simulators while preserving accuracy. Taking the design of interferometric gravitational wave detectors as a representative example, we train a neural network to surrogate the gravitational wave physics simulator Finesse, which was developed by the LIGO community. Despite that small changes in physical parameters can change the output by orders of magnitudes, the model rapidly predicts the quality and feasibility of candidate designs, allowing an efficient exploration of large design spaces. Our algorithm loops between training the surrogate, inverse designing new experiments, and verifying their properties with the slow simulator for further training. Assisted by auto-differentiation and GPU parallelism, our method proposes high-quality experiments much faster than direct optimization. Solutions that our algorithm finds within hours outperform designs that take five days for the optimizer to reach. Though shown in the context of gravitational wave detectors, our framework is broadly applicable to other domains where simulator bottlenecks hinder optimization and discovery.</p></br><a href="https://arxiv.org/pdf/2511.19390v1"><h2>Predicting partially observable dynamical systems via diffusion models with a multiscale inference scheme</h2></a>Authors:  Rudy Morel, Francesco Pio Ramunno, Jeff Shen, Alberto Bietti, Kyunghyun Cho, Miles Cranmer, Siavash Golkar, Olexandr Gugnin, Geraud Krawezik, Tanya Marwah, Michael McCabe, Lucas Meyer, Payel Mukhopadhyay, Ruben Ohana, Liam Parker, Helen Qu, François Rozet, K. D. Leka, François Lanusse, David Fouhey, Shirley Ho</br>Comments: No comment found</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.SR, cs.AI, stat.ML</br><p>Conditional diffusion models provide a natural framework for probabilistic prediction of dynamical systems and have been successfully applied to fluid dynamics and weather prediction. However, in many settings, the available information at a given time represents only a small fraction of what is needed to predict future states, either due to measurement uncertainty or because only a small fraction of the state can be observed. This is true for example in solar physics, where we can observe the Sun's surface and atmosphere, but its evolution is driven by internal processes for which we lack direct measurements. In this paper, we tackle the probabilistic prediction of partially observable, long-memory dynamical systems, with applications to solar dynamics and the evolution of active regions. We show that standard inference schemes, such as autoregressive rollouts, fail to capture long-range dependencies in the data, largely because they do not integrate past information effectively. To overcome this, we propose a multiscale inference scheme for diffusion models, tailored to physical processes. Our method generates trajectories that are temporally fine-grained near the present and coarser as we move farther away, which enables capturing long-range temporal dependencies without increasing computational cost. When integrated into a diffusion model, we show that our inference scheme significantly reduces the bias of the predicted distributions and improves rollout stability.</p></br>
