search_query=cat:astro-ph.*+AND+lastUpdatedDate:[202509272000+TO+202510032000]&start=0&max_results=5000
<h1>New astro-ph.* submissions cross listed on cs.AI, stat.*, cs.LG, physics.data-an staritng 202509272000 and ending 202510032000</h1>Feed last updated: 2025-10-03T00:00:00-04:00<a href="http://arxiv.org/pdf/2509.24904v1"><h2>Graph-based Analysis for Revealing the Stochastic Gravitational Wave
  Background in Pulsar Timing Arrays</h2></a>Authors:  M. Alakhras, S. M. S. Movahed</br>Comments: 29 pages, 15 figures, 1 table. Comments are welcome</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, astro-ph.HE, astro-ph.IM, physics.data-an, stat.CO</br><p>The stochastic gravitational wave background (SGWB) reveals valuable
information about its origin and the Universe. The pulsar timing arrays (PTAs)
are suitable indicators for detecting SGWB within the nano-Hertz frequency
range. In this work, we propose a graph-based method implemented on the pulsar
timing residuals (PTRs) for SGWB detection and examining uncertainties of its
parameters. We construct a correlation graph with pulsars as its nodes, and
analyze the graph-based summary statistics, which include topological and
geometrical characteristics, for identifying SGWB in real and synthetic
datasets. The effect of the number of pulsars, the observation time span, and
the strength of the SGWB on the graph-based feature vector is evaluated. Our
results demonstrate that the merit feature vector for common signal detection
consists of the average clustering coefficient and the edge weight fluctuation.
The SGWB detection conducted after the observation of a common signal and then
exclusion of non-Hellings \& Downs templates is performed by the second
cumulant of edge weight for angular separation thresholds $\bar{\zeta}\gtrsim
40^{\circ}$. The lowest detectable value of SGWB strain amplitude utilizing our
graph-based measures at the current PTAs sensitivity is $A_{\rm SGWB}\gtrsim
1.2\times 10^{-15}$. Fisher forecasts confirmed that the uncertainty levels of
$\log_{10} A_{\rm SGWB}$ and spectral index reach $2.2\%$ and $28.3\%$,
respectively, at $2\sigma$ confidence interval. Evidence for an SGWB at the
$3\sigma$ level is obtained by applying our graph-based method to the NANOGrav
15-year dataset.</p></br><a href="http://arxiv.org/pdf/2510.01799v1"><h2>PRESOL: a web-based computational setting for feature-based flare
  forecasting</h2></a>Authors:  Chiara Curletto, Paolo Massa, Valeria Tagliafico, Cristina Campi, Federico Benvenuto, Michele Piana, Andrea Tacchino</br>Comments: No comment found</br>Primary Category: astro-ph.SR</br>All Categories: astro-ph.SR, astro-ph.IM, cs.LG, physics.space-ph, 68T07, 85-04</br><p>Solar flares are the most explosive phenomena in the solar system and the
main trigger of the events' chain that starts from Coronal Mass Ejections and
leads to geomagnetic storms with possible impacts on the infrastructures at
Earth. Data-driven solar flare forecasting relies on either deep learning
approaches, which are operationally promising but with a low explainability
degree, or machine learning algorithms, which can provide information on the
physical descriptors that mostly impact the prediction. This paper describes a
web-based technological platform for the execution of a computational pipeline
of feature-based machine learning methods that provide predictions of the flare
occurrence, feature ranking information, and assessment of the prediction
performances.</p></br><a href="http://arxiv.org/pdf/2509.23901v1"><h2>Interpreting deep learning-based stellar mass estimation via causal
  analysis and mutual information decomposition</h2></a>Authors:  Wei Zhang, Qiufan Lin, Yuan-Sen Ting, Shupei Chen, Hengxin Ruan, Song Li, Yifan Wang</br>Comments: Accepted at Astronomy & Astrophysics; 23 + 12 pages; 8 + 16 figures</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, astro-ph.GA, cs.AI, cs.CV</br><p>End-to-end deep learning models fed with multi-band galaxy images are
powerful data-driven tools used to estimate galaxy physical properties in the
absence of spectroscopy. However, due to a lack of interpretability and the
associational nature of such models, it is difficult to understand how the
information additional to integrated photometry (e.g., morphology) contributes
to the estimation task. Improving our understanding in this field would enable
further advances into unraveling the physical connections among galaxy
properties and optimizing data exploitation. Therefore, our work is aimed at
interpreting the deep learning-based estimation of stellar mass via two
interpretability techniques: causal analysis and mutual information
decomposition. The former reveals the causal paths between multiple variables
beyond nondirectional statistical associations, while the latter quantifies the
multicomponent contributions (i.e., redundant, unique, and synergistic) of
different input data to the stellar mass estimation. Using data from the Sloan
Digital Sky Survey (SDSS) and the Wide-field Infrared Survey Explorer (WISE),
we obtained meaningful results that provide physical interpretations for
image-based models. Our work demonstrates the gains from combining deep
learning with interpretability techniques, and holds promise in promoting more
data-driven astrophysical research (e.g., astrophysical parameter estimations
and investigations on complex multivariate physical processes).</p></br><a href="http://arxiv.org/pdf/2510.01112v1"><h2>The causal structure of galactic astrophysics</h2></a>Authors:  Harry Desmond, Joseph Ramsey</br>Comments: 5 pages, 3 figures; submitted to MNRAS Letters</br>Primary Category: astro-ph.GA</br>All Categories: astro-ph.GA, astro-ph.CO, cs.LG, stat.AP, stat.ME</br><p>Data-driven astrophysics currently relies on the detection and
characterisation of correlations between objects' properties, which are then
used to test physical theories that make predictions for them. This process
fails to utilise information in the data that forms a crucial part of the
theories' predictions, namely which variables are directly correlated (as
opposed to accidentally correlated through others), the directions of these
determinations, and the presence or absence of confounders that correlate
variables in the dataset but are themselves absent from it. We propose to
recover this information through causal discovery, a well-developed methodology
for inferring the causal structure of datasets that is however almost entirely
unknown to astrophysics. We develop a causal discovery algorithm suitable for
astrophysical datasets and illustrate it on $\sim$5$\times10^5$ low-redshift
galaxies from the Nasa Sloan Atlas, demonstrating its ability to distinguish
physical mechanisms that are degenerate on the basis of correlations alone.</p></br><a href="http://arxiv.org/pdf/2510.00063v1"><h2>AstroMMBench: A Benchmark for Evaluating Multimodal Large Language
  Models Capabilities in Astronomy</h2></a>Authors:  Jinghang Shi, Xiao Yu Tang, Yang Hunag, Yuyang Li, Xiaokong, Yanxia Zhang, Caizhan Yue</br>Comments: No comment found</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI</br><p>Astronomical image interpretation presents a significant challenge for
applying multimodal large language models (MLLMs) to specialized scientific
tasks. Existing benchmarks focus on general multimodal capabilities but fail to
capture the complexity of astronomical data. To bridge this gap, we introduce
AstroMMBench, the first comprehensive benchmark designed to evaluate MLLMs in
astronomical image understanding. AstroMMBench comprises 621 multiple-choice
questions across six astrophysical subfields, curated and reviewed by 15 domain
experts for quality and relevance. We conducted an extensive evaluation of 25
diverse MLLMs, including 22 open-source and 3 closed-source models, using
AstroMMBench. The results show that Ovis2-34B achieved the highest overall
accuracy (70.5%), demonstrating leading capabilities even compared to strong
closed-source models. Performance showed variations across the six
astrophysical subfields, proving particularly challenging in domains like
cosmology and high-energy astrophysics, while models performed relatively
better in others, such as instrumentation and solar astrophysics. These
findings underscore the vital role of domain-specific benchmarks like
AstroMMBench in critically evaluating MLLM performance and guiding their
targeted development for scientific applications. AstroMMBench provides a
foundational resource and a dynamic tool to catalyze advancements at the
intersection of AI and astronomy.</p></br><a href="http://arxiv.org/pdf/2510.00090v1"><h2>Architecturally Constrained Solutions to Ill-Conditioned Problems in
  QUBIC</h2></a>Authors:  Leonora Kardum</br>Comments: No comment found</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, physics.data-an</br><p>This article introduces a new physics-guided Machine Learning framework, with
which we solve the generally non-invertible, ill-conditioned problems through
an analytical approach and constrain the solution to the approximate inverse
with the architecture of Neural Networks. By informing the networks of the
underlying physical processes, the method optimizes data usage and enables
interpretability of the model while simultaneously allowing estimation of
detector properties and the propagation of their corresponding uncertainties.
The method is applied in reconstructing Cosmic Microwave Background (CMB) maps
observed with the novel interferometric QUBIC experiment aimed at measuring the
tensor-to-scalar ratio r.</p></br><a href="http://arxiv.org/pdf/2510.00873v1"><h2>Reducción de ruido por medio de autoencoders: caso de estudio con la
  señal GW150914</h2></a>Authors:  Fernanda Zapata Bascuñán, Darío Fernando Mendieta</br>Comments: in Spanish language, Presented at the RPIC 2023 (Information
  Processing and Control work Reunion)</br>Primary Category: cs.LG</br>All Categories: cs.LG, astro-ph.IM</br><p>This brief study focuses on the application of autoencoders to improve the
quality of low-amplitude signals, such as gravitational events. A pre-existing
autoencoder was trained using cosmic event data, optimizing its architecture
and parameters. The results show a significant increase in the signal-to-noise
ratio of the processed signals, demonstrating the potential of autoencoders in
the analysis of small signals with multiple sources of interference.</p></br><a href="http://arxiv.org/pdf/2510.01299v1"><h2>Enhancing the development of Cherenkov Telescope Array control software
  with Large Language Models</h2></a>Authors:  Dmitriy Kostunin, Elisa Jones, Vladimir Sotnikov, Valery Sotnikov, Sergo Golovachev, Alexandre Strube</br>Comments: EuCAIFCon 2025 proceedings</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI</br><p>We develop AI agents based on instruction-finetuned large language models
(LLMs) to assist in the engineering and operation of the Cherenkov Telescope
Array Observatory (CTAO) Control and Data Acquisition Software (ACADA). These
agents align with project-specific documentation and codebases, understand
contextual information, interact with external APIs, and communicate with users
in natural language. We present our progress in integrating these features into
CTAO pipelines for operations and offline data analysis.</p></br><a href="http://arxiv.org/pdf/2509.24134v1"><h2>ASTROCO: Self-Supervised Conformer-Style Transformers for Light-Curve
  Embeddings</h2></a>Authors:  Antony Tan, Pavlos Protopapas, Martina Cádiz-Leyton, Guillermo Cabrera-Vives, Cristobal Donoso-Oliva, Ignacio Becker</br>Comments: Accepted at the NeurIPS 2025 Workshop on Machine Learning and the
  Physical Sciences (ML4PS), camera-ready version in progress</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI, cs.LG</br><p>We present AstroCo, a Conformer-style encoder for irregular stellar light
curves. By combining attention with depthwise convolutions and gating, AstroCo
captures both global dependencies and local features. On MACHO R-band, AstroCo
outperforms Astromer v1 and v2, yielding 70 percent and 61 percent lower error
respectively and a relative macro-F1 gain of about 7 percent, while producing
embeddings that transfer effectively to few-shot classification. These results
highlight AstroCo's potential as a strong and label-efficient foundation for
time-domain astronomy.</p></br><a href="http://arxiv.org/pdf/2509.26567v1"><h2>AI-assisted Advanced Propellant Development for Electric Propulsion</h2></a>Authors:  Angel Pan Du, Miguel Arana-Catania, Enric Grustan Gutiérrez</br>Comments: 23 pages, 10 figures, 5 tables. Journal of Electric Propulsion</br>Primary Category: astro-ph.IM</br>All Categories: astro-ph.IM, cs.AI, cs.LG, physics.space-ph</br><p>Artificial Intelligence algorithms are introduced in this work as a tool to
predict the performance of new chemical compounds as alternative propellants
for electric propulsion, focusing on predicting their ionisation
characteristics and fragmentation patterns. The chemical properties and
structure of the compounds are encoded using a chemical fingerprint, and the
training datasets are extracted from the NIST WebBook. The AI-predicted
ionisation energy and minimum appearance energy have a mean relative error of
6.87% and 7.99%, respectively, and a predicted ion mass with a 23.89% relative
error. In the cases of full mass spectra due to electron ionisation, the
predictions have a cosine similarity of 0.6395 and align with the top 10 most
similar mass spectra in 78% of instances within a 30 Da range.</p></br><a href="http://arxiv.org/pdf/2510.01733v1"><h2>Reducing Simulation Dependence in Neutrino Telescopes with Masked Point
  Transformers</h2></a>Authors:  Felix J. Yu, Nicholas Kamp, Carlos A. Argüelles</br>Comments: 8 pages, 3 figures, presented at the 39th International Cosmic Ray
  Conference (ICRC2025)</br>Primary Category: hep-ex</br>All Categories: hep-ex, astro-ph.IM, cs.LG</br><p>Machine learning techniques in neutrino physics have traditionally relied on
simulated data, which provides access to ground-truth labels. However, the
accuracy of these simulations and the discrepancies between simulated and real
data remain significant concerns, particularly for large-scale neutrino
telescopes that operate in complex natural media. In recent years,
self-supervised learning has emerged as a powerful paradigm for reducing
dependence on labeled datasets. Here, we present the first self-supervised
training pipeline for neutrino telescopes, leveraging point cloud transformers
and masked autoencoders. By shifting the majority of training to real data,
this approach minimizes reliance on simulations, thereby mitigating associated
systematic uncertainties. This represents a fundamental departure from previous
machine learning applications in neutrino telescopes, paving the way for
substantial improvements in event reconstruction and classification.</p></br><a href="http://arxiv.org/pdf/2509.24327v1"><h2>Inferring Cosmological Parameters with Evidential Physics-Informed
  Neural Networks</h2></a>Authors:  Hai Siong Tan</br>Comments: 25 pages, 11 figures</br>Primary Category: astro-ph.CO</br>All Categories: astro-ph.CO, cs.LG, gr-qc</br><p>We examine the use of a novel variant of Physics-Informed Neural Networks to
predict cosmological parameters from recent supernovae and baryon acoustic
oscillations (BAO) datasets. Our machine learning framework generates
uncertainty estimates for target variables and the inferred unknown parameters
of the underlying PDE descriptions. Built upon a hybrid of the principles of
Evidential Deep Learning, Physics-Informed Neural Networks, Bayesian Neural
Networks and Gaussian Processes, our model enables learning of the posterior
distribution of the unknown PDE parameters through standard gradient-descent
based training. We apply our model to an up-to-date BAO dataset (Bousis et al.
2024) calibrated with the CMB-inferred sound horizon, and the Pantheon$+$ Sne
Ia distances (Scolnic et al. 2018), examining the relative effectiveness and
mutual consistency among the standard $\Lambda$CDM, $w$CDM and $\Lambda_s$CDM
models. Unlike previous results arising from the standard approach of
minimizing an appropriate $\chi^2$ function, the posterior distributions for
parameters in various models trained purely on Pantheon$+$ data were found to
be largely contained within the $2\sigma$ contours of their counterparts
trained on BAO data. Their posterior medians for $h_0$ were within about
$2\sigma$ of one another, indicating that our machine learning-guided approach
provides a different measure of the Hubble tension.</p></br>
